[{"comments":[{"id":"IC_kwDOPZi2kc7qib7S","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"This happens because the **KaraFan** vocal separation library (used by the **Vocal Removal** node you are running) had a hardcoded path specifically looking for `ffmpeg.exe` inside the ComfyUI portable directory, bypassing any custom system PATH or environmental variables you set.\n\nI have pushed a fix for this in version `4.21.7`. The Vocal Remover will now properly use the suite's centralized FFmpeg detection, which respects your system PATH.\n\nUpdate your TTS-Audio-Suite nodes and it should start working!","createdAt":"2026-02-20T13:55:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/263#issuecomment-3934895826","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7qoe2R","author":{"login":"bolekcg"},"authorAssociation":"NONE","body":"@diodiogod Thanks.\nI Will check that soon. \nI suppose i will redo git clone ( i'm not using manager ... that's making mess in python packages ... out of control )\n\nI've got another question ... but that's for other thread \nBest!","createdAt":"2026-02-20T18:36:37Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/263#issuecomment-3936480657","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7qo0qM","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod) Thanks. I Will check that soon. I suppose i will redo git clone ( i'm not using manager ... that's making mess in python packages ... out of control )\n> \n> I've got another question ... but that's for other thread Best!\n\nI don't really know if what I fixed is exactly what you encountered because you said you were using the \"analyzer\". That could mean a bunch of things. But searching the code, this was a fix that matched your description. \n\nTo update just do a git pull. And it's good to run install.py (inside your environment) again (not this time, but when new functionalities or engines are added)","createdAt":"2026-02-20T18:59:32Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/263#issuecomment-3936569996","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":263,"title":"ffmpeg is not recognized","updatedAt":"2026-02-20T19:04:57Z"},{"comments":[],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":260,"title":"ADD NEW MOSS-TTS","updatedAt":"2026-02-20T19:04:43Z"},{"comments":[{"id":"IC_kwDOPZi2kc7o_dJ9","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"There is not much to go one here @wcmille. So far, nothing point to a bug. Also you did not post your full logs or your generation log. \n\nVibeVoice does all of that you said it is doing. IMO it's a very instable model, specially if you are not doing a long audio. If you want, I can try your workflow with youe text + voices so we can compare. But I doubt \"ghost music, adds word\" has anything to fo with my implementations. It's how the model works.\n\nSome personal tips: Try to not satart the prompt with \"Hello\", \"Hi\" etc. Try to make long sentences for each character. Try to change seed and other paramether.\n\nIn the end, VibeVoice is a instable model IMO. I still don't get why people like it that much. Sure the cloning is good, but you will need to regenerate a lot.","createdAt":"2026-02-16T15:00:21Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/259#issuecomment-3908948605","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7plOL4","author":{"login":"wcmille"},"authorAssociation":"NONE","body":"I need the SRT feature. Do the other models support that?","createdAt":"2026-02-18T05:51:29Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/259#issuecomment-3918848760","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7prb4m","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> I need the SRT feature. Do the other models support that?\n\nAny TTS model in the suite will work with SRT\n","createdAt":"2026-02-18T12:11:27Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/259#issuecomment-3920477734","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIGsg","name":"needs-clarification","description":"","color":"fbca04"},{"id":"LA_kwDOPZi2kc8AAAACKotBIg","name":"not an error","description":"","color":"aaaaaa"}],"number":259,"title":"[Bug]","updatedAt":"2026-02-18T12:11:41Z"},{"comments":[],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":257,"title":"[feature request] Support MioTTS","updatedAt":"2026-02-16T01:14:35Z"},{"comments":[{"id":"IC_kwDOPZi2kc7oz73s","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I did not forget about this, I just didn't get the time yet but it's in my list","createdAt":"2026-02-16T01:14:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/253#issuecomment-3905928684","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":253,"title":"Egyptian Arabic Model","updatedAt":"2026-02-16T01:14:08Z"},{"comments":[{"id":"IC_kwDOPZi2kc7lLwPX","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi! Thank you for reporting this issue.\n\nI've implemented a tentative fix for Step Audio EditX compatibility on Mac (Apple Silicon/MPS) in version **4.20.9**. \n\n## What was fixed\n\nThe issue was that Step Audio EditX's bundled implementation had hardcoded `torch.device('cuda')` calls that fail on Mac with \"Torch not compiled with CUDA enabled\". I've created a compatibility patch that:\n\n- Detects the actual device from the model parameters\n- Gracefully disables CUDA Graphs on non-CUDA devices (MPS/CPU)\n- Allows the model to run on Apple Silicon using MPS acceleration\n\n## For CUDA users (Linux/Windows)\nNo changes - same performance and behavior as before.\n\n## Please test!\n\nSince I don't have a Mac to test on, could you please update to version 4.20.9 and test if Step Audio EditX inline edit tags (including `<speed:slower>` for slowing down Qwen3 speech) now work on your MacBook Pro M4?\n\nThe fix should:\n1. ‚úÖ No longer crash with \"Torch not compiled with CUDA enabled\"\n2. ‚úÖ Run on MPS device for better performance than CPU\n3. ‚ÑπÔ∏è You'll see a one-time message: \"Step Audio EditX: CUDA Graphs disabled (running on mps)\"\n\nPlease let me know if this resolves the issue or if you encounter any problems!","createdAt":"2026-02-04T03:38:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3845063639","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7lOSJC","author":{"login":"0xpenelopegarcia"},"authorAssociation":"NONE","body":"\nThank you for getting back to me. Unfortunately I‚Äôm still getting errors after trying all the different ways I could think of like the inline tags, the step audio nodes, and just adding the <speed:slower> tag to the TTS text node, but I kept getting errors:\n\nEdit failed: Torch not compiled with CUDA enabled\n!!! Exception during processing !!! Torch not compiled with CUDA enabled\n\nAnd\n\nraise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled\n\nAnd \n\n‚úÖ Step Audio EditX model loaded via unified interface on mps\nEdit failed: Torch not compiled with CUDA enabled\n     ‚ùå Failed: Torch not compiled with CUDA enabled\n\nPlease let me know if I‚Äôm missing something! Thank you so much","createdAt":"2026-02-04T07:03:50Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3845726786","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7lqI5L","author":{"login":"0xpenelopegarcia"},"authorAssociation":"NONE","body":"Upon further investigation, it seems the source of the errors is due to further (obscure) calls to the CUDA library within the Step Audio EditX implementation.\n\nFor example, the `infer_encoder` function on line 550 of `..\\step_audio_editx/step_audio_editx_impl/funasr_detach/auto/auto_model.py` attempts the assignment `model = model.cuda()`\n\nDo you have any ideas on extending your previous compatibility fix to include these issues?","createdAt":"2026-02-05T11:31:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3853028939","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7m5iNy","author":{"login":"garpunzel"},"authorAssociation":"NONE","body":"@0xpenelopegarcia Same, dude. Trying to set up ComfyUI to run in the cloud right now to avoid all this Mac-related headache. Choosing between RunPod and RunComfy. Sorry for the off-topic.","createdAt":"2026-02-09T21:02:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3873842034","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7m6WPp","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hello! I've implemented a fix for the Step Audio EditX Mac compatibility issue in version **4.20.20**.\n\nChanges:\n- Replaced hardcoded CUDA initialization with a modular device resolver that supports MPS (Apple Silicon) and CPU.\n- Fixed several hardcoded \"cuda\" strings in the underlying implementation.\n\nCould you please update to version **4.20.20** and verify if this resolves the \"Torch not compiled with CUDA enabled\" error on your Mac?","createdAt":"2026-02-09T21:50:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3874055145","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7m8sej","author":{"login":"0xpenelopegarcia"},"authorAssociation":"NONE","body":"Hey! Unfortunately I am getting the same errors after updating","createdAt":"2026-02-10T00:40:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3874670499","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7m83Kk","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Thank you for the feedback!  the bundled `funasr_detach` implementation had hardcoded `.cuda()` calls that my initial fix missed.\n\nI've just released **v4.20.21** which specifically patches `engines/step_audio_editx/step_audio_editx_impl/funasr_detach/auto/auto_model.py` to:\n- Replace `model.cuda()` with `model.to(device)`\n- Use dynamic device resolution (supporting MPS/CPU)\n- Safely handle `empty_cache()` calls\n\nPlease update to **4.20.21** and let me know if this finally clears the \"Torch not compiled with CUDA enabled\" error!","createdAt":"2026-02-10T00:55:43Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3874714276","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7m9zP3","author":{"login":"0xpenelopegarcia"},"authorAssociation":"NONE","body":"Update after latest patch\n\nUnfortunately, Step Audio EditX still fails during inference.\n\n‚ö†Ô∏è  Detected incorrect weight tying in transformers 4.54+ - restoring original lm_head weights...\n‚úÖ Restored lm_head weights (norm: 264.00 ‚Üí 236.00)\n‚úÖ Step Audio EditX model loaded via unified interface on mps\nüîÑ Edit iteration 1/2...\nEdit failed: infer failed\n!!! Exception during processing !!! infer failed\nTraceback (most recent call last):\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/funasr_detach/models/paraformer_streaming/model.py\", line 780, in infer_encoder\n    speech, speech_lengths = extract_fbank(\n                             ^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/funasr_detach/utils/load_utils.py\", line 144, in extract_fbank\n    data, data_len = frontend(data, data_len, **kwargs)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/funasr_detach/frontends/wav_frontend.py\", line 422, in forward\n    waveforms, feats, feats_lengths = self.forward_fbank(\n                                      ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/funasr_detach/frontends/wav_frontend.py\", line 346, in forward_fbank\n    waveform = input[i].cuda()\n               ^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/venv/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 417, in _lazy_init\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/<user>/comfy/ComfyUI_lab/execution.py\", line 527, in execute\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/execution.py\", line 331, in get_output_data\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/execution.py\", line 305, in _async_map_node_over_list\n    await process_inputs(input_dict, i)\n  File \"/Users/<user>/comfy/ComfyUI_lab/execution.py\", line 293, in process_inputs\n    result = f(**inputs)\n             ^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/nodes/step_audio_editx_special/step_audio_editx_audio_editor_node.py\", line 565, in edit_audio\n    current_tensor = step_audio_engine.edit_single(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/utils/models/unified_model_interface.py\", line 976, in edit_single\n    audio_tensor, sample_rate = self._tts_engine.edit(\n                                ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/tts.py\", line 322, in edit\n    self.preprocess_prompt_wav(input_audio_path)\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/tts.py\", line 519, in preprocess_prompt_wav\n    vq0206_codes, vq02_codes_ori, vq06_codes_ori = self.audio_tokenizer.wav2token(prompt_wav, prompt_wav_sr)\n                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/tokenizer.py\", line 121, in wav2token\n    vq02_ori = self.get_vq02_code(audio)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/tokenizer.py\", line 163, in get_vq02_code\n    res, new_cache = self.funasr_model.infer_encoder(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/funasr_detach/auto/auto_model.py\", line 611, in infer_encoder\n    results, meta_data, cache = model.infer_encoder(**batch, **kwargs)\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/<user>/comfy/ComfyUI_lab/custom_nodes/tts_audio_suite/engines/step_audio_editx/step_audio_editx_impl/funasr_detach/models/paraformer_streaming/model.py\", line 792, in infer_encoder\n    raise RuntimeError(\"infer failed\")\nRuntimeError: infer failed\n\nPrompt executed in 0.35 seconds","createdAt":"2026-02-10T02:26:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/245#issuecomment-3874960375","viewerDidAuthor":false}],"labels":[],"number":245,"title":"Step Audio EditX compatibility mac","updatedAt":"2026-02-20T19:55:49Z"},{"comments":[{"id":"IC_kwDOPZi2kc7ka4Qw","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'll probably need to add support for it. I'll have a look. I might integrate training in the suite if it works well! Thanks for raising the issue.","createdAt":"2026-02-01T23:18:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/242#issuecomment-3832251440","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":242,"title":"Fine-Tuning Qwen3-TTS","updatedAt":"2026-02-01T23:18:43Z"},{"comments":[{"id":"IC_kwDOPZi2kc7kV2ne","author":{"login":"suicycle"},"authorAssociation":"NONE","body":"I've just tried reinstalling it all using install.py. I'm still getting the same error above.","createdAt":"2026-02-01T11:46:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/241#issuecomment-3830933982","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kWiK3","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Tentative Fix - Testing Needed\n\n**Root Cause:**\nThe error \"Unrecognized configuration class\" is caused by two issues:\n1. The downloaded config.json is missing the `AutoModelForCausalLM` entry in `auto_map` (same as issue #226)\n2. Transformers cached the broken config and keeps using the stale cache even after updates\n\n**Fixes Applied (commits 57e7329 + 37f36ac):**\n1. ‚úÖ Automatic config.json patching (adds missing AutoModelForCausalLM mapping)\n2. ‚úÖ Transformers module cache clearing (forces fresh import of fixed config)\n\n---\n\n## üß™ Testing Instructions\n\n**Step 1: Update via git pull**\n```bash\ncd ComfyUI/custom_nodes/tts_audio_suite\ngit pull\n```\n\n**Step 2: Clear transformers cache manually** (one-time, just to be safe)\n```bash\n# Linux/Mac:\nrm -rf ~/.cache/huggingface/modules/transformers_modules/*Step*\n\n# Windows:\n# Delete: C:\\Users\\YourUsername\\.cache\\huggingface\\modules\\transformers_modules\\\n# (any folders with \"Step\" in the name)\n```\n\n**Step 3: Restart ComfyUI and test**\n\nThe code will now automatically:\n- Patch your config.json on first use\n- Clear stale cache before loading\n- Load the model correctly with the fixed config\n\n---\n\n@suicycle - Please test this and report back if it resolves the issue. This is a tentative fix, so your feedback is important!","createdAt":"2026-02-01T14:14:18Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/241#issuecomment-3831112375","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kW1V5","author":{"login":"suicycle"},"authorAssociation":"NONE","body":"Still not working. Getting the same error.\nI should mention that, when it comes to Python, I have no idea what I'm doing. I'm a newbie.\n\nUpdate via git pull - done. this is the output : \n\n-----------------------\nK:\\COMFY\\ComfyUI\\custom_nodes\\TTS-Audio-Suite>git pull\nremote: Enumerating objects: 700, done.\nremote: Counting objects: 100% (268/268), done.\nremote: Compressing objects: 100% (46/46), done.\nremote: Total 700 (delta 237), reused 225 (delta 222), pack-reused 432 (from 3)\nReceiving objects: 100% (700/700), 738.28 KiB | 269.00 KiB/s, done.\nResolving deltas: 100% (415/415), completed with 78 local objects.\nFrom https://github.com/comfyanonymous/ComfyUI\n   b16390c2..96020c2c  assets-redo-part2       -> origin/assets-redo-part2\n * [new branch]        assets-redo-pruneposal  -> origin/assets-redo-pruneposal\n + a6ed8eb2...535ef706 austin/node-convert-to-list -> origin/austin/node-convert-to-list  (forced update)\n   803808b1..f3873798  austin/trim-video       -> origin/austin/trim-video\n * [new branch]        cbyrne/fix-outputs-count-non-dict -> origin/cbyrne/fix-outputs-count-non-dict\n * [new branch]        cbyrne/text-preview-support -> origin/cbyrne/text-preview-support\n * [new branch]        feat/api-nodes/11labs-music -> origin/feat/api-nodes/11labs-music\n * [new branch]        feat/api-nodes/enable-magnific-upscalers -> origin/feat/api-nodes/enable-magnific-upscalers\n * [new branch]        feat/api-nodes/hitpaw   -> origin/feat/api-nodes/hitpaw\n   dcf68685..0141af07  feat/cache-provider-api -> origin/feat/cache-provider-api\n + 68d5b81c...a18989ba feat/comfy_api/File3D-type -> origin/feat/comfy_api/File3D-type  (forced update)\n * [new branch]        jk/control-after-generate -> origin/jk/control-after-generate\n   3c0365f6..7484c9c2  jk/node-replace-api     -> origin/jk/node-replace-api\n   f23c478b..6d49f56e  jk/remove-unused-code   -> origin/jk/remove-unused-code\n * [new branch]        jk/requirements-files   -> origin/jk/requirements-files\n   09725967..667a1b88  master                  -> origin/master\n * [new branch]        partition-advanced-widgets -> origin/partition-advanced-widgets\n + 46a83e96...aaea976f pysssss/basic-glsl-shader-node -> origin/pysssss/basic-glsl-shader-node  (forced update)\n * [new branch]        pysssss/basic-glsl-shader-node-glfw -> origin/pysssss/basic-glsl-shader-node-glfw\n * [new branch]        pysssss/color-to-int-node -> origin/pysssss/color-to-int-node\n * [new branch]        pysssss/glsl-blueprints -> origin/pysssss/glsl-blueprints\n * [new branch]        remove-cache-busting    -> origin/remove-cache-busting\n * [new branch]        rename-mahiro           -> origin/rename-mahiro\n * [new branch]        toolkit-nodes/aspect-ratio-blueprint -> origin/toolkit-nodes/aspect-ratio-blueprint\n * [new tag]           v0.11.1                 -> v0.11.1\nThere is no tracking information for the current branch.\nPlease specify which branch you want to merge with.\nSee git-pull(1) for details.\n\n    git pull <remote> <branch>\n\nIf you wish to set tracking information for this branch you can do so with:\n\n    git branch --set-upstream-to=origin/<branch> master\n\n-------------\n\nDelete: C:\\Users\\YourUsername\\.cache\\huggingface\\modules\\transformers_modules\\ - done\n\n--------------\n\nRestart ComfyUI and test - done. still same error.\n\nby the way, there are only \"__init__.py\" (empty file) and \"configuration_step1.py files in the \n\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\n\nbelow is configuration_step1.py file :\n\n---------\nfrom typing import Optional, List, Any, Dict\nfrom transformers.configuration_utils import PretrainedConfig\n\n\n\nclass Step1Config(PretrainedConfig):\n    model_type = \"step1\"\n    keys_to_ignore_at_inference = [\"past_key_values\"]\n    \n    def __init__(\n        self,\n        hidden_size: int = 5120,\n        intermediate_size: int = 13312,\n        num_attention_heads: int = 40,\n        num_attention_groups: int = 8,\n        num_hidden_layers: int = 48,\n        max_seq_len: int = 4096,\n        vocab_size: int = 65536,\n        rms_norm_eps: float = 1e-5,\n        bos_token_id: int = 1,\n        eos_token_id: int = 3,\n        pad_token_id: int = 0,\n        **kwargs,\n    ) -> None:\n        self.hidden_size = hidden_size\n        self.intermediate_size = intermediate_size\n        self.num_attention_heads = num_attention_heads\n        self.num_attention_groups = num_attention_groups\n        self.num_hidden_layers = num_hidden_layers\n        self.max_seq_len = max_seq_len\n        self.vocab_size = vocab_size\n        self.rms_norm_eps = rms_norm_eps\n        super().__init__(\n            bos_token_id=bos_token_id,\n            pad_token_id=pad_token_id,\n            eos_token_id=eos_token_id,\n            **kwargs\n        )\n\n\n__all__ = [\"Step1Config\"]","createdAt":"2026-02-01T15:18:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/241#issuecomment-3831190905","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7pWSGG","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Root Cause Found + Updated Fix Available\n\nLooking at your `git pull` output, I can see the issue:\n\n```\nFrom https://github.com/comfyanonymous/ComfyUI\n```\n\n**Your git remote is pointing to the ComfyUI repository**, not TTS-Audio-Suite. That's why you got all those unrelated branches. You didn't actually pull the fixes.\n\n---\n\n## Step-by-step Fix\n\n**Step 1 - Fix the git remote:**\n```bash\ncd ComfyUI/custom_nodes/TTS-Audio-Suite\ngit remote set-url origin https://github.com/diodiogod/TTS-Audio-Suite.git\ngit pull origin main\n```\n\n**Step 2 - Clear the transformers cache:**\n\nDelete this folder (or just its contents):\n`C:\\Users\\YourUsername\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX`\n\n**Step 3 - Restart ComfyUI and test**\n\n---\n\n## What Changed\n\nSince your last report, we found and fixed the actual root cause (v4.20.15): a Python 3.12 incompatibility in a bundled audio model component was silently failing, preventing proper initialization of the engine. The previous fix (config.json patching) was addressing a symptom, not the root cause.\n\nOnce you pull from the correct repository, the fix should be in place. Please report back!","createdAt":"2026-02-17T14:14:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/241#issuecomment-3914932614","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":241,"title":"TTS Text generation failed: Failed to load Step Audio EditX model: Unrecognized configuration class","updatedAt":"2026-02-17T14:15:24Z"},{"comments":[{"id":"IC_kwDOPZi2kc7kE7mg","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Thanks for the report! But I need to know your initialization log from comfyui to see if anything failed to load, and your main dependencies... your comfyui version, TTS Auidio Sute version etc. Could you paste it here?","createdAt":"2026-01-30T23:46:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3826497952","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kFaXL","author":{"login":"persey01"},"authorAssociation":"NONE","body":"D:\\ComfyUI\\ComfyUI-Easy-Install>.\\python_embeded\\python.exe -I ComfyUI\\main.py --windows-standalone-build\n[START] Security scan\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2026-01-31 02:10:05.122\n** Platform: Windows\n** Python version: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n** Python executable: D:\\ComfyUI\\ComfyUI-Easy-Install\\python_embeded\\python.exe\n** ComfyUI Path: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\n** ComfyUI Base Folder Path: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\n** User directory: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\user\n** ComfyUI-Manager config path: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\user\\__manager\\config.ini\n** Log path: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\user\\comfyui.log\n\nPrestartup times for custom nodes:\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\rgthree-comfy\n   2.6 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-manager\n\nCheckpoint files will always be loaded safely.\nTotal VRAM 12288 MB, total RAM 65376 MB\npytorch version: 2.10.0+cu128\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 NVIDIA GeForce RTX 2060 : cudaMallocAsync\nUsing async weight offloading with 2 streams\nEnabled pinned memory 29419.0\nworking around nvidia conv3d memory bug.\nWARNING: You need pytorch with cu130 or higher to use optimized CUDA operations.\nFound comfy_kitchen backend triton: {'available': False, 'disabled': True, 'unavailable_reason': \"ImportError: No module named 'triton'\", 'capabilities': []}\nFound comfy_kitchen backend eager: {'available': True, 'disabled': False, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}\nFound comfy_kitchen backend cuda: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8']}\nUsing pytorch attention\nPython version: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\nComfyUI version: 0.11.1\nComfyUI frontend version: 1.37.11\n[Prompt Server] web root: D:\\ComfyUI\\ComfyUI-Easy-Install\\python_embeded\\Lib\\site-packages\\comfyui_frontend_package\\static\n[Crystools INFO] Crystools version: 1.27.4\n[Crystools INFO] Platform release: 10\n[Crystools INFO] JETSON: Not detected.\n[Crystools INFO] CPU: 12th Gen Intel(R) Core(TM) i3-12100F - Arch: AMD64 - OS: Windows 10\n[Crystools INFO] pynvml (NVIDIA) initialized.\n[Crystools INFO] GPU/s:\n[Crystools INFO] 0) NVIDIA GeForce RTX 2060\n[Crystools INFO] NVIDIA Driver: 580.97\n[ComfyUI-Easy-Use] server: v1.3.7 Loaded\n[ComfyUI-Easy-Use] web root: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\\web_version/v2 Loaded\nComfyUI-GGUF: Allowing full torch compile\nD:\\ComfyUI\\ComfyUI-Easy-Install\\python_embeded\\Lib\\site-packages\\transparent_background\\gui.py:24: UserWarning: Failed to import flet. Ignore this message when you do not need GUI mode.\n  warnings.warn('Failed to import flet. Ignore this message when you do not need GUI mode.')\n### Loading: ComfyUI-Manager (V3.39.2)\n[ComfyUI-Manager] network_mode: public\n[ComfyUI-Manager] ComfyUI per-queue preview override detected (PR #11261). Manager's preview method feature is disabled. Use ComfyUI's --preview-method CLI option or 'Settings > Execution > Live preview method'.\n### ComfyUI Version: v0.11.1-3-g0a799372 | Released on '2026-01-30'\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n------------------------------------------\nComfyroll Studio v1.76 :  175 Nodes Loaded\n------------------------------------------\n** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n------------------------------------------\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n[D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux] | INFO -> Using ckpts path: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux\\ckpts\n[D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux] | INFO -> Using symlinks: False\n[D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'MIGraphXExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider'][ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n\nDWPose: Onnxruntime with acceleration providers detected\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Searge_LLM\\Searge_LLM_Node.py\", line 13, in <module>\n    Llama = importlib.import_module(\"llama_cpp_cuda\").Llama\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"importlib\\__init__.py\", line 126, in import_module\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1140, in _find_and_load_unlocked\nModuleNotFoundError: No module named 'llama_cpp_cuda'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\nodes.py\", line 2216, in load_custom_node\n    module_spec.loader.exec_module(module)\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Searge_LLM\\__init__.py\", line 1, in <module>\n    from .Searge_LLM_Node import *\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Searge_LLM\\Searge_LLM_Node.py\", line 15, in <module>\n    Llama = importlib.import_module(\"llama_cpp\").Llama\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"importlib\\__init__.py\", line 126, in import_module\nModuleNotFoundError: No module named 'llama_cpp'\n\nCannot import D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Searge_LLM module for custom nodes: No module named 'llama_cpp'\n\nInitializing ControlAltAI Nodes\n\n[rgthree-comfy] Loaded 48 exciting nodes. üéâ\n\n[rgthree-comfy] ComfyUI's new Node 2.0 rendering may be incompatible with some rgthree-comfy nodes and features, breaking some rendering as well as losing the ability to access a node's properties (a vital part of many nodes). It also appears to run MUCH more slowly spiking CPU usage and causing jankiness and unresponsiveness, especially with large workflows. Personally I am not planning to use the new Nodes 2.0 and, unfortunately, am not able to invest the time to investigate and overhaul rgthree-comfy where needed. If you have issues when Nodes 2.0 is enabled, I'd urge you to switch it off as well and join me in hoping ComfyUI is not planning to deprecate the existing, stable canvas rendering all together.\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\nodes.py\", line 2216, in load_custom_node\n    module_spec.loader.exec_module(module)\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\teacache\\__init__.py\", line 1, in <module>\n    from .nodes import NODE_CLASS_MAPPINGS as NODES_CLASS, NODE_DISPLAY_NAME_MAPPINGS as NODES_DISPLAY\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\teacache\\nodes.py\", line 12, in <module>\n    from comfy.ldm.lightricks.model import precompute_freqs_cis\nImportError: cannot import name 'precompute_freqs_cis' from 'comfy.ldm.lightricks.model' (D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\comfy\\ldm\\lightricks\\model.py)\n\nCannot import D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\teacache module for custom nodes: cannot import name 'precompute_freqs_cis' from 'comfy.ldm.lightricks.model' (D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\comfy\\ldm\\lightricks\\model.py)\n   üîß torchaudio.save/load globally patched (scipy for WAV files, no TorchCodec)\n   üîá Suppressed torchaudio 2.9 migration warnings\nAPEX FusedRMSNorm not available, using native implementation\n‚ÑπÔ∏è Critical package versions: NumPy 2.2.6, Librosa 0.11.0, Numba 0.63.1, PyTorch 2.10.0+cu128, TorchAudio 2.10.0+cu128, Transformers 5.0.0, Accelerate 1.12.0, SoundFile 0.13.1\n======================================================================\nüöÄ TTS Audio Suite v4.19.12\nUniversal multi-engine TTS extension for ComfyUI\n‚úÖ TTS Audio Suite v4.19.12 loaded with 32 nodes:\n   ‚Ä¢ ‚öôÔ∏è ChatterBox Official 23-Lang Engine\n   ‚Ä¢ ‚öôÔ∏è ChatterBox TTS Engine\n   ‚Ä¢ ‚öôÔ∏è CosyVoice3 Engine\n   ‚Ä¢ ‚öôÔ∏è F5 TTS Engine\n   ‚Ä¢ ‚öôÔ∏è Higgs Audio 2 Engine\n   ‚Ä¢ ‚öôÔ∏è IndexTTS-2 Engine\n   ‚Ä¢ ‚öôÔ∏è Qwen3-TTS Engine\n   ‚Ä¢ ‚öôÔ∏è RVC Engine\n   ‚Ä¢ ‚öôÔ∏è Step Audio EditX Engine\n   ‚Ä¢ ‚öôÔ∏è VibeVoice Engine\n   ‚Ä¢ üåà IndexTTS-2 Emotion Vectors\n   ‚Ä¢ üåà IndexTTS-2 Text Emotion\n   ‚Ä¢ üåä Audio Wave Analyzer\n   ‚Ä¢ üéôÔ∏è Voice Capture\n   ‚Ä¢ üé§ TTS Text\n   ‚Ä¢ üé® Qwen3-TTS Voice Designer\n   ‚Ä¢ üé® Step Audio EditX - Audio Editor\n   ‚Ä¢ üé≠ Character Voices\n   ‚Ä¢ üé≠ Load RVC Character Model\n   ‚Ä¢ üè∑Ô∏è Multiline TTS Tag Editor\n   ‚Ä¢ üëÑ F5-TTS Speech Editor\n   ‚Ä¢ üìù Phoneme Text Normalizer\n   ‚Ä¢ üì∫ TTS SRT\n   ‚Ä¢ üîÑ Voice Changer\n   ‚Ä¢ üîß Audio Analyzer Options\n   ‚Ä¢ üîß F5-TTS Edit Options\n   ‚Ä¢ üîß RVC Pitch Extraction Options\n   ‚Ä¢ üîß Viseme Mouth Shape Options\n   ‚Ä¢ üó£Ô∏è Silent Speech Analyzer\n   ‚Ä¢ ü§ê Noise or Vocal Removal\n   ‚Ä¢ ü§ê Voice Fixer\n   ‚Ä¢ ü•™ Merge Audio\n======================================================================\nFETCH ComfyRegistry Data: 5/123\nWAS Node Suite: OpenCV Python FFMPEG support is enabled\nWAS Node Suite Warning: `ffmpeg_bin_path` is not set in `D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\was-node-suite-comfyui\\was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\n[TTS Audio Suite] üé≠ Character voices: Found 26 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\nWAS Node Suite: Finished. Loaded 220 nodes successfully.\n\n        \"The only limit to our realization of tomorrow will be our doubts of today.\" - Franklin D. Roosevelt\n\n\nImport times for custom nodes:\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\websocket_image_save.py\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\canvas_tab\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_AdvancedRefluxControl\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-seamless-tiling\n   0.0 seconds (IMPORT FAILED): D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\teacache\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-omnigen\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-inpaint-cropandstitch\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-TiledDiffusion\n   0.0 seconds (IMPORT FAILED): D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Searge_LLM\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-GGUF\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\janus-pro\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\controlaltai-nodes\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-kjnodes\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\rgthree-comfy\n   0.0 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-LTXVideo\n   0.1 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\kaytool\n   0.1 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Comfyroll_CustomNodes\n   0.1 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-videohelpersuite\n   0.1 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Sonic\n   0.1 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-ToSVG\n   0.2 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-ollama\n   0.2 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-advancedliveportrait\n   0.2 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-kokoro\n   0.3 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Florence2\n   0.3 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-itools\n   0.4 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux\n   0.6 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-manager\n   0.8 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Crystools\n   0.9 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\was-node-suite-comfyui\n   2.3 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\n   3.3 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\n   3.3 seconds: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-inspyrenet-rembg\n\nContext impl SQLiteImpl.\nWill assume non-transactional DDL.\nAssets scan(roots=['models']) completed in 0.070s (created=0, skipped_existing=63, total_seen=92)\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\nLoading faiss with AVX2 support.\nSuccessfully loaded faiss with AVX2 support.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/groupNode.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\nFETCH ComfyRegistry Data: 10/123\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\nüîß Settings endpoint called\nüîß Received settings: precision=auto, device=auto, vc_engine=chatterbox_23lang, cosyvoice_variant=RL\nüé® Step Audio EditX inline tags: precision=auto, device=auto\nüîÑ Voice restoration engine: chatterbox_23lang\nFETCH ComfyRegistry Data: 15/123\nFETCH ComfyRegistry Data: 20/123\nException in callback _ProactorBasePipeTransport._call_connection_lost(None)\nhandle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\nTraceback (most recent call last):\n  File \"asyncio\\events.py\", line 84, in _run\n  File \"asyncio\\proactor_events.py\", line 165, in _call_connection_lost\nConnectionResetError: [WinError 10054] –£–¥–∞–ª–µ–Ω–Ω—ã–π —Ö–æ—Å—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–æ—Ä–≤–∞–ª —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\nFETCH ComfyRegistry Data: 25/123\nFETCH ComfyRegistry Data: 30/123\nüîß Settings endpoint called\nüîß Received settings: precision=auto, device=auto, vc_engine=chatterbox_23lang, cosyvoice_variant=RL\nüé® Step Audio EditX inline tags: precision=auto, device=auto\nüîÑ Voice restoration engine: chatterbox_23lang\nFETCH ComfyRegistry Data: 35/123\ngot prompt\n‚öôÔ∏è Qwen3-TTS: Configured on auto\n   Model: 1.7B | Language: Russian\n   Settings: voice_preset=None (Zero-shot / Custom), temperature=0.9, top_k=50, top_p=1.0\n   Advanced: repetition_penalty=1.1, max_tokens=2048, x_vector_only=False\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS will fail, Qwen3-TTS will use x_vector_only mode (lower quality)\nüé§ Generating Qwen3_Tts for 'narrator' (lang: ru)\n[Qwen3-TTS] Auto-selected attention: sdpa\nüîÑ Loading Qwen3-TTS: Qwen3-TTS-12Hz-1.7B-Base\n   Path: D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\models\\TTS\\qwen3_tts\\Qwen3-TTS-12Hz-1.7B-Base\n   Device: cuda | Dtype: torch.float16 | Attention: sdpa\n‚ùå Failed to create engine node instance: Failed to load Qwen3-TTS model: 'default'\n‚ùå TTS Text generation failed: Failed to create engine node instance\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\unified/tts_text_node.py\", line 743, in generate_speech\n    raise RuntimeError(\"Failed to create engine node instance\")\nRuntimeError: Failed to create engine node instance\nPrompt executed in 0.22 seconds\n\nComfyUI Manager V3.39.2\nComfyUI: v0.11.1-3-g0a799372 (2026-01-30)","createdAt":"2026-01-31T00:13:33Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3826623947","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kNA7Y","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Thanks for the logs. The error `Failed to load Qwen3-TTS model: 'default'` is almost always an incomplete local model folder (missing config/weights), which makes transformers crash with a KeyError.\n\nI added a strict completeness check for all Qwen3‚ÄëTTS model variants and the tokenizer. Now, if any required file is missing, it will clearly list missing files and force a clean re‚Äëdownload instead of crashing. Commit: `4b844b3` (already pushed).\n\nPlease delete the local folder and let it re‚Äëdownload:\n- `models/TTS/qwen3_tts/Qwen3-TTS-12Hz-1.7B-Base`\n\nThen rerun and confirm whether the load succeeds.","createdAt":"2026-01-31T14:24:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3828616920","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kN_43","author":{"login":"persey01"},"authorAssociation":"NONE","body":"What a mess! I installed Comfy from scratch, deleted all models from the cache (.cache\\huggingface\\hub), redownloaded the models, and the result: \n\n[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n[ComfyUI-Manager] All startup tasks have been completed.\nFetching 13 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [08:40<00:00, 40.01s/it]\n\n‚úÖ Download complete: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\models\\TTS\\qwen3_tts\\Qwen3-TTS-12Hz-1.7B-Base\n[Qwen3-TTS] Auto-selected attention: sdpa\nüîÑ Loading Qwen3-TTS: Qwen3-TTS-12Hz-1.7B-Base \nPath: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\models\\TTS\\qwen3_tts\\Qwen3-TTS-12Hz-1.7B-Base \nDevice: cuda | Dtype: torch.float16 | Attention: sdpa\n‚ùå Failed to create engine node instance: Failed to load Qwen3-TTS model: 'default'\n‚ùå TTS Text generation failed: Failed to create engine node instance\nTraceback (most recent call last): \nFile \"F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\unified/tts_text_node.py\", line 743, in generate_speech \nraise RuntimeError(\"Failed to create engine node instance\")\nRuntimeError: Failed to create engine node instance\nPrompt executed in 521.49 seconds\n\n\n\nTo see the GUI go to: http://127.0.0.1:8188\n[TTS Audio Suite] üé≠ Character voices: Found 26 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\nLoading faiss with AVX2 support.\nSuccessfully loaded faiss with AVX2 support.\nException in callback _ProactorBasePipeTransport._call_connection_lost()\nhandle: <Handle _ProactorBasePipeTransport._call_connection_lost()>\nTraceback (most recent call last):\n  File \"asyncio\\events.py\", line 89, in _run\n  File \"asyncio\\proactor_events.py\", line 165, in _call_connection_lost\nConnectionResetError: [WinError 10054] –£–¥–∞–ª–µ–Ω–Ω—ã–π —Ö–æ—Å—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–æ—Ä–≤–∞–ª —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/groupNode.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\nFETCH ComfyRegistry Data: 10/123\nüîß Settings endpoint called\nüîß Received settings: precision=auto, device=auto, vc_engine=chatterbox_23lang, cosyvoice_variant=RL\nüé® Step Audio EditX inline tags: precision=auto, device=auto\nüîÑ Voice restoration engine: chatterbox_23lang\n[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\nFETCH DATA from: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\user\\__manager\\cache\\1514988643_custom-node-list.json [DONE]\nFETCH DATA from: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\user\\__manager\\cache\\746607195_github-stats.json [DONE]\nFETCH DATA from: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\user\\__manager\\cache\\832903789_extras.json [DONE]\nFETCH DATA from: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\user\\__manager\\cache\\1742899825_extension-node-map.json [DONE]\nFETCH ComfyRegistry Data: 15/123\nFETCH ComfyRegistry Data: 20/123\nFETCH ComfyRegistry Data: 25/123\ngot prompt\n‚öôÔ∏è Qwen3-TTS: Configured on auto\n   Model: 1.7B | Language: Russian\n   Settings: voice_preset=None (Zero-shot / Custom), temperature=0.9, top_k=50, top_p=1.0\n   Advanced: repetition_penalty=1.1, max_tokens=2048, x_vector_only=False\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS will fail, Qwen3-TTS will use x_vector_only mode (lower quality)\nüé§ Generating Qwen3_Tts for 'narrator' (lang: ru)\nüì• Model not found, downloading Qwen3-TTS-12Hz-1.7B-Base...\n\n============================================================\nüì¶ Qwen3-TTS Model Download\n============================================================\nModel: Qwen3-TTS-12Hz-1.7B-Base\nDescription: Qwen3-TTS 1.7B Base - Zero-shot voice cloning high quality (~12GB)\nRepository: Qwen/Qwen3-TTS-12Hz-1.7B-Base\nTarget: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\models\\TTS\\qwen3_tts\\Qwen3-TTS-12Hz-1.7B-Base\n============================================================\n\nüì• Downloading Qwen3-TTS-12Hz-1.7B-Base from HuggingFace...\nFETCH ComfyRegistry Data: 30/123\nHTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/revision/main \"HTTP/1.1 200 OK\"\nFetching 13 files:   0%|                                                                        | 0/13 [00:00<?, ?it/s]HTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/merges.txt \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/merges.txt \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer/config.json \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/README.md \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/merges.txt \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/model.safetensors \"HTTP/1.1 302 Found\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/preprocessor_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer%2Fconfig.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/README.md \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/.gitattributes \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/preprocessor_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer%2Fconfig.json \"HTTP/1.1 200 OK\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/README.md \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/.gitattributes \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/config.json \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/.gitattributes \"HTTP/1.1 200 OK\"\nFetching 13 files:   8%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                           | 1/13 [00:00<00:03,  3.11it/s]HTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/generation_config.json \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/config.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/generation_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/xet-read-token/fd4b254389122332181a7c3db7f27e918eec64e3 \"HTTP/1.1 200 OK\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/config.json \"HTTP/1.1 200 OK\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/generation_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer/configuration.json \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer/preprocessor_config.json \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer/model.safetensors \"HTTP/1.1 302 Found\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer%2Fconfiguration.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer%2Fpreprocessor_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer%2Fconfiguration.json \"HTTP/1.1 200 OK\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/speech_tokenizer%2Fpreprocessor_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/tokenizer_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-Base/resolve/fd4b254389122332181a7c3db7f27e918eec64e3/vocab.json \"HTTP/1.1 307 Temporary Redirect\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/tokenizer_config.json \"HTTP/1.1 200 OK\"\nHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/vocab.json \"HTTP/1.1 200 OK\"\nHTTP Request: GET https://huggingface.co/api/resolve-cache/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base/fd4b254389122332181a7c3db7f27e918eec64e3/vocab.json \"HTTP/1.1 200 OK\"\nFETCH ComfyRegistry Data: 35/123\nFETCH ComfyRegistry Data: 40/123\nFETCH ComfyRegistry Data: 45/123\nFETCH ComfyRegistry Data: 50/123\nFETCH ComfyRegistry Data: 55/123\nFETCH ComfyRegistry Data: 60/123\nFETCH ComfyRegistry Data: 65/123\nFETCH ComfyRegistry Data: 70/123\nFETCH ComfyRegistry Data: 75/123\nFETCH ComfyRegistry Data: 80/123\nFETCH ComfyRegistry Data: 85/123\nFETCH ComfyRegistry Data: 90/123\nFETCH ComfyRegistry Data: 95/123\nFETCH ComfyRegistry Data: 100/123\nFETCH ComfyRegistry Data: 105/123\nFETCH ComfyRegistry Data: 110/123\nFETCH ComfyRegistry Data: 115/123\nFETCH ComfyRegistry Data: 120/123\nFETCH ComfyRegistry Data [DONE]\n[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n[ComfyUI-Manager] All startup tasks have been completed.\nFetching 13 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [08:40<00:00, 40.01s/it]\n\n‚úÖ Download complete: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\models\\TTS\\qwen3_tts\\Qwen3-TTS-12Hz-1.7B-Base\n[Qwen3-TTS] Auto-selected attention: sdpa\nüîÑ Loading Qwen3-TTS: Qwen3-TTS-12Hz-1.7B-Base\n   Path: F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\models\\TTS\\qwen3_tts\\Qwen3-TTS-12Hz-1.7B-Base\n   Device: cuda | Dtype: torch.float16 | Attention: sdpa\n‚ùå Failed to create engine node instance: Failed to load Qwen3-TTS model: 'default'\n‚ùå TTS Text generation failed: Failed to create engine node instance\nTraceback (most recent call last):\n  File \"F:\\2\\ComfyUI_windows_portable_nvidia\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\unified/tts_text_node.py\", line 743, in generate_speech\n    raise RuntimeError(\"Failed to create engine node instance\")\nRuntimeError: Failed to create engine node instance\nPrompt executed in 521.49 seconds","createdAt":"2026-01-31T17:28:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3828874807","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kPdHS","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"oh, you are on Transformers 5.0.0, that is probably it... but IDK. I'll have to install it myself to check. Transformers compatibility is a pain in the ass to deal with.","createdAt":"2026-01-31T20:12:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3829256658","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kPftp","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"yes, confirmed. I'll try to see how I can patch it @persey01 sorry for making you download everything again.","createdAt":"2026-01-31T20:16:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3829267305","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kTEUZ","author":{"login":"persey01"},"authorAssociation":"NONE","body":"> –î–∞, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é. –ü–æ–ø—Ä–æ–±—É—é –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫ —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å.[@persey01](https://github.com/persey01)–ò–∑–≤–∏–Ω–∏—Ç–µ, —á—Ç–æ –∑–∞—Å—Ç–∞–≤–∏–ª –≤–∞—Å –≤—Å—ë —Å–∫–∞—á–∏–≤–∞—Ç—å –∑–∞–Ω–æ–≤–æ.\n\nI rolled back to Transformers 4.57.3 and everything worked.\n\nCommand: \nOpen PowerShell as administrator\ncd \"D:\\ComfyUI\\ComfyUI-Easy-Install\"\n\n1. First, uninstall the current version\npython_embeded\\python.exe -m pip uninstall transformers -y\n\n2. Install the desired version\npython_embeded\\python.exe -m pip install transformers==4.57.3\n\n3. Verify the installation\npython_embeded\\python.exe -c \"import transformers; print(f'Version: {transformers.__version__}')\"\n\nWorking logs (If you need a pause, use: [stop:2s], If you use [pause:1] - everything falls apart): \n\ngot prompt\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS will fail, Qwen3-TTS will use x_vector_only mode (lower quality)\nüé§ Generating Qwen3_Tts for 'narrator' (lang: ru)\nüîÑ Reusing cached qwen3_tts engine instance (updated with new generation parameters)\nüîÑ Qwen3-TTS: Processing 1 character segments\n\nüé§ Segment 1/1: Character 'narrator'\n  üåç Language switched to: Russian\n   Complete: 22 tokens in 4.6s (avg 4.8 it/s)\n   Complete: 44 tokens in 8.2s (avg 5.3 it/s)\n   Complete: 68 tokens in 12.1s (avg 5.6 it/s)\n   Complete: 59 tokens in 10.2s (avg 5.8 it/s)\n\n‚úÖ Qwen3_Tts generation complete. Default narrator: narrator\nPrompt executed in 36.69 seconds\n\nEverything works great, pauses are set, I'm happy!\n\n","createdAt":"2026-02-01T03:10:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3830203673","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kTqm2","author":{"login":"sev222"},"authorAssociation":"CONTRIBUTOR","body":"please fix for transformers 5","createdAt":"2026-02-01T04:37:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3830360502","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kWMLw","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"It's been really hard to make this work on transformer 5.0.0... I'll keep trying but IDK. I'm almost giving up. We might have to wait for someone more capable than me. If you guys know of any other project that made this work, please link it here!","createdAt":"2026-02-01T13:05:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3831022320","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kWNoN","author":{"login":"persey01"},"authorAssociation":"NONE","body":"> –ù–∞–ª–∞–¥–∏—Ç—å —Ä–∞–±–æ—Ç—É —ç—Ç–æ–≥–æ –Ω–∞ Transformer 5.0.0 –æ–∫–∞–∑–∞–ª–æ—Å—å –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ... –Ø –±—É–¥—É –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ø–æ–ø—ã—Ç–∫–∏, –Ω–æ –Ω–µ –∑–Ω–∞—é, —á—Ç–æ –¥–µ–ª–∞—Ç—å. –Ø –ø–æ—á—Ç–∏ —Å–¥–∞—é—Å—å. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–∞–º –ø—Ä–∏–¥—ë—Ç—Å—è –ø–æ–¥–æ–∂–¥–∞—Ç—å –∫–æ–≥–æ-–Ω–∏–±—É–¥—å –±–æ–ª–µ–µ —Å–ø–æ—Å–æ–±–Ω–æ–≥–æ, —á–µ–º —è. –ï—Å–ª–∏ –≤—ã –∑–Ω–∞–µ—Ç–µ –∫–∞–∫–∏–µ-–ª–∏–±–æ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–µ–∫—Ç—ã, –≥–¥–µ —ç—Ç–æ —É–¥–∞–ª–æ—Å—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–µ–ª–∏—Ç–µ—Å—å —Å—Å—ã–ª–∫–æ–π –∑–¥–µ—Å—å!\n\nWhen cloning, the mute's voice changes..\n\nIs there any way to make it so that after [stop:550ms] the voice doesn't change (I understand that it is created anew and is generated from scratch each time, even if you set the seed to a fixed one), maybe you can train your own lore?","createdAt":"2026-02-01T13:11:29Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3831028237","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kWc-W","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> > –ù–∞–ª–∞–¥–∏—Ç—å —Ä–∞–±–æ—Ç—É —ç—Ç–æ–≥–æ –Ω–∞ Transformer 5.0.0 –æ–∫–∞–∑–∞–ª–æ—Å—å –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ... –Ø –±—É–¥—É –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ø–æ–ø—ã—Ç–∫–∏, –Ω–æ –Ω–µ –∑–Ω–∞—é, —á—Ç–æ –¥–µ–ª–∞—Ç—å. –Ø –ø–æ—á—Ç–∏ —Å–¥–∞—é—Å—å. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–∞–º –ø—Ä–∏–¥—ë—Ç—Å—è –ø–æ–¥–æ–∂–¥–∞—Ç—å –∫–æ–≥–æ-–Ω–∏–±—É–¥—å –±–æ–ª–µ–µ —Å–ø–æ—Å–æ–±–Ω–æ–≥–æ, —á–µ–º —è. –ï—Å–ª–∏ –≤—ã –∑–Ω–∞–µ—Ç–µ –∫–∞–∫–∏–µ-–ª–∏–±–æ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–µ–∫—Ç—ã, –≥–¥–µ —ç—Ç–æ —É–¥–∞–ª–æ—Å—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–µ–ª–∏—Ç–µ—Å—å —Å—Å—ã–ª–∫–æ–π –∑–¥–µ—Å—å!\n> \n> When cloning, the mute's voice changes..\n> \n> Is there any way to make it so that after [stop:550ms] the voice doesn't change (I understand that it is created anew and is generated from scratch each time, even if you set the seed to a fixed one), maybe you can train your own lore?\n\nHi, you mean that when you use [pause:2] the next segment is not using the chosen voice? If that is the case it's a different bug, and I should fix it; please open another github issue, so we can keep this one about transformers 5.0","createdAt":"2026-02-01T13:56:18Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3831091094","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kYo1h","author":{"login":"persey01"},"authorAssociation":"NONE","body":"> > > –ù–∞–ª–∞–¥–∏—Ç—å —Ä–∞–±–æ—Ç—É —ç—Ç–æ–≥–æ –Ω–∞ Transformer 5.0.0 –æ–∫–∞–∑–∞–ª–æ—Å—å –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ... –Ø –±—É–¥—É –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ø–æ–ø—ã—Ç–∫–∏, –Ω–æ –Ω–µ –∑–Ω–∞—é, —á—Ç–æ –¥–µ–ª–∞—Ç—å. –Ø –ø–æ—á—Ç–∏ —Å–¥–∞—é—Å—å. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–∞–º –ø—Ä–∏–¥—ë—Ç—Å—è –ø–æ–¥–æ–∂–¥–∞—Ç—å –∫–æ–≥–æ-–Ω–∏–±—É–¥—å –±–æ–ª–µ–µ —Å–ø–æ—Å–æ–±–Ω–æ–≥–æ, —á–µ–º —è. –ï—Å–ª–∏ –≤—ã –∑–Ω–∞–µ—Ç–µ –∫–∞–∫–∏–µ-–ª–∏–±–æ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–µ–∫—Ç—ã, –≥–¥–µ —ç—Ç–æ —É–¥–∞–ª–æ—Å—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–µ–ª–∏—Ç–µ—Å—å —Å—Å—ã–ª–∫–æ–π –∑–¥–µ—Å—å!\n> > \n> > \n> > When cloning, the mute's voice changes..\n> > Is there any way to make it so that after [stop:550ms] the voice doesn't change (I understand that it is created anew and is generated from scratch each time, even if you set the seed to a fixed one), maybe you can train your own lore?\n> \n> Hi, you mean that when you use [pause:2] the next segment is not using the chosen voice? If that is the case it's a different bug, and I should fix it; please open another github issue, so we can keep this one about transformers 5.0\n\nThe voice remains the same as the one we are cloning, but its pitch and speed change. One person speaks, but depending on the segment, the speed and pitch of the voice vary, as if the recording were being made under different conditions. ","createdAt":"2026-02-01T18:17:01Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3831663969","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kx3A2","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"We traced this to Transformers 5.0.0 tokenizer incompatibilities with Qwen3‚ÄëTTS. We could not get a reliable tokenizer load path under 5.0.0 (vocab/merges + fast tokenizer) without hard failures, so for now 5.x is **not supported** for Qwen3‚ÄëTTS.\n\nMitigation added:\n- Cap transformers to <=4.57.3 (requirements + installer)\n- Startup warning if Transformers 5.x is detected\n- Investigation report in docs (TRANSFORMERS_5_QWEN3_TTS_REPORT.md)\n\nRecommended action: downgrade to transformers<=4.57.3. This should restore Qwen3‚ÄëTTS.\n\nSorry for the churn ‚Äî but 5.0.0 is genuinely breaking the tokenizer path in this environment.","createdAt":"2026-02-03T01:25:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3838275638","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kx4l9","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'm officially out of trying to patch transformers 5.0.0 if you guys find out about any other project that fixed it, or if a new version fixes it, let us now in the comments here and I'll be glad to implement it.","createdAt":"2026-02-03T01:26:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/238#issuecomment-3838282109","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWvQ","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"LA_kwDOPZi2kc8AAAACHIPW4Q","name":"wontfix","description":"This will not be worked on","color":"d4c5f9"},{"id":"LA_kwDOPZi2kc8AAAACRuPrGg","name":"Dependencies-help","description":"","color":"d3aba3"}],"number":238,"title":"[Bug] Qwen3-TTS cloning error. V. 4.19.12 [transformers 5.0.0 incompatibility] ","updatedAt":"2026-02-05T02:49:14Z"},{"comments":[{"id":"IC_kwDOPZi2kc7jlo-U","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"We already support flash attn2 and sage attn. I guess I could try to add torch.compile and I don't really have much knowledge about the others... but I'll investigate.","createdAt":"2026-01-29T15:08:28Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/234#issuecomment-3818295188","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kBkOt","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I've added some pretty good optimizations on [Version 4.19.12](https://github.com/diodiogod/TTS-Audio-Suite/commit/7bf270cae9584fea00c401786c49ea954733cb69) \n\nbut it needs pytorch 2.10.0+cu130 + triton (on windows, at least, it's what I've tested)\n\nSpeed went from 5 it/s to 8.6 it/s","createdAt":"2026-01-30T20:32:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/234#issuecomment-3825615789","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7kBrtF","author":{"login":"shivdbz2010"},"authorAssociation":"NONE","body":"Can you copy optimization techniques from this tts to other tts?","createdAt":"2026-01-30T20:40:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/234#issuecomment-3825646405","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7kE41h","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Maybe... I don't really know @shivdbz2010. I think theoretically other models could have torch.compile optimizations as well (some already do), but I'm not the expert here. I would rather have other people do it and then I can integrate it. Or people can do a PR!\nI could investigate but I don't have the time right now though =(","createdAt":"2026-01-30T23:44:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/234#issuecomment-3826486625","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACOVaPDQ","name":"done","description":"","color":"63028d"}],"number":234,"title":"Add optimization from https://github.com/groxaxo/Qwen3-TTS-Openai-Fastapi","updatedAt":"2026-01-30T23:44:12Z"},{"comments":[{"id":"IC_kwDOPZi2kc7iqvLg","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"it's supported on 4.18, update and test to see if it works well","createdAt":"2026-01-27T03:19:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/232#issuecomment-3802854112","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7ir-Iu","author":{"login":"yogeshnichal"},"authorAssociation":"NONE","body":"* **VibeVoice-7B** produces clear output only for short inputs (around **200‚Äì300 characters**). For longer generations, the audio develops **echo, reverb, and quality degradation**.\n* **F5-TTS (Hindi)** works for longer audio, but since it is a **smaller model**, it introduces **pronunciation errors, instability, and inconsistencies**, especially in **30-minute or longer narrations**.\n\nAt the moment, there is no reliable solution for:\n\n* Long-form Hindi storytelling or narration\n* Stable voice quality over extended duration\n* Accurate pronunciation and consistent prosody in Hindi\n* A **larger or better-trained Hindi model**, or\n* **Long-form chunking with seamless stitching**, or\n* Any recommended **configuration, inference strategy, or roadmap** for improving long-duration Hindi audio quality.\n\nThank you for your work‚Äîthis would greatly benefit users creating long Hindi content such as audiobooks, stories, and narrations.","createdAt":"2026-01-27T05:21:40Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/232#issuecomment-3803177518","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7ixLSj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> * **VibeVoice-7B** produces clear output only for short inputs (around **200‚Äì300 characters**). For longer generations, the audio develops **echo, reverb, and quality degradation**.\n> \n>     * **F5-TTS (Hindi)** works for longer audio, but since it is a **smaller model**, it introduces **pronunciation errors, instability, and inconsistencies**, especially in **30-minute or longer narrations**.\n> \n> \n> At the moment, there is no reliable solution for:\n> \n>     * Long-form Hindi storytelling or narration\n> \n>     * Stable voice quality over extended duration\n> \n>     * Accurate pronunciation and consistent prosody in Hindi\n> \n>     * A **larger or better-trained Hindi model**, or\n> \n>     * **Long-form chunking with seamless stitching**, or\n> \n>     * Any recommended **configuration, inference strategy, or roadmap** for improving long-duration Hindi audio quality.\n> \n> \n> Thank you for your work‚Äîthis would greatly benefit users creating long Hindi content such as audiobooks, stories, and narrations.\n\nVibeVoice by default skips chunking because it is supposed to be good at long generations. But if it is bad in the finetunes hindi model, try enabling chunk. It ignores the TTS Text chunk option, but you can enable chunk on the engine. On the engine set chunk_minutes to 1 or any value you find works better.\n\nAnd there is another option that is lang-23 chatterbox. it supports Hindi as well.\n\nYet another option for you is generating your tts with SRT. With the srt node you can change parameters only for the part you didn't like. This is useful for F5 for example. If in one session it goes bad, you can try to regenerate only that part by changing the text or using another seed, add on the text [seed:42]. Actually you can add [seed:42] on the TTS Text node as well to force a chunk/segment.","createdAt":"2026-01-27T11:07:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/232#issuecomment-3804542115","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7i2DWW","author":{"login":"yogeshnichal"},"authorAssociation":"NONE","body":"üí¨ Narrator Voice: Harsh ready for F5-TTS, ChatterBox, and future engines (text from voices_examples/Ref_Voice/Harsh.MP3)\n‚öôÔ∏è ChatterBox Engine: Configured for local:Hindi on auto\n   Settings: exaggeration=0.5, temperature=0.8, cfg_weight=0.5\n   Crash protection: hmm ,, {seg} hmm ,,\nüé§ TTS Text: Using voice reference from Character Voices node (Harsh)\nüé§ Generating Chatterbox for 'Harsh' (lang: local)\nüé≠ ChatterBox: Character switching mode - found characters: harsh\nüé≠ Voice mapping - character voices: harsh\nüéØ TRADITIONAL MODE: Processing 1 language groups sequentially\n‚ö†Ô∏è Chatterbox: Language 'hi' not supported, falling back to English model\nFETCH ComfyRegistry Data: 35/122\ninput frame rate=25\nüî§ Using available tokenizer: tokenizer.json\nüì¶ ChatterBox models loaded from: C:\\pinokio\\api\\comfy.git\\app\\models\\TTS\\chatterbox\\English\nüî§ Final text to ChatterBox TTS model (harsh): '‡§∏‡•Å‡§® ‡§≠‡§æ‡§à, ‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡§∞‡•ç‡§∑ ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§¨‡§ö‡§™‡§® ‡§∏‡•á ‡§ò‡•ã‡§°‡•ã‡§Ç ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§™‡§≤‡§æ-‡§¨‡§¢‡§æ ‡§π‡•Ç‡§Å, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§†‡•Ä‡§ï ‡§∏‡•á ‡§ö‡§≤ ‡§≠‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§™‡§æ‡§§‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§∏‡•á ‡§Ö‡§∏‡•ç‡§§‡§¨‡§≤ ‡§ï‡•Ä ‡§ß‡•Ç‡§≤ ‡§î‡§∞ ‡§≤‡•Ä‡§¶ ‡§ï‡•Ä ‡§Æ‡§π‡§ï ‡§Æ‡•á‡§∞‡•á ‡§´‡•á‡§´‡§°‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§∏‡•Ä ‡§π‡•à, ‡§ò‡•ã‡§°‡•ã‡§Ç ‡§ï‡•Ä ‡§∞‡§ó-‡§∞‡§ó ‡§∏‡•á ‡§µ‡§æ‡§ï‡§ø‡§´ ‡§π‡•Ç‡§Å ‡§Æ‡•à‡§Ç.'\nReference mel length is not equal to 2 * reference token length.\n\nSampling:  25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                                                                                                 | 252/1000 [00:06<00:18, 41.13it/s]FETCH ComfyRegistry Data: 40/122\nSampling:  39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                       | 387/1000 [00:09<00:14, 41.09it/s]\nüé≠ Generating ChatterBox segment 1/4 for 'harsh' (lang: hi)\n‚ö†Ô∏è Chatterbox: Language 'hi' not supported, falling back to English model\nüî§ Final text to ChatterBox TTS model (harsh): '‡§â‡§®‡§ï‡•Ä ‡§§‡§æ‡§ï‡§§, ‡§â‡§®‡§ï‡•Ä ‡§µ‡§´‡§æ‡§¶‡§æ‡§∞‡•Ä, ‡§â‡§®‡§ï‡§æ ‡§ó‡•Å‡§∏‡•ç‡§∏‡§æ.. ‡§î‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§ú‡§∞‡•Ç‡§∞‡•Ä ‡§¨‡§æ‡§§ ‡§â‡§®‡§ï‡§æ ‡§°‡§∞, ‡§ú‡§æ‡§®‡§µ‡§∞ ‡§ù‡•Ç‡§† ‡§®‡§π‡•Ä‡§Ç ‡§¨‡•ã‡§≤‡§§‡•á, ‡§∞‡§æ‡§µ, ‡§ú‡§¨ ‡§µ‡•ã ‡§°‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§∏‡§Æ‡§ù ‡§≤‡•ã ‡§ï‡§ø ‡§π‡§µ‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§ó‡§≤‡§§ ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§™‡•Å‡§£‡•á ‡§ï‡•á ‡§™‡§æ‡§∏, ‡§§‡§æ‡§Æ‡•ç‡§π‡§ø‡§£‡•Ä ‡§ò‡§æ‡§ü ‡§ï‡•á ‡§â‡§∏ ‡§™‡§æ‡§∞, ‡§è‡§ï ‡§∏‡•Å‡§®‡§∏‡§æ‡§® ‡§á                      ‡§á‡§≤‡§æ‡§ï‡•á ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§•‡§æ, ‡§è‡§ï‡§¶‡§Æ ‡§µ‡•Ä‡§∞‡§æ‡§®.'\nReference mel length is not equal to 2 * reference token length.\n\nSampling:  15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                                                                                                                    | 153/1000 [00:03<00:20, 40.80it/s]\n\n(env) (base) C:\\pinokio\\api\\comfy.git\\app>\n\n‚ñà‚ñà Terminated Shell e7b0d612-b39b-4f85-a8da-de76228559de","createdAt":"2026-01-27T15:20:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/232#issuecomment-3805820310","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7i9QIU","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I don't know what is going on there @yogeshnichal, is it crashing, is that it? Just because of chunking? That is weird.","createdAt":"2026-01-27T21:49:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/232#issuecomment-3807707668","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACOVaPDQ","name":"done","description":"","color":"63028d"}],"number":232,"title":"Vibevoice Finetune Hindi Model","updatedAt":"2026-01-27T21:49:40Z"},{"comments":[{"id":"IC_kwDOPZi2kc7iPo4a","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'm working on it","createdAt":"2026-01-25T00:28:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/230#issuecomment-3795750426","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7iQYbf","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"‚úÖ **Vietnamese (Viterbox) support added in v4.17.0!**\n\nThe Vietnamese community finetune by Dolly AI 23 is now fully integrated into ChatterBox Official 23-Lang.\n\n## How to Use\n\n1. **Select Model Version**: Choose \"Vietnamese (Viterbox)\" from the model_version dropdown in the ChatterBox Official 23-Lang engine node\n2. **Select Language**: Choose \"Vietnamese (Viterbox only)\" from the language dropdown\n3. **Auto-Download**: Model files will download automatically from dolly-vn/viterbox on first use\n\n## Implementation Details\n\n- Added Vietnamese (Viterbox) as a model version option (alongside v1 and v2)\n- Supports 24 languages total (original 23 + Vietnamese)\n- Expanded Vietnamese tokenization (2549 tokens vs 2352/2454 in official models)\n- Flexible architecture supports future community finetunes with different vocab sizes\n- Files auto-download to `models/TTS/chatterbox_official_23lang/Vietnamese (Viterbox)/`\n\n## Language Tag Usage\n\nUse `[vi:character_name]` tags for Vietnamese text in character switching mode, or select Vietnamese from the language dropdown for the entire generation.\n\nThanks for the suggestion! The implementation now supports both the official models and community finetunes seamlessly.","createdAt":"2026-01-25T04:21:18Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/230#issuecomment-3795945183","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACOVaPDQ","name":"done","description":"","color":"63028d"}],"number":230,"title":"Add mod dataset to Chatterbox, but the voice weird","updatedAt":"2026-01-25T04:22:03Z"},{"comments":[{"id":"IC_kwDOPZi2kc7h7a54","author":{"login":"sudeep333"},"authorAssociation":"NONE","body":"me too. waiting for it to be integrated. ","createdAt":"2026-01-23T14:14:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3790450296","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7iAIjI","author":{"login":"Grownz"},"authorAssociation":"NONE","body":"There already exists a rough implementation https://github.com/flybirdxx/ComfyUI-Qwen-TTS\n\nBut (for now, atleast) it lacks some core features, though.","createdAt":"2026-01-23T18:28:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3791685832","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7iK-cg","author":{"login":"Poilaucul"},"authorAssociation":"NONE","body":"Patiently waiting for this.","createdAt":"2026-01-24T11:57:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3794528032","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7iOXMX","author":{"login":"juangea"},"authorAssociation":"NONE","body":"Yeah, me too, this is by far the best model I've tested so far with multilanguage and voice design, amazing model.","createdAt":"2026-01-24T19:49:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3795415831","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7iOsBJ","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"It looks promising, I'll be working on implementing it as soon as I got the time.","createdAt":"2026-01-24T20:55:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":11}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3795501129","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7jMIdC","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"It's done on v4.19. Please report any issues!","createdAt":"2026-01-28T14:23:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":2}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3811608386","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7jQ6_1","author":{"login":"Tenidus"},"authorAssociation":"NONE","body":"When trying to voice clone I get the following error:\n\n‚ùå TTS Text generation failed: Boolean value of Tensor with more than one value is ambiguous\nTraceback (most recent call last):\n  File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\unified/tts_text_node.py\", line 1270, in generate_speech\n    audio_segments = engine_instance.process_text(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\qwen3_tts\\qwen3_tts_processor.py\", line 287, in process_text\n    return self._process_character_switching(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\qwen3_tts\\qwen3_tts_processor.py\", line 356, in _process_character_switching\n    self._process_character_block(segment.character, segment.text.strip(), voice_mapping,\n  File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\qwen3_tts\\qwen3_tts_processor.py\", line 511, in _process_character_block\n    audio_tensor = self.adapter.generate_with_pause_tags(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\engines\\adapters\\qwen3_tts_adapter.py\", line 204, in generate_with_pause_tags\n    return self._generate_direct(text, voice_ref, params, character_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\engines\\adapters\\qwen3_tts_adapter.py\", line 229, in _generate_direct\n    return self._generate_voice_clone(text, voice_ref, params, character_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\engines\\adapters\\qwen3_tts_adapter.py\", line 418, in _generate_voice_clone\n    elif ref_audio_original and isinstance(ref_audio_original, str):\n         ^^^^^^^^^^^^^^^^^^\nRuntimeError: Boolean value of Tensor with more than one value is ambiguous\nPrompt executed in 4.36 seconds","createdAt":"2026-01-28T17:51:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3812863989","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7jRSdE","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> When trying to voice clone I get the following error:\n> \n> ‚ùå TTS Text generation failed: Boolean value of Tensor with more than one value is ambiguous Traceback (most recent call last): File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\unified/tts_text_node.py\", line 1270, in generate_speech audio_segments = engine_instance.process_text( ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\qwen3_tts\\qwen3_tts_processor.py\", line 287, in process_text return self._process_character_switching( ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\qwen3_tts\\qwen3_tts_processor.py\", line 356, in _process_character_switching self._process_character_block(segment.character, segment.text.strip(), voice_mapping, File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\nodes\\qwen3_tts\\qwen3_tts_processor.py\", line 511, in _process_character_block audio_tensor = self.adapter.generate_with_pause_tags( ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\engines\\adapters\\qwen3_tts_adapter.py\", line 204, in generate_with_pause_tags return self._generate_direct(text, voice_ref, params, character_name) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\engines\\adapters\\qwen3_tts_adapter.py\", line 229, in _generate_direct return self._generate_voice_clone(text, voice_ref, params, character_name) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\test\\Documents\\ComfyUI_New\\custom_nodes\\tts_audio_suite\\engines\\adapters\\qwen3_tts_adapter.py\", line 418, in _generate_voice_clone elif ref_audio_original and isinstance(ref_audio_original, str): ^^^^^^^^^^^^^^^^^^ RuntimeError: Boolean value of Tensor with more than one value is ambiguous Prompt executed in 4.36 seconds\n\nwhat version? I think I fixed this already","createdAt":"2026-01-28T18:08:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3812960068","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7jRVBf","author":{"login":"Tenidus"},"authorAssociation":"NONE","body":"@diodiogod version 4.19.5, I'll update to 4.19.6 and report back\n\nUpdate:  Yes, 4.19.6 did work without issue.  Thank you!","createdAt":"2026-01-28T18:09:44Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3812970591","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7jWHRw","author":{"login":"juangea"},"authorAssociation":"NONE","body":"I see a problem.\n\nI'm giving a opt_narrator voice and configure spanish, but it goes back to the default narrator in english, it does not matter what language do I pick.\n\n<img width=\"823\" height=\"319\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/347a51f3-7bbb-4f52-bd69-7054b42b768f\" />\n\nThat's my config, and this is the terminal info:\n\n```\n‚úÖ Qwen3_Tts generation complete. Default narrator: David_Attenborough CC3\nPrompt executed in 212.70 seconds\ngot prompt\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS engines will fail\nüé§ Generating Qwen3_Tts for 'narrator' (lang: sp)\nüîÑ Reusing cached qwen3_tts engine instance (updated with new generation parameters)\nüé≠ Qwen3-TTS: Using character-specific voice for 'narrator' (ICL mode)\nüîÑ Qwen3-TTS: Processing 1 character segments\n\nüé§ Segment 1/1: Character 'narrator'\n  üåç Language switched to: English\nüé≠ Qwen3-TTS - Generating for 'narrator' (Language: English):\n```","createdAt":"2026-01-28T22:19:43Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3814225008","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7jXdt3","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"fixed on  4.19.7 @juangea, thanks for the report!\n\nAnd keep in mind the model will work with direct audio, but it prefers a character (audio + reference text).","createdAt":"2026-01-29T00:05:45Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3814579063","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7jdFZN","author":{"login":"juangea"},"authorAssociation":"NONE","body":"Perfect, thanks.\n\nI imagine there is no way to make the model work with the voice changer, right?","createdAt":"2026-01-29T07:53:28Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3816052301","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7jfFJG","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> Perfect, thanks.\n> \n> I imagine there is no way to make the model work with the voice changer, right?\n\nIf you are asking if  the model has VC capabilities, no unfortunately no =( You still have only RVC, Chatterbox and more recently CozyVice3.\n\nI have also introduced some nice tables in this update; check the readme links\n üìä [Full comparison tables ‚Üí](https://github.com/diodiogod/TTS-Audio-Suite/blob/main/docs/ENGINE_COMPARISON.md) | [Language matrix ‚Üí](https://github.com/diodiogod/TTS-Audio-Suite/blob/main/docs/LANGUAGE_SUPPORT.md) | [Feature matrix ‚Üí](https://github.com/diodiogod/TTS-Audio-Suite/blob/main/docs/FEATURE_COMPARISON.md)","createdAt":"2026-01-29T09:47:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3816575558","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7jfcqa","author":{"login":"juangea"},"authorAssociation":"NONE","body":"Oh! so we can use CosyVoice3 for Voice Changing, that's great news, becuase chatterbox drags some letters in spanish, and RVC is a nightmare to train (unless you tell me that we can train with this node, and avoid living a nightmare installing RVC in the Venv)","createdAt":"2026-01-29T10:07:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3816671898","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7jgSg0","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> Oh! so we can use CosyVoice3 for Voice Changing, that's great news, becuase chatterbox drags some letters in spanish, and RVC is a nightmare to train (unless you tell me that we can train with this node, and avoid living a nightmare installing RVC in the Venv)\n\nI did have initial plans of supporting RVC training, but didn't got the time to implement it yet","createdAt":"2026-01-29T10:49:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3816892468","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7jikXM","author":{"login":"juangea"},"authorAssociation":"NONE","body":"If you at any point in time can implement it, it would be amazing, no node, or even RVC via Python with the required virtual env , is easy to install, it's a total nightmare, and it's the reason why we ignore RVC completely.\n\nI should say also that anyways, with the CosyVoice VC, the results are way better than with ChatterBox, so it's great :)","createdAt":"2026-01-29T12:49:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3817489868","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7jivJN","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> If you at any point in time can implement it, it would be amazing, no node, or even RVC via Python with the required virtual env , is easy to install, it's a total nightmare, and it's the reason why we ignore RVC completely.\n> \n> I should say also that anyways, with the CosyVoice VC, the results are way better than with ChatterBox, so it's great :)\n\nyeah that is my impression as well, that CozyVoice3 VC is better than Chatterbox. BTW I also added on comfyui settings option menu a way to change the default \\<restore\\> inline tag to use CozyVoice3 VC and not just default to Chatterbox.","createdAt":"2026-01-29T12:58:17Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/229#issuecomment-3817534029","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"},{"id":"LA_kwDOPZi2kc8AAAACOVaPDQ","name":"done","description":"","color":"63028d"}],"number":229,"title":"Qwen3-TTS Released","updatedAt":"2026-01-29T12:58:50Z"},{"comments":[{"id":"IC_kwDOPZi2kc7ejgnv","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Issue Analysis & Resolution\n\nThanks for the detailed report! I've analyzed your AI-generated fixes and implemented the **valid issues** properly in v4.16.10, while explaining why the memory management changes are unnecessary.\n\n---\n\n## ‚úÖ Valid Issues - **FIXED in v4.16.10**\n\n### 1. dtype Parameter Error (Phase 1)\n**Your diagnosis:** Correct - `Step1ForCausalLM.__init__()` doesn't accept `dtype` parameter  \n**Our fix:** Changed `load_kwargs[\"dtype\"]` ‚Üí `load_kwargs[\"torch_dtype\"]` in `model_loader.py` (3 locations)  \n**Architecture layer:** Engine implementation (correct layer for this fix)\n\n### 2. bf16 GPU Compatibility (Phase 6)\n**Your diagnosis:** Correct - bf16 requires SM 8.0+ (Ampere GPUs)  \n**Our fix:** \n- Added GPU compute capability detection in `step_audio_editx.py`\n- Changed default from `\"bfloat16\"` ‚Üí `\"auto\"` with smart detection:\n  - RTX 30xx/40xx, A100 (SM ‚â• 8.0) ‚Üí automatically use bf16\n  - RTX 20xx, V100, older GPUs ‚Üí automatically use fp16\n- Centralized fix in one location instead of scattered across 5 files\n\n---\n\n## ‚ùå Invalid/Unnecessary Fixes\n\n### Memory Management Issues (Phase 2, 3, 4, 5)\n**Your approach:** Added manual `gc.collect()`, `torch.cuda.empty_cache()`, `__del__` methods in node/processor layers\n\n**Why this is wrong:**\n\n1. **We already have ComfyUI model management integration** (see `PROJECT_INDEX.md` line 9)\n   - `utils/models/comfyui_model_wrapper/` - Full ComfyUI integration\n   - Works with \"Clear VRAM\" button automatically\n   - Auto-unloads when loading other models\n   - Proper memory tracking via `loaded_size()` and `model_size()`\n\n2. **Violates modular architecture:**\n   - Memory management belongs in `utils/models/`, NOT in node/processor layers\n   - Nodes delegate to processors ‚Üí processors delegate to engines ‚Üí engines use unified_model_interface\n   - Adding `__del__` methods in nodes breaks this clean separation\n\n3. **The fixes target the wrong layer:**\n   - Phase 2/3/4: Modified `step_audio_editx_audio_editor_node.py` (processor layer)\n   - Should use existing `unified_model_interface` caching system\n   - Manual CUDA cleanup bypasses ComfyUI's memory manager\n\n4. **Already handled by existing code:**\n   - `utils/models/smart_loader.py` - Prevents duplicate model loading\n   - `utils/models/unified_model_interface.py` - Centralized caching with proper cleanup\n   - `ComfyUIModelWrapper` - Integrates with ComfyUI's native model management\n\n---\n\n## How Memory Management Actually Works\n\nThe architecture already handles GPU memory properly:\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ ComfyUI Model Management (Native)          ‚îÇ\n‚îÇ - \"Clear VRAM\" button                       ‚îÇ\n‚îÇ - Auto-unload on memory pressure            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n               ‚îÇ\n               ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ ComfyUIModelWrapper (utils/models/)         ‚îÇ\n‚îÇ - loaded_size() tracking                    ‚îÇ\n‚îÇ - Automatic GPU/CPU offloading              ‚îÇ\n‚îÇ - Cleanup on model replacement              ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n               ‚îÇ\n               ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ unified_model_interface                     ‚îÇ\n‚îÇ - Smart caching (prevents duplicates)       ‚îÇ\n‚îÇ - Engine-specific handlers                  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n               ‚îÇ\n               ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Step Audio EditX Engine                     ‚îÇ\n‚îÇ - Model loading/inference                   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**To free GPU memory:**\n1. Use ComfyUI's \"Clear VRAM\" button (works automatically)\n2. Load a different model (auto-unloads previous)\n3. Let ComfyUI's memory manager handle it\n\n---\n\n## Summary\n\n- **Fixed:** dtype parameter error + GPU capability detection\n- **Not needed:** Manual memory cleanup (architecture already handles it)\n- **Version:** v4.16.10 released with proper fixes\n\nYour bug report identified real issues, but the AI-generated solutions didn't understand the existing architecture. The fixes are now implemented correctly in the right layers.","createdAt":"2026-01-11T02:37:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/224#issuecomment-3733850607","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7enPIz","author":{"login":"yulezz"},"authorAssociation":"NONE","body":"Thank you very much for your effort in integrating so many TTS models together - it's truly remarkable and challenging. I also want to contribute to this project, but I have no coding knowledge at all. Moreover, I feel that AI-generated fixes are often quite superficial and don't consider the global picture when solving problems. This leads to fixing one issue while creating new ones.\n\nI previously tried to fork the project and submit a PR after making fixes, but after submitting, I tested other nodes again and they started throwing errors, so I had to urgently withdraw the PR. In the end, I had the AI generate this modification description.\n\nAdditionally, I tested the new version 4.16.10 - the errors are basically fixed. However, the StepAudioEditXAudioEditorNode is running at only 5 tokens per second, making it completely unusable. I tried to fix this with AI assistance, but as I mentioned, its modifications kept creating new problems. After several hours of attempts, I gave up on fixing it. Still, I came to the following conclusions:\n\nPyTorch's code for detecting compute capability might return true for BF16 support even when full BF16 computation isn't actually supported.\n\nWhen I tried to force all models to use FP16 precision, I encountered issues with the torchaudio.compliance.kaldi.fbank function, which only supports float32 and not float16 (Half) dtype. My attempts to modify this kept creating new problems.\n\nUltimately, I concluded that StepAudioEditXAudioEditorNode likely has models using different precisions during the inference stage, causing slow inference speeds - a problem I couldn't solve.\n\nBelow are some logs from my attempted modifications. Since I couldn't resolve the issue, I decided to abandon using the StepAudioEditXAudioEditorNode node.\n# Step Audio EditX Performance Optimization and Bug Fix Summary\n\n## Problem Description\n\n### Performance Discrepancy\n- **StepAudioEditXAudioEditorNode**: Running speed ~5-6 tokens/s\n- **StepAudioEditXEngineNode**: Running speed ~16 tokens/s\n- **Goal**: Unify performance between both nodes and eliminate performance differences\n\nKey Information Analysis\nGPU Information:\n\nGPU Model: NVIDIA GeForce RTX 2080 Ti\n\nCompute Capability: 7.5\n\nBF16 Support: Supports BF16: True\n\nPrecision Settings:\n\nInitial Setting: precision=auto\n\nParsing Process: auto ‚Üí torch_dtype_val=auto\n\nFinal Precision: torch_dtype_str=auto ‚Üí torch_dtype=torch.bfloat16\n\nRTX 2080 Ti BF16 Support Issue Analysis\n1. Why does RTX 2080 Ti show BF16 support?\nHardware Background:\n\nRTX 2080 Ti uses Turing architecture (Compute Capability 7.5)\n\nFull native BF16 support starts from Ampere architecture (Compute Capability 8.0+, e.g., RTX 30xx series)\n\nTuring architecture only has limited BF16 support:\n\nSupports BF16 storage, but not full BF16 computational instructions\n\nUses FP32 ALU for BF16 operations, requiring additional conversion overhead\n\nPyTorch Detection Logic:\n\ntorch.cuda.is_bf16_supported() returns True on Turing architecture\n\nThis is because PyTorch detects whether the hardware can store BF16 data, not whether it can compute BF16 efficiently\n\n2. Why is BF16 slower than FP16?\nPerformance Difference Reasons:\n\nDifferent Computational Paths:\n\nFP16: Turing architecture has native FP16 ALU, direct hardware acceleration\n\nBF16: Needs simulation through FP32 ALU, adding conversion overhead\n\nConversion Overhead:\n\ntext\nBF16 Input ‚Üí FP32 Conversion ‚Üí FP32 Calculation ‚Üí BF16 Conversion ‚Üí BF16 Output\nEach operation adds two precision conversions\n\nConversion operations consume additional computational resources\n\nMemory Bandwidth:\n\nBoth BF16 and FP16 are 2-byte data, same memory bandwidth\n\nBut additional conversion operations offset the memory bandwidth advantage\n\n3. Solutions\nImmediate Solution:\n\nForce FP16 precision in Step Audio EditX nodes:\n\nIf there's a precision parameter, set it to fp16\n\nOr modify default settings in the code\n\nCode Modification Solution:\n\npython\n# Modify default precision in step_audio_editx_audio_editor_node.py\ndefault_precision = \"fp16\"  # Change to fp16 instead of auto\nprecision_setting = inline_tag_precision if inline_tag_precision else default_precision\n\n## System Environment\n\n### Hardware Configuration\n- GPU: NVIDIA GeForce RTX 2080 Ti\n- Compute Capability: 7.5\n\n### Software Environment\n- PyTorch: Older version (does not support xFormers SDPA detection) (My PyTorch is 2.6+cuda126)\n- Transformers: 4.51\n- xFormers: 0.0.29.post3 (installed but cannot be used)\n\n## All Errors Encountered\n\n### 1. NameError: name 'Any' is not defined\n**File**: `tts.py`\n**Cause**: Missing type annotation import\n**Fix**: Added `from typing import Any`\n\n### 2. AttributeError: module 'torch.backends.cuda' has no attribute 'xformers_sdp_enabled'\n**File**: `model_loader.py`, `tts.py`\n**Cause**: Older PyTorch version does not support certain SDPA attributes\n**Fix**: Wrapped SDPA backend checks with try/except\n\n### 3. SDPA Function Name Error\n**File**: `model_loader.py`, `tts.py`\n**Cause**: Used incorrect function names (e.g., `flash_sdp_enabled()` instead of `enable_flash_sdp()`)\n**Fix**: Corrected function names\n```python\n# Wrong\ntorch.backends.cuda.flash_sdp_enabled()\n# Correct\ntorch.backends.cuda.enable_flash_sdp(False)\n```\n\n### 4. Token Type Mismatch\n**Error Message**: `Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.HalfTensor instead`\n\n**File**: `cosyvoice.py`\n**Cause**: Token and prompt_token were converted to float16, but embedding layers require integer types\n**Fix**: Keep token and prompt_token as integer types, only convert feature tensors to model precision\n\n### 5. dtype Hardcoding Issue\n**File**: `generator.py`\n**Cause**: `_f02uv` method hardcoded `torch.float32`, causing mismatch with FP16 model\n**Fix**: Use `f0.dtype` instead of hardcoded type\n\n### 6. RuntimeError: Unsupported dtype Half\n**Error Message**: `RuntimeError: Unsupported dtype Half`\n**File**: `tts.py`, `frontend.py`\n**Cause**: `torchaudio.compliance.kaldi.fbank` only supports float32\n**Fix**: Keep audio as float32 for feature extraction, only convert features to model precision\n\n### 7. resample_audio Does Not Support float16\n**Error Message**: `expected scalar type Half but found Float`\n**File**: `tokenizer.py`\n**Cause**: `torchaudio.transforms.Resample` only supports float32\n**Fix**: Convert to float32 before resampling, restore original precision after completion\n\n### 8. torchaudio.save Does Not Support float16\n**Error Message**: `ValueError: Unsupported dtype for wav: torch.float16`\n**File**: `tokenizer.py`\n**Cause**: `torchaudio.save` only supports float32 format for WAV files\n**Fix**: Temporarily convert to float32 before saving\n\n## List of Modified Files\n\n### 1. tts.py\n**Changes**:\n- Added GPU compute capability detection\n- Configured SDPA backends (for SM 7.5 GPU)\n- Modified audio preprocessing pipeline to keep float32 for feature extraction\n- Added detailed debug logging\n\n**Key Code**:\n```python\ndef preprocess_prompt_wav(self, prompt_wav_path : str):\n    prompt_wav, prompt_wav_sr = torchaudio.load(prompt_wav_path)\n    \n    # Keep audio as float32 for preprocessing\n    model_dtype = self.llm.dtype if hasattr(self.llm, 'dtype') else next(self.llm.parameters()).dtype\n    \n    # Audio preprocessing (keep as float32)\n    if prompt_wav.shape[0] > 1:\n        prompt_wav = prompt_wav.mean(dim=0, keepdim=True)\n    \n    norm = torch.max(torch.abs(prompt_wav), dim=1, keepdim=True)[0]\n    if norm > 0.6:\n        prompt_wav = prompt_wav / norm * 0.6\n    \n    # Feature extraction (using float32)\n    speech_feat, speech_feat_len = self.cosy_model.frontend.extract_speech_feat(\n        prompt_wav, prompt_wav_sr\n    )\n    \n    # Convert features to model precision\n    speech_feat = speech_feat.to(model_dtype)\n    \n    speech_embedding = self.cosy_model.frontend.extract_spk_embedding(\n        prompt_wav, prompt_wav_sr\n    )\n    speech_embedding = speech_embedding.to(model_dtype)\n    \n    # Convert audio to model precision for tokenization\n    prompt_wav_model_dtype = prompt_wav.to(model_dtype)\n    vq0206_codes, vq02_codes_ori, vq06_codes_ori = self.audio_tokenizer.wav2token(prompt_wav_model_dtype, prompt_wav_sr)\n```\n\n### 2. tokenizer.py\n**Changes**:\n- Added dtype conversion for audio resampling\n- Added dtype conversion for audio saving\n\n**Key Code**:\n```python\ndef preprocess_wav(self, audio, sample_rate, enable_trim=True, energy_norm=True):\n    # Save original dtype\n    original_dtype = audio.dtype\n    audio_float32 = audio.to(torch.float32) if original_dtype != torch.float32 else audio\n    \n    audio = resample_audio(audio_float32, sample_rate, 16000)\n    \n    if energy_norm:\n        audio = energy_norm_fn(audio)\n    \n    if enable_trim:\n        audio = audio.cpu().numpy().squeeze(0)\n        audio = trim_silence(audio, 16000)\n        audio = torch.from_numpy(audio)\n        audio = audio.unsqueeze(0)\n    \n    # Restore original dtype\n    if original_dtype != torch.float32:\n        audio = audio.to(original_dtype)\n    \n    return audio\n\ndef get_vq02_code(self, audio, session_id=None, is_final=True):\n    # Convert to float32 for saving\n    audio_float32 = audio.to(torch.float32) if audio.dtype != torch.float32 else audio\n    torchaudio.save(tmp_path, audio_float32, 16000, format=\"wav\")\n```\n\n### 3. model_loader.py\n**Changes**:\n- Added GPU compute capability detection\n- Configured SDPA backend priority\n- Added detailed debug logging\n\n**Key Code**:\n```python\n# Configure SDPA backends\ntry:\n    major, minor = torch.cuda.get_device_capability()\n    compute_capability = major + minor * 0.1\n    \n    if compute_capability < 8.0:\n        # For older GPUs (like 2080 Ti, SM 7.5), disable flash_attention\n        try:\n            torch.backends.cuda.enable_flash_sdp(False)\n            torch.backends.cuda.enable_mem_efficient_sdp(True)\n            try:\n                torch.backends.cuda.enable_xformers_sdp(True)\n            except AttributeError:\n                pass\n        except AttributeError:\n            pass\nexcept Exception as e:\n    print(f\"Warning: Failed to configure SDPA backends: {e}\")\n```\n\n### 4. cosyvoice.py\n**Changes**:\n- Fixed token type conversion issues\n- Added detailed dtype debug logging\n- Ensured HiFTGenerator components use correct dtype\n\n**Key Code**:\n```python\ndef token2wav_nonstream(self, token, prompt_token, prompt_feat, embedding):\n    # Keep token and prompt_token as integer types\n    token, prompt_token, prompt_feat, embedding = map(\n        lambda ts: ts.to(self.device),\n        (token, prompt_token, prompt_feat, embedding),\n    )\n    \n    # Only convert feature tensors to model precision\n    prompt_feat = prompt_feat.to(self.dtype)\n    embedding = embedding.to(self.dtype)\n```\n\n### 5. generator.py\n**Changes**:\n- Fixed dtype hardcoding issue in `_f02uv` method\n\n**Key Code**:\n```python\ndef _f02uv(self, f0):\n    # Use f0.dtype instead of hardcoded torch.float32\n    uv = torch.FloatTensor(f0.shape[0], f0.shape[1]).to(f0.device)\n    uv = uv.type(type(f0.dtype))\n```\n\n## Performance Optimization Strategies\n\n### 1. Precision Management Strategy\nAdopt \"compromise approach\" for dtype conversion:\n```\n[FP16 Input] -> [Convert to FP32] -> [Perform Fbank High-Precision Computation] -> [Convert Back to FP16]\n```\n\n**Advantages**:\n- Compatibility: Solves function not supporting FP16 issues\n- Performance: Temporary conversion adds almost no overhead\n- Quality: Complex computations done in FP32, ensuring audio quality\n\n### 2. Attention Mechanism Optimization\n- **Transformers < 4.54**: Use eager attention\n- **Transformers >= 4.54**: Use SDPA (if available)\n- **Older GPU (SM < 8.0)**: Disable flash_attention, use memory_efficient_attention\n\n### 3. GPU Compute Capability Adaptation\n```python\nif compute_capability < 8.0:\n    # Force use of FP16 (does not support BF16)\n    torch_dtype = torch.float16\n    torch.backends.cuda.enable_flash_sdp(False)\n    torch.backends.cuda.enable_mem_efficient_sdp(True)\nelse:\n    # Supports BF16\n    torch_dtype = torch.bfloat16\n```\n\n## Current Status\n\n### Resolved Issues\n‚úÖ Type annotation import error\n‚úÖ SDPA attribute compatibility issues\n‚úÖ SDPA function name errors\n‚úÖ Token type mismatch\n‚úÖ dtype hardcoding issues\n‚úÖ kaldi.fbank dtype not supported\n‚úÖ resample_audio dtype not supported\n‚úÖ torchaudio.save dtype not supported\n\n### Pending Issues\n‚ùå **Performance discrepancy still exists**: StepAudioEditXAudioEditorNode is still slower than StepAudioEditXEngineNode\n‚ùå **xFormers cannot be used**: Limited by older PyTorch version, cannot use xFormers acceleration\n‚ùå **Transformers version limitation**: Current version 4.51 limits SDPA usage\n\n## Suggested Future Optimization Directions\n\n### 1. Upgrade Dependencies\n```bash\npip install --upgrade transformers>=4.54\npip install --upgrade torch>=2.0\n```\n\n### 2. Performance Analysis\nFurther analysis needed for performance differences between the two nodes:\n- Check if different attention mechanisms are being used\n- Analyze differences in inference pipeline\n- Check for unnecessary dtype conversions\n\n### 3. Code Optimization\n- Unify implementation of both nodes\n- Reduce unnecessary tensor copying\n- Optimize memory usage\n\n## Debug Log Examples\n\n### Successful Log Output\n```\nüí° DEBUG: Loaded audio dtype: torch.float32, shape: torch.Size([1, 246461]), sr: 24000\nüí° DEBUG: Model dtype: torch.float16\nüí° DEBUG: After normalization - audio dtype: torch.float32\nüí° DEBUG: speech_feat dtype: torch.float32, shape: torch.Size([1, 513, 80])\nüí° DEBUG: Converted speech_feat to model dtype: torch.float16\nüí° DEBUG: speech_embedding dtype: torch.float32, shape: torch.Size([1, 192])\nüí° DEBUG: Converted speech_embedding to model dtype: torch.float16\n```\n\n### SDPA Configuration Log\n```\nüí° DEBUG: SDPA settings:\n   Configuring SDPA backends for compute capability < 8.0\n   flash_sdp_enabled: False\n   mem_efficient_sdp_enabled: True\n   xformers_sdp_enabled: N/A (old PyTorch)\n   eager_sdp_enabled: N/A (old PyTorch)\n   allow_tf32: False\n```\n\n## Summary\n\nThis fix primarily addressed dtype compatibility issues. By adopting the \"compromise approach\" (FP16 -> FP32 -> FP16), we successfully resolved multiple functions not supporting FP16. However, the root cause of the performance discrepancy has not yet been found and requires further analysis of the implementation differences between the two nodes.\n\n**Key Findings**:\n1. Audio preprocessing and feature extraction need to be done in FP32\n2. Model inference can be done in FP16 to improve performance\n3. Older versions of PyTorch and Transformers limit the use of advanced optimization features\n4. GPU compute capability (SM 7.5) limits certain optimizations (such as flash_attention)\n\n**Recommendations**:\n1. Upgrade PyTorch and Transformers to latest versions\n2. Deeply analyze the performance differences between the two nodes\n3. Consider using performance analysis tools (like PyTorch Profiler) to locate bottlenecks\n4. Unify the implementation of both nodes to ensure the same optimization strategies are used\n\n---\n\n**Document Generated**: 2026-01-11\n**GPU**: NVIDIA GeForce RTX 2080 Ti (SM 7.5)\n**Status**: Partially fixed, performance issues pending resolution","createdAt":"2026-01-11T15:35:01Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/224#issuecomment-3734827571","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":224,"title":"[Bug]StepAudioEditXAudioEditorNode bug","updatedAt":"2026-01-11T15:35:01Z"},{"comments":[{"id":"IC_kwDOPZi2kc7dUfnz","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Since I've never had this problem in my end, I can't help you if you don't follow the bug template. Post the full complete information and I might be able to help.","createdAt":"2026-01-06T05:10:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/222#issuecomment-3713137139","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7fmB4x","author":{"login":"japanvik"},"authorAssociation":"NONE","body":"The 'infer' in line 254 for engines/ft_tts/infer/utils_infer.py is redundant since dunder 'package' points to 'engines.f5_tts.infer' already when the module is imported.\n```\n    if vocab_file == \"\":\n        #vocab_file = str(files(__package__ or \"f5_tts\").joinpath(\"infer/examples/vocab.txt\"))\n        vocab_file = str(files(__package__ or \"f5_tts\").joinpath(\"examples/vocab.txt\"))\n```\nRemoving it as above worked for me on the F5 base model.\nI'm on nightly ComfyUI.","createdAt":"2026-01-14T19:40:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/222#issuecomment-3751288369","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7f_UHN","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Fixed in v4.16.11\n\nThe issue was in `engines/f5_tts/infer/utils_infer.py:254` where the vocab.txt path had a redundant `infer/` prefix.\n\n**Root cause:** When `__package__` = `'engines.f5_tts.infer'`, the code was generating:\n```\n/path/to/engines/f5_tts/infer/infer/examples/vocab.txt  ‚ùå\n```\n\nInstead of the correct path:\n```\n/path/to/engines/f5_tts/infer/examples/vocab.txt  ‚úÖ\n```\n\n**Fixed by:** Removing the redundant `\"infer/\"` prefix since `files(__package__)` already points to the `infer` directory.\n\nThis affected users loading E2-TTS models from HuggingFace or using fallback model loading paths without explicit vocab_file specification.","createdAt":"2026-01-16T03:13:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/222#issuecomment-3757916621","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7i1ebI","author":{"login":"0x164C9DFC"},"authorAssociation":"NONE","body":"Somehow, the Huggingface repository does not include the vocab.txt, when looking at the shell output:\n```\nüì• Downloading E2TTS_Base/vocab.txt directly (no cache)\n‚ùå Download failed for E2TTS_Base/vocab.txt: 404 Client Error: Not Found for url: https://huggingface.co/SWivid/E2-TTS/resolve/main/E2TTS_Base/vocab.txt\n‚ö† Some files failed to download: ['vocab.txt']\n\n```","createdAt":"2026-01-27T14:52:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/222#issuecomment-3805669064","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7i9SF4","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> Somehow, the Huggingface repository does not include the vocab.txt, when looking at the shell output:\n> \n> ```\n> üì• Downloading E2TTS_Base/vocab.txt directly (no cache)\n> ‚ùå Download failed for E2TTS_Base/vocab.txt: 404 Client Error: Not Found for url: https://huggingface.co/SWivid/E2-TTS/resolve/main/E2TTS_Base/vocab.txt\n> ‚ö† Some files failed to download: ['vocab.txt']\n> ```\n\nI don't think E2 has it's own vocab file. At this moment I don't remember what the code will do, but it will probably use the normal f5 vocab txt. I think.","createdAt":"2026-01-27T21:51:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/222#issuecomment-3807715704","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIGsg","name":"needs-clarification","description":"","color":"fbca04"}],"number":222,"title":"Incorrect file location reference","updatedAt":"2026-01-27T21:51:58Z"},{"comments":[{"id":"IC_kwDOPZi2kc7c4YDA","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Tentative Fix Available - Please Test\n\nI've implemented a fix for the PyYAML compatibility error you're experiencing. The issue was that newer PyYAML versions (6.0+) removed the `max_depth` attribute from YAML loaders, which the bundled `hyperpyyaml` library expects.\n\n**What was changed:**\n- Added monkey-patch to restore `max_depth` attribute to YAML loaders before hyperpyyaml is imported\n- Ensures compatibility with PyYAML 6.0+ versions\n- Should resolve the `'Loader' object has no attribute 'max_depth'` error\n\n**Please test:**\n1. Update to version 4.16.4\n2. Try loading CosyVoice3 model again\n3. Let me know if the initialization error is resolved\n\n**File modified:**\n- `engines/cosyvoice/impl/cosyvoice/cli/cosyvoice.py` (lines 19-28)\n\nThis is a tentative fix - your testing will help confirm if it resolves the issue completely.","createdAt":"2026-01-02T16:50:46Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/220#issuecomment-3705766080","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7c5jEW","author":{"login":"Vollond"},"authorAssociation":"NONE","body":"Traceback (most recent call last):\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/unified/tts_text_node.py\", line 1062, in generate_speech\n    result = engine_instance.generate_tts_audio(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/unified/tts_text_node.py\", line 507, in generate_tts_audio\n    audio, generation_info = processor.process_text(\n                             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/engines/processors/cosyvoice_processor.py\", line 359, in process_text\n    segment_audio = self._generate_audio_segment(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/engines/processors/cosyvoice_processor.py\", line 403, in _generate_audio_segment\n    return self.adapter.generate(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/engines/adapters/cosyvoice_adapter.py\", line 214, in generate\n    audio = self.engine.generate(\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/engines/cosyvoice/cosyvoice.py\", line 513, in generate\n    return self.generate_zero_shot(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/engines/cosyvoice/cosyvoice.py\", line 236, in generate_zero_shot\n    self._ensure_model_loaded()\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/engines/cosyvoice/cosyvoice.py\", line 179, in _ensure_model_loaded\n    self._cosyvoice = unified_model_interface.load_model(self._model_config)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/utils/models/unified_model_interface.py\", line 156, in load_model\n    wrapper = tts_model_manager.load_model(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/utils/models/comfyui_model_wrapper/model_manager.py\", line 253, in load_model\n    model = model_factory_func(config)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/ComfyUI/custom_nodes/TTS-Audio-Suite/utils/models/unified_model_interface.py\", line 1114, in cosyvoice_factory\n    raise RuntimeError(f\"Failed to load CosyVoice3 model: {e}\")\nRuntimeError: Failed to load CosyVoice3 model: 'Loader' object has no attribute 'max_depth'\n","createdAt":"2026-01-02T19:22:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/220#issuecomment-3706073366","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7c9TZV","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Enhanced Fix Applied - Please Test v4.16.5+\n\nI've applied a more comprehensive fix for the PyYAML compatibility issue. The patch is now applied across all CosyVoice entry points to ensure the yaml module is patched before any hyperpyyaml imports.\n\n**Files patched (v4.16.5):**\n- `engines/cosyvoice/cosyvoice.py` (main engine wrapper)\n- `engines/adapters/cosyvoice_adapter.py` (adapter)\n- `engines/processors/cosyvoice_processor.py` (processor)\n- `nodes/cosyvoice/cosyvoice_srt_processor.py` (SRT processor)\n- `nodes/engines/cosyvoice_engine_node.py` (engine configuration node)\n- `engines/cosyvoice/impl/cosyvoice/cli/cosyvoice.py` (bundled implementation)\n\n**Please test:**\n1. Update to version 4.16.5 or later\n2. Try loading CosyVoice3 model again\n3. Verify the `'Loader' object has no attribute 'max_depth'` error is resolved\n\nThe fix adds the missing `max_depth` attribute to PyYAML loaders before hyperpyyaml is imported anywhere in the loading chain.","createdAt":"2026-01-03T13:31:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/220#issuecomment-3707057749","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":220,"title":"[Bug] RuntimeError: Failed to load CosyVoice3 model: 'Loader' object has no attribute 'max_depth'","updatedAt":"2026-01-03T13:31:06Z"},{"comments":[{"id":"IC_kwDOPZi2kc7c4Y4Y","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"This is not enough to go on. What is your FULL initialization log?","createdAt":"2026-01-02T16:52:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/219#issuecomment-3705769496","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIGsg","name":"needs-clarification","description":"","color":"fbca04"}],"number":219,"title":"Missing nodes.","updatedAt":"2026-01-02T16:52:30Z"},{"comments":[{"id":"IC_kwDOPZi2kc7ctqLA","author":{"login":"trollver9000"},"authorAssociation":"NONE","body":"I agreee, the whole txt setup is a PITA and we dont use THAT many speakers at once, maybe 2-4 max","createdAt":"2025-12-31T22:03:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3702956736","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7c4u_L","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I don't get this request to be honest. The alias txt file is completely optional. What is this PITA experience you are referring to? You can just toss an audio on the voices folder and use that audio name as a character tag [AudioName] and if the engine does not require a .txt transcription it should just work. \n\nAdding input on the TTS Text node and on the SRT node would be very confusing for most users. I don't think this makes sense. \n\nRemember the character switching system is a custom system made by me. IF ANY engine has native speakers system, there will be a input for thos extra narrators on the engine. Like Higg2 and VibeVoice. Maybe if you don't like my character switching system, you can use those.\n\nIf I understand correctly, what you guys want is a way to use my character switching system without messing up with external files. MAYBE I could think of a way to input audio files into a node that automatically add those to the voice folder, IDK. I would have to think of a pratical way. But I won't add another input to the unified TTS Text or TTS SRT nodes.\n\nAnd just because you @trollver9000 use 2-4 speakers doesn't mean all the other users (me included) use only that many.","createdAt":"2026-01-02T17:25:48Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3705860043","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7c4ywR","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"And just to correct myself after tossing the audio file in the voices folder you just need to press R inside comfyui, and your character voices will be updated. That is it. You don't even need to reboot comfyui anymore.","createdAt":"2026-01-02T17:33:52Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3705875473","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7c6uRr","author":{"login":"qualar"},"authorAssociation":"NONE","body":"Look at the dialog node here https://github.com/filliptm/ComfyUI_Fill-ChatterBox/blob/main/assets/workflow_preview.png\n\nBasically you have a load audio node for all your reference speakers and point those to the chatterbox node.  \n\nMust confess though I was not aware that your node picked up speakers from your folders.  If that is the case why allow a single input.  ","createdAt":"2026-01-02T22:37:16Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3706381419","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7c9Rtc","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> Look at the dialog node here https://github.com/filliptm/ComfyUI_Fill-ChatterBox/blob/main/assets/workflow_preview.png\n> \n> Basically you have a load audio node for all your reference speakers and point those to the chatterbox node.\n> \n> Must confess though I was not aware that your node picked up speakers from your folders. If that is the case why allow a single input.\n\nBecause a single speaker is a requirement for the native function of most models that natively supports only one speaker. The character switching is a custom-made way of switching voices. ","createdAt":"2026-01-03T13:18:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3707050844","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7dRFcd","author":{"login":"trollver9000"},"authorAssociation":"NONE","body":"its just convenience thing- i dont wantr to \"r\" .and wait each time i want new voice. i wanna load myself and plug them in asap after i record them.\nIm not a fan of comfy not refreshing default folders automatically each time theyre updated, you have to press \"r\" and wait and it often juts does not work for many nodes, - you have to restart comfy.The r thingy shouldnt exist, feels like last minute addon.\nI know its possible to do inputs dynamically and reduce the amount of inputs by changing node values, ive seen several nodes that can change input amounts on the node itself in realtime and autorefresh.This should be very common in a lot of nodes.But oh well, i  like lazy and simple.\nAnd yes different ppl do different requests but i believe in simple and dynamic and fast.having to \"r\" and wait - it is inconvenience.","createdAt":"2026-01-05T22:04:10Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3712243485","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7dUces","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Well the \"r\" thing was a very recent addition by me, focused on convenience, since someone asked nicely and it made sense. Before that, you needed to reboot. If that is still not convenient enough, I'm sorry, feel free to open a PR.\n\nI won't be adding this input thing in the near future, as it's not on my priority list. But thanks for the suggestion. \n\nI won't be closing this because it's a valid suggestion that I might give it more though in the future.","createdAt":"2026-01-06T05:03:07Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3713124268","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7dhmve","author":{"login":"trollver9000"},"authorAssociation":"NONE","body":"the reason i dont like it is that very often when i press r - it stops and refreshes everything blocking me out of comfy because i accidentally pressed r , IMO it should be with modifier , not just r.\nI wouldnt add extra inputs too cause you have a couple engines that would need rework, its too late for that change i suspect without ton of work.","createdAt":"2026-01-06T22:20:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3716574174","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7dj3bv","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> the reason i dont like it is that very often when i press r - it stops and refreshes everything blocking me out of comfy because i accidentally pressed r , IMO it should be with modifier , not just r. I wouldnt add extra inputs too cause you have a couple engines that would need rework, its too late for that change i suspect without ton of work.\n\nExactly, I would need to work on supporting it on all 8 engines rewriting a lot of code, and for little gain since this functionality already exists. About the R+modifier, I don't think its possible, but you can change to any other key you like. It's a comfyui setting \n\n<img width=\"1868\" height=\"1506\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/991eeefa-34aa-4559-a8ec-94023970efbe\" />","createdAt":"2026-01-07T03:20:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/217#issuecomment-3717166831","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJLHnXQ","name":"low-priority","description":"","color":"f9d0c4"},{"id":"LA_kwDOPZi2kc8AAAACJRCLwg","name":"not-planned","description":"","color":"d93f0b"}],"number":217,"title":"[REQUEST] INPUTS FOR MULTIPLE AUDIO FILES ON THE TTS TEXT NODE","updatedAt":"2026-01-07T03:20:27Z"},{"comments":[{"id":"IC_kwDOPZi2kc7cRFDg","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Can you try updating the node? You are running an old version.","createdAt":"2025-12-29T05:28:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3695464672","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cRhZC","author":{"login":"avogatro"},"authorAssociation":"NONE","body":"l tried the newest version 4.15.17,  is even worse with 'NoneType' object has no attribute 'infer'\n\n`‚ùå IndexTTS-2 processor error: 'NoneType' object has no attribute 'infer'\nTraceback (most recent call last):\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\processors\\index_tts_processor.py\", line 514, in process_text\n    result = self.pause_processor.generate_audio_with_pauses(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\text\\pause_processor.py\", line 126, in generate_audio_with_pauses\n    audio = tts_generate_func(content, **generation_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\processors\\index_tts_processor.py\", line 510, in tts_generate_with_params\n    return tts_generate_func(text_content, segment_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\processors\\index_tts_processor.py\", line 432, in tts_generate_func\n    result = self.adapter.generate(\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\adapters\\index_tts_adapter.py\", line 281, in generate\n    audio = self.engine.generate(\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\index_tts\\index_tts.py\", line 333, in generate\n    result = self._tts_engine.infer(\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\models\\comfyui_model_wrapper\\base_wrapper.py\", line 398, in __getattr__\n    return getattr(self.model, name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'infer'\n‚ùå TTS Text generation failed: not enough values to unpack (expected 2, got 1)\nTraceback (most recent call last):\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\nodes\\unified/tts_text_node.py\", line 931, in generate_speech\n    audio_result, chunk_info = engine_instance.process_text(\n    ^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: not enough values to unpack (expected 2, got 1)`\nI want the new tag feature for emotion and speed.\nI am currently trying to install separate conda env py313 and all packages.\n\nEven if this works, have to install a specific version of python, cuda, pytorch to make this work, is not very fun...","createdAt":"2025-12-29T06:27:57Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3695580738","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cRi1v","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"It should be working just fine in python 3.12. Are you sure you don't have any other conflicting nodes? Can you post your full initialization comfyui log so I can check it?","createdAt":"2025-12-29T06:32:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3695586671","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cRjMC","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"You did... hum, maybe it's the anaconda environment. I have never tested with it...","createdAt":"2025-12-29T06:33:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3695588098","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cRjpA","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Did you run the install.py inside your environment?","createdAt":"2025-12-29T06:34:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3695589952","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cRlg0","author":{"login":"avogatro"},"authorAssociation":"NONE","body":"install.py let me try","createdAt":"2025-12-29T06:40:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3695597620","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cRofp","author":{"login":"avogatro"},"authorAssociation":"NONE","body":"Ok I changed version to 4.15.17.\ninstall.py show [+] Installation completed successfully!\nand I restarted my job. still the same error:\n\n`\n‚ùå IndexTTS-2 processor error: IndexTTS-2 dependencies not available. Error:\n‚ùå External IndexTTS installation detected!\n\n   Found at: E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\index_tts\\indextts\\__init__.py\n\n   This conflicts with our bundled IndexTTS-2 engine and causes import errors.\n\n   üîß SOLUTION: Please uninstall the external version:\n      pip uninstall indextts\n\n   Then restart ComfyUI.\n\n   Our bundled version has all required dependencies and will work perfectly.\n\nTraceback (most recent call last):\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 696, in index_tts_factory\n    raise e\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 680, in index_tts_factory\n    raise ImportError(f\"\"\"\nImportError:\n‚ùå External IndexTTS installation detected!\n\n   Found at: E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\index_tts\\indextts\\__init__.py\n\n   This conflicts with our bundled IndexTTS-2 engine and causes import errors.\n\n   üîß SOLUTION: Please uninstall the external version:\n      pip uninstall indextts\n\n   Then restart ComfyUI.\n\n   Our bundled version has all required dependencies and will work perfectly.\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\processors\\index_tts_processor.py\", line 514, in process_text\n    result = self.pause_processor.generate_audio_with_pauses(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\text\\pause_processor.py\", line 126, in generate_audio_with_pauses\n    audio = tts_generate_func(content, **generation_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\processors\\index_tts_processor.py\", line 510, in tts_generate_with_params\n    return tts_generate_func(text_content, segment_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\processors\\index_tts_processor.py\", line 432, in tts_generate_func\n    result = self.adapter.generate(\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\adapters\\index_tts_adapter.py\", line 281, in generate\n    audio = self.engine.generate(\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\index_tts\\index_tts.py\", line 216, in generate\n    self._ensure_model_loaded()\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\index_tts\\index_tts.py\", line 156, in _ensure_model_loaded\n    self._tts_engine = unified_model_interface.load_model(self._model_config)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 156, in load_model\n    wrapper = tts_model_manager.load_model(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\models\\comfyui_model_wrapper\\model_manager.py\", line 253, in load_model\n    model = model_factory_func(config)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 728, in index_tts_factory\n    raise ImportError(f\"IndexTTS-2 dependencies not available. Error: {e}\")\nImportError: IndexTTS-2 dependencies not available. Error:\n‚ùå External IndexTTS installation detected!\n\n   Found at: E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\engines\\index_tts\\indextts\\__init__.py\n\n   This conflicts with our bundled IndexTTS-2 engine and causes import errors.\n\n   üîß SOLUTION: Please uninstall the external version:\n      pip uninstall indextts\n\n   Then restart ComfyUI.\n\n   Our bundled version has all required dependencies and will work perfectly.\n\n‚ùå TTS Text generation failed: not enough values to unpack (expected 2, got 1)\nTraceback (most recent call last):\n  File \"E:\\ComfiUI_conda\\custom_nodes\\tts_audio_suite\\nodes\\unified/tts_text_node.py\", line 931, in generate_speech\n    audio_result, chunk_info = engine_instance.process_text(\n    ^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: not enough values to unpack (expected 2, got 1)\nPrompt executed in 5.45 seconds\n`","createdAt":"2025-12-29T06:51:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3695609833","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cWEA2","author":{"login":"avogatro"},"authorAssociation":"NONE","body":"I use conda to create python 3.13 env, switched now to the nightly build.","createdAt":"2025-12-29T15:06:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3696771126","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7c4Py6","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"We've implemented a **TENTATIVE FIX** for this issue in version **4.16.2**.\n\n## What was the problem?\n\nThe detection logic for external IndexTTS installations was checking if the path contained keywords like `conda`, `pip`, `site-packages`, or `dist-packages`. Since your ComfyUI is installed in `E:\\ComfiUI_conda\\`, the bundled IndexTTS path also contained \"conda\", triggering a false positive.\n\n## What we changed\n\nReplaced keyword-based detection with path-based detection:\n- Now checks if the imported `indextts` module is actually located **inside** the TTS Audio Suite directory structure\n- If it's inside `custom_nodes/tts_audio_suite/engines/index_tts/indextts/` ‚Üí bundled version (allowed)\n- If it's outside (in site-packages, etc.) ‚Üí external installation (blocked)\n\n## Please test this fix\n\n1. Update TTS Audio Suite to version 4.16.2\n2. Restart ComfyUI\n3. Try using the IndexTTS-2 engine\n4. Let us know if the error is resolved\n\nThe fix should work regardless of whether your ComfyUI directory contains \"conda\", \"pip\", or similar keywords in the path.","createdAt":"2026-01-02T16:31:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3705732282","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7gwl1c","author":{"login":"patrickwilliamwalker"},"authorAssociation":"NONE","body":"I've been hit with this as well, though on the Linux environment.\n\nOne of the things I've noticed is that it's telling me to run pip install -r requirements.txt.  I've run it, yet I still get the same missing files error on ComfyUI startup:\n\n> \n>üìã System Dependencies (background check):\n>  ‚ö†Ô∏è Engine dependencies missing:\n>      F5-TTS:\n>       ‚Ä¢ cached-path (import: cached_path)\n>     Higgs Audio 2:\n>        ‚Ä¢ descript-audio-codec (import: dac)\n>        ‚Ä¢ vector-quantize-pytorch (import: vector_quantize_pytorch)\n>      RVC Voice Conversion:\n>        ‚Ä¢ onnxruntime-gpu (import: onnxruntime)\n>        ‚Ä¢ torchcrepe (import: torchcrepe)\n>   üîß Fix: pip install -r requirements.txt\n>   ‚ÑπÔ∏è Engine nodes will fail without dependencies\n\nI went through and manually installed the missing dependencies and cleared out the errors.  A simple workflow been working fine so far.","createdAt":"2026-01-20T03:16:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3770834268","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7hACE2","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> I've been hit with this as well, though on the Linux environment.\n> \n> One of the things I've noticed is that it's telling me to run pip install -r requirements.txt. I've run it, yet I still get the same missing files error on ComfyUI startup:\n> \n> > üìã System Dependencies (background check):\n> > ‚ö†Ô∏è Engine dependencies missing:\n> > F5-TTS:\n> > ‚Ä¢ cached-path (import: cached_path)\n> > Higgs Audio 2:\n> > ‚Ä¢ descript-audio-codec (import: dac)\n> > ‚Ä¢ vector-quantize-pytorch (import: vector_quantize_pytorch)\n> > RVC Voice Conversion:\n> > ‚Ä¢ onnxruntime-gpu (import: onnxruntime)\n> > ‚Ä¢ torchcrepe (import: torchcrepe)\n> > üîß Fix: pip install -r requirements.txt\n> > ‚ÑπÔ∏è Engine nodes will fail without dependencies\n> \n> I went through and manually installed the missing dependencies and cleared out the errors. A simple workflow been working fine so far.\n\nI should fix that message. requirements.txt is not really where all dependencies get installed but with the install.py script. ","createdAt":"2026-01-20T20:50:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3774882102","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7i1KFC","author":{"login":"0x164C9DFC"},"authorAssociation":"NONE","body":"In 4.17.0, IndexTTS-2 doesn't play nice with a python 3.13 env and Transformers 5.0.0\n\n```\nüîÑ IndexTTS-2: Initializing engine (first run may take 2-3 minutes to load models)...\n   Loading: QwenEmotion ‚Üí GPT ‚Üí Semantic Codec ‚Üí S2Mel ‚Üí CampPlus ‚Üí BigVGAN...\n‚ùå IndexTTS-2 processor error: IndexTTS-2 dependencies not available. Error: cannot import name 'OffloadedCache' from 'transformers.cache_utils' \n```","createdAt":"2026-01-27T14:37:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3805585730","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7i9Ob1","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@0x164C9DFC \n\nplease don't hijack another persons' bug report, open a new one so we can check your bug there, thanks!!","createdAt":"2026-01-27T21:47:44Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3807700725","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7mme6K","author":{"login":"patrickwilliamwalker"},"authorAssociation":"NONE","body":"I got hit again with after I did a complete ComfyUI reinstall.\n\n\"ValueError: not enough values to unpack (expected 2, got 1)\" \n\nNow, the only error I saw (and it was quite buried and almost missed it):\n\n\"ModuleNotFoundError: No module named 'torchcodec'\", so I did a \"pip install torchcodec\" then restarted ComfyUI.\n\n","createdAt":"2026-02-09T01:44:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/213#issuecomment-3868847754","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":213,"title":"[Bug]","updatedAt":"2026-02-09T01:44:41Z"},{"comments":[{"id":"IC_kwDOPZi2kc7b3w0B","author":{"login":"3272118850"},"authorAssociation":"NONE","body":"Even after installing flash attention, the generation still fails, and the runtime error remains the same.\n\n<img width=\"922\" height=\"112\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/786a3a60-4a29-48da-9c4e-1dd345ce8208\" />\n\n<img width=\"1106\" height=\"573\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cc411af0-2d26-43bb-ba7d-2cd4793dcf40\" />","createdAt":"2025-12-24T06:30:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/210#issuecomment-3688828161","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cPsBX","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Fixed in v4.15.16\n\nThe crash issue has been resolved. The Russian model download was failing because the files were located in a nested subdirectory that wasn't being accessed correctly.\n\n### What was fixed\n- Corrected the download path from `ru/` to `ru/chatterbox-ru-t3k/`\n- Russian model now downloads successfully (all 5 required files)\n- No more crashes during generation\n\n### Installation\nUpdate to v4.15.16 and the Russian model will download correctly when you use ChatterBox TTS Engine with Russian language.\n\n### Note about audio quality\nThe community Russian model for classic ChatterBox (`fron1runner/chatterbox-ru-t3k`) is an experimental fine-tune with no quality documentation. Some users report the output sounds unusual or English-like.\n\n**Recommendation:** For better Russian TTS quality, use the **ChatterBox Official 23-Lang engine** instead, which has well-tested Russian support built in.\n\nTo switch:\n1. Use the `‚öôÔ∏è ChatterBox Official 23-Lang Engine` node instead of `‚öôÔ∏è ChatterBox TTS Engine`\n2. Set language to Russian\n3. Much better quality output\n\nLet me know if you have any issues with v4.15.16!","createdAt":"2025-12-28T22:29:52Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/210#issuecomment-3695099991","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cQm3x","author":{"login":"3272118850"},"authorAssociation":"NONE","body":"> ## Fixed in v4.15.16\n> The crash issue has been resolved. The Russian model download was failing because the files were located in a nested subdirectory that wasn't being accessed correctly.\n> \n> ### What was fixed\n> * Corrected the download path from  to `ru/``ru/chatterbox-ru-t3k/`\n> * Russian model now downloads successfully (all 5 required files)\n> * No more crashes during generation\n> \n> ### Installation\n> Update to v4.15.16 and the Russian model will download correctly when you use ChatterBox TTS Engine with Russian language.\n> \n> ### Note about audio quality\n> The community Russian model for classic ChatterBox () is an experimental fine-tune with no quality documentation. Some users report the output sounds unusual or English-like.`fron1runner/chatterbox-ru-t3k`\n> \n> **Recommendation:** For better Russian TTS quality, use the **ChatterBox Official 23-Lang engine** instead, which has well-tested Russian support built in.\n> \n> To switch:\n> \n> 1. Use the  node instead of `‚öôÔ∏è ChatterBox Official 23-Lang Engine``‚öôÔ∏è ChatterBox TTS Engine`\n> 2. Set language to Russian\n> 3. Much better quality output\n> \n> Let me know if you have any issues with v4.15.16!\n\nThank you for the update, author. I can download it now, but another issue has come up. After downloading the model, when I click to run it, it still crashes.\n\ngot prompt\n[TimbreAudioLoader] Â∑≤Âä†ËΩΩ 58 ‰∏™Èü≥È¢ëÊñá‰ª∂\n[TimbreAudioLoader] Â∑≤Âä†ËΩΩ 58 ‰∏™Èü≥È¢ëÊñá‰ª∂\n[TimbreAudioLoader] Â∑≤Âä†ËΩΩ 58 ‰∏™Èü≥È¢ëÊñá‰ª∂\n[TimbreAudioLoader] Â∑≤Âä†ËΩΩ 58 ‰∏™Èü≥È¢ëÊñá‰ª∂\n[TimbreAudioLoader] Â∑≤Âä†ËΩΩ 58 ‰∏™Èü≥È¢ëÊñá‰ª∂\n[TimbreAudioLoader] Â∑≤Âä†ËΩΩ 58 ‰∏™Èü≥È¢ëÊñá‰ª∂\n[TimbreAudioLoader] Â∑≤Âä†ËΩΩ 58 ‰∏™Èü≥È¢ëÊñá‰ª∂\n‚öôÔ∏è ChatterBox Engine: Configured for local:Russian on auto\n   Settings: exaggeration=0.5, temperature=0.8, cfg_weight=0.5\n   Crash protection: hmm ,, {seg} hmm ,,\nend_vram - start_vram: 8519680 - 8519680 = 0\n#117 [ChatterBoxEngineNode]: 0.00s - vram 0b\nend_vram - start_vram: 8519680 - 8519680 = 0\n#154 [VHS_LoadVideo]: 2.98s - vram 0b\nend_vram - start_vram: 8519680 - 8519680 = 0\n#155 [AudioCrop]: 0.08s - vram 0b\nend_vram - start_vram: 8519680 - 8519680 = 0\n#119 [PrimitiveStringMultiline]: 0.00s - vram 0b\nüîç Auto-detected language: english\nend_vram - start_vram: 8519680 - 8519680 = 0\n#118 [PhonemeTextNormalizer]: 0.00s - vram 0b\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS engines will fail\nüé§ Generating Chatterbox for 'narrator' (lang: local)\ninput frame rate=25\nüî§ Using available tokenizer: tokenizer.json\nüì¶ ChatterBox models loaded from: D:\\ComfyUI\\zuixin\\ComfyUI\\models\\TTS\\chatterbox\\Russian\nüî§ Final text to ChatterBox TTS model (narrator): '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Å—Ç—Ä–µ–º–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—è–µ—Ç –Ω–∞—à—É –∂–∏–∑–Ω—å. –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã, —É–º–Ω—ã–µ –¥–æ–º–∞, –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ ‚Äî –≤—Å—ë —ç—Ç–æ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —á–∞—Å—Ç—å—é –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ—Å—Ç–∏. –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –Ω–µ —Ç–æ–ª—å–∫–æ —É–ø—Ä–æ—â–∞—é—Ç –∑–∞–¥–∞—á–∏, –Ω–æ –∏ –æ—Ç–∫—Ä—ã–≤–∞—é—Ç –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞ –∏ –æ–±—É—á–µ–Ω–∏—è. –í–∞–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö —Ä–∞–∑—É–º–Ω–æ, —Å–æ—Ö—Ä–∞–Ω—è—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ. –ë—É–¥—É—â–µ–µ —É–∂–µ –Ω–∞—Å—Ç—É–ø–∞–µ—Ç, –∏ –æ–Ω–æ –ø–æ–ª–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤.'\n\nD:\\ComfyUI\\zuixin\\ComfyUI>\n\n<img width=\"2295\" height=\"944\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/afa633b3-58b5-4ac1-b0f3-1197270e43bd\" />\nThis Russian text was generated using a large language model.","createdAt":"2025-12-29T03:26:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/210#issuecomment-3695341041","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cREAR","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"crashes in what way? The console log does not show any error","createdAt":"2025-12-29T05:24:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/210#issuecomment-3695460369","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cREYP","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"And I still think you should give up on this Russian model on classic chatterbox. I don't speak Russian, but it sounded really bad. Try the 23-lang chatterbox Engine.","createdAt":"2025-12-29T05:25:37Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/210#issuecomment-3695461903","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":210,"title":"Running \"ChatterBox TTS\" with the language set to Russian directly crashes ComfyUI.","updatedAt":"2025-12-29T05:25:38Z"},{"comments":[{"id":"IC_kwDOPZi2kc7cP1MG","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Thanks for the report. The second pass with step audio editx was broken on VibeVoice Native mode. I'm fixing it.","createdAt":"2025-12-28T23:36:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/208#issuecomment-3695137542","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cP3Pr","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Well I had to disable editing tags for VibeVoice in native mode when it detects multiple narrators. Why? Step EditX only works for one narrator only, and Vobe Voice on native mode generates a whole segment in one go for all the narrators, and Step EditX can't handle that, it would turn all voices into one.","createdAt":"2025-12-28T23:47:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/208#issuecomment-3695145963","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cQL1y","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Fixed in v4.15.17! üéâ\n\nThe issue has been resolved - inline edit tags like `<Sigh>` now work correctly with VibeVoice.\n\n## Important Usage Notes\n\n**‚úÖ Edit Tags Work With:**\n- **Single narrator** in Native Multi-Speaker mode (only one speaker in the text)\n- **Custom Character Switching mode** (always works)\n\n**‚ö†Ô∏è Edit Tags Don't Work With:**\n- **Native Multi-Speaker mode with multiple speakers** - The system will detect this and skip edit tags with a warning message\n\n### Why This Limitation?\n\nIn Native Multi-Speaker mode with multiple speakers, VibeVoice uses all 4 speaker slots and voice references simultaneously. Step Audio EditX (which applies the edit tags) cannot preserve the multi-speaker voice mapping when editing segments.\n\n### Workaround\n\nIf you need both **multiple speakers AND edit tags**, use **Custom Character Switching mode** instead of Native Multi-Speaker mode. Custom mode applies edit tags per-character, so it works perfectly with inline tags.\n\n---\n\n**Changes in v4.15.17:**\n- Fixed inline parameter application (`[seed:2|cfg:7]` now properly bypasses cache)\n- Added automatic detection and warnings for multi-speaker + edit tags scenarios\n- Edit tags are automatically stripped in incompatible scenarios to prevent crashes","createdAt":"2025-12-29T01:30:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/208#issuecomment-3695230322","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cewq8","author":{"login":"wcmille"},"authorAssociation":"NONE","body":"Thanks. To make voice clones in Custom Character switching, I'd just go into the configs and create the characters?","createdAt":"2025-12-30T11:16:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/208#issuecomment-3699051196","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cfayx","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> Thanks. To make voice clones in Custom Character switching, I'd just go into the configs and create the characters?\n\nto use character tags (with vibe voice you need to switch the mode to custom Multi-Speaker instead of native) you need to have the audio + text of each character in your model/voices folder check the guide here: https://github.com/diodiogod/TTS-Audio-Suite/blob/main/docs/CHARACTER_SWITCHING_GUIDE.md","createdAt":"2025-12-30T12:35:11Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/208#issuecomment-3699223729","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":208,"title":"[Bug] <sigh> vocalization doesn't work in VibeVoice Native","updatedAt":"2025-12-30T12:35:56Z"},{"comments":[{"id":"IC_kwDOPZi2kc7bN07u","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"There might be a bug on the auto downloader, IDK, maybe you have an incomplete model and it is failing because of that. I'll check. But on the readme there should be links to each model if you want to download them manually.\nI've just deleted my f5 models and the workflow run in like 38 seconds, counting the model downloding...","createdAt":"2025-12-20T13:47:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/206#issuecomment-3677834990","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7bN3vj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Improved Auto-Download Error Handling\n\nI've added safety checks to detect incomplete F5-TTS model downloads and provide better error messages.\n\n### What Changed\n\nAdded verification after each download operation to check if files actually exist on disk:\n\n1. **Model weights verification** - If the model file download fails or is incomplete, you'll get a clear error message instead of a confusing `FileNotFoundError` later\n2. **Vocab file verification** - If vocab.txt download fails, the code now falls back to the bundled vocab file instead of crashing\n3. **Better error messages** - When downloads fail, the error clearly states which file is missing and where it expected to find it\n\n### How This Helps\n\n**Before**: Partial download ‚Üí code assumes files exist ‚Üí crashes with `FileNotFoundError: vocab.txt`\n\n**After**: Partial download ‚Üí code detects missing files ‚Üí either uses fallback or gives clear error about what failed\n\n### Still Recommended\n\nAs mentioned earlier, if you have an incomplete model:\n1. Delete the model folder (`models/TTS/F5-TTS/F5TTS_v1_Base/`)\n2. Run the workflow again to trigger a fresh download\n\nThe new checks will now detect if the re-download also fails and provide clearer error messages.\n\n---\n\n**Note**: This doesn't fix network/download issues, but makes it much easier to diagnose what went wrong.","createdAt":"2025-12-20T14:04:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/206#issuecomment-3677846499","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7bpqPI","author":{"login":"xXMantequillaXx"},"authorAssociation":"NONE","body":"Hey, here are the new error messages. I deleted the whole custom node, and all the models, including both the TTS folder structure entirely and the Vibevoice folder structure. \n\nNode processing failed: RuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\nTraceback:\nTraceback (most recent call last):\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 687, in _load_f5tts\nraise Exception(f\"Model download incomplete: {model_filename} not found at {model_file}\")\nException: Model download incomplete: model_1250000.safetensors not found at D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\model_1250000.safetensors\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 696, in _load_f5tts\nself.f5tts_model = F5TTS(\n^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\api.py\", line 82, in __init__\nself.ema_model = load_model(\n^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\infer\\utils_infer.py\", line 261, in load_model\nvocab_char_map, vocab_size = get_tokenizer(vocab_file, tokenizer)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\model\\utils.py\", line 159, in get_tokenizer\nwith open(dataset_name, \"r\", encoding=\"utf-8\") as f:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 473, in f5tts_factory\nreturn ChatterBoxF5TTS.from_local(local_path, config.device, model_name)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 785, in from_local\nreturn cls(model_name, device, ckpt_dir)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 124, in __init__\nself._load_f5tts()\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 779, in _load_f5tts\nraise RuntimeError(f\"Failed to load F5-TTS model '{self.model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\base_node.py\", line 374, in process_with_error_handling\nreturn process_func(*args, **kwargs)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\f5tts/f5tts_edit_node.py\", line 180, in _process\nself.load_f5tts_model(inputs[\"model\"], inputs[\"device\"])\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\f5tts_base_node.py\", line 107, in load_f5tts_model\nwrapped_model = load_tts_model(\n^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 282, in load_tts_model\nreturn unified_model_interface.load_model(config, force_reload)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 156, in load_model\nwrapper = tts_model_manager.load_model(\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\comfyui_model_wrapper\\model_manager.py\", line 253, in load_model\nmodel = model_factory_func(config)\n^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 479, in f5tts_factory\nraise RuntimeError(f\"Failed to load F5-TTS model '{model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'","createdAt":"2025-12-23T05:10:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/206#issuecomment-3685131208","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cPpZS","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Thanks for the detailed error log! The safety checks are working - they correctly detected that the download failed:\n\n```\nModel download incomplete: model_1250000.safetensors not found at D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\model_1250000.safetensors\n```\n\n**The root issue**: The unified downloader isn't actually downloading the files. This could be caused by:\n\n1. **Network/firewall blocking HuggingFace** - Can you access https://huggingface.co/SWivid/F5-TTS in your browser?\n2. **Permission issues** - Does ComfyUI have write access to `D:\\ComfyUI\\models\\TTS\\F5-TTS\\` folder?\n3. **Antivirus blocking** - Some antivirus software blocks large file downloads\n\n**To diagnose**, can you check:\n- Are there any earlier error messages in the console before this one? (Look for messages starting with \"üì• Downloading\" or \"‚ùå Download failed\")\n- Do you see any files at all in `D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\`? Even if incomplete?\n- What's your internet connection like? The model is ~1.2GB\n\n**Workaround**: You can manually download the model from HuggingFace:\n1. Go to: https://huggingface.co/SWivid/F5-TTS/tree/main/F5TTS_v1_Base\n2. Download `model_1250000.safetensors` and `vocab.txt`\n3. Place them in: `D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\`","createdAt":"2025-12-28T22:10:16Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/206#issuecomment-3695089234","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cochx","author":{"login":"xXMantequillaXx"},"authorAssociation":"NONE","body":"What is interesting is that other models, like vibevoice 7b, have been successfully downloaded via your node. here are the full detailed logs from the terminal:\n(according to claude, these could mean that: the model file (model_1250000.safetensors) failed to download, and there's a missing vocab.txt file. The custom node seems to have a broken path structure (infer\\infer\\examples\\ looks like a duplicate). You might need to reinstall the TTS Audio Suite node or manually download the F5-TTS model files.)\nI will use the manual download workaround, but i thought these might be of use to you. Thanks\ngot prompt\nüìÅ Using local F5-TTS model: D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\nüì¶ Loading F5-TTS model 'F5TTS_v1_Base' from HuggingFace\nüì• Downloading F5-TTS model to organized directory: model_1250000.safetensors\n‚ö†Ô∏è Failed to download to organized directory, using HF cache: Model download incomplete: model_1250000.safetensors not found at D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\model_1250000.safetensors\nDownload Vocos from huggingface charactr/vocos-mel-24khz\n!!! Exception during processing !!! Node processing failed: RuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\nTraceback:\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 687, in _load_f5tts\n    raise Exception(f\"Model download incomplete: {model_filename} not found at {model_file}\")\nException: Model download incomplete: model_1250000.safetensors not found at D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\model_1250000.safetensors\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 696, in _load_f5tts\n    self.f5tts_model = F5TTS(\n                       ^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\api.py\", line 82, in __init__\n    self.ema_model = load_model(\n                     ^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\infer\\utils_infer.py\", line 261, in load_model\n    vocab_char_map, vocab_size = get_tokenizer(vocab_file, tokenizer)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\model\\utils.py\", line 159, in get_tokenizer\n    with open(dataset_name, \"r\", encoding=\"utf-8\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 473, in f5tts_factory\n    return ChatterBoxF5TTS.from_local(local_path, config.device, model_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 785, in from_local\n    return cls(model_name, device, ckpt_dir)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 124, in __init__\n    self._load_f5tts()\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 779, in _load_f5tts\n    raise RuntimeError(f\"Failed to load F5-TTS model '{self.model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\base_node.py\", line 374, in process_with_error_handling\n    return process_func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\f5tts/f5tts_edit_node.py\", line 180, in _process\n    self.load_f5tts_model(inputs[\"model\"], inputs[\"device\"])\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\f5tts_base_node.py\", line 107, in load_f5tts_model\n    wrapped_model = load_tts_model(\n                    ^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 282, in load_tts_model\n    return unified_model_interface.load_model(config, force_reload)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 156, in load_model\n    wrapper = tts_model_manager.load_model(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\comfyui_model_wrapper\\model_manager.py\", line 253, in load_model\n    model = model_factory_func(config)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 479, in f5tts_factory\n    raise RuntimeError(f\"Failed to load F5-TTS model '{model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 687, in _load_f5tts\n    raise Exception(f\"Model download incomplete: {model_filename} not found at {model_file}\")\nException: Model download incomplete: model_1250000.safetensors not found at D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\model_1250000.safetensors\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 696, in _load_f5tts\n    self.f5tts_model = F5TTS(\n                       ^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\api.py\", line 82, in __init__\n    self.ema_model = load_model(\n                     ^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\infer\\utils_infer.py\", line 261, in load_model\n    vocab_char_map, vocab_size = get_tokenizer(vocab_file, tokenizer)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\model\\utils.py\", line 159, in get_tokenizer\n    with open(dataset_name, \"r\", encoding=\"utf-8\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 473, in f5tts_factory\n    return ChatterBoxF5TTS.from_local(local_path, config.device, model_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 785, in from_local\n    return cls(model_name, device, ckpt_dir)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 124, in __init__\n    self._load_f5tts()\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 779, in _load_f5tts\n    raise RuntimeError(f\"Failed to load F5-TTS model '{self.model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\base_node.py\", line 374, in process_with_error_handling\n    return process_func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\f5tts/f5tts_edit_node.py\", line 180, in _process\n    self.load_f5tts_model(inputs[\"model\"], inputs[\"device\"])\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\f5tts_base_node.py\", line 107, in load_f5tts_model\n    wrapped_model = load_tts_model(\n                    ^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 282, in load_tts_model\n    return unified_model_interface.load_model(config, force_reload)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 156, in load_model\n    wrapper = tts_model_manager.load_model(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\comfyui_model_wrapper\\model_manager.py\", line 253, in load_model\n    model = model_factory_func(config)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 479, in f5tts_factory\n    raise RuntimeError(f\"Failed to load F5-TTS model '{model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\comfyui\\execution.py\", line 518, in execute\n    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\comfyui\\execution.py\", line 329, in get_output_data\n    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\comfyui\\execution.py\", line 303, in _async_map_node_over_list\n    await process_inputs(input_dict, i)\n  File \"D:\\comfyui\\execution.py\", line 291, in process_inputs\n    result = f(**inputs)\n             ^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\f5tts/f5tts_edit_node.py\", line 250, in edit_speech\n    return self.process_with_error_handling(_process)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\base_node.py\", line 390, in process_with_error_handling\n    raise RuntimeError(\nRuntimeError: Node processing failed: RuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\nTraceback:\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 687, in _load_f5tts\n    raise Exception(f\"Model download incomplete: {model_filename} not found at {model_file}\")\nException: Model download incomplete: model_1250000.safetensors not found at D:\\ComfyUI\\models\\TTS\\F5-TTS\\F5TTS_v1_Base\\model_1250000.safetensors\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 696, in _load_f5tts\n    self.f5tts_model = F5TTS(\n                       ^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\api.py\", line 82, in __init__\n    self.ema_model = load_model(\n                     ^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\infer\\utils_infer.py\", line 261, in load_model\n    vocab_char_map, vocab_size = get_tokenizer(vocab_file, tokenizer)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5_tts\\model\\utils.py\", line 159, in get_tokenizer\n    with open(dataset_name, \"r\", encoding=\"utf-8\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 473, in f5tts_factory\n    return ChatterBoxF5TTS.from_local(local_path, config.device, model_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 785, in from_local\n    return cls(model_name, device, ckpt_dir)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 124, in __init__\n    self._load_f5tts()\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\f5tts\\f5tts.py\", line 779, in _load_f5tts\n    raise RuntimeError(f\"Failed to load F5-TTS model '{self.model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\base_node.py\", line 374, in process_with_error_handling\n    return process_func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\f5tts/f5tts_edit_node.py\", line 180, in _process\n    self.load_f5tts_model(inputs[\"model\"], inputs[\"device\"])\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\nodes\\base\\f5tts_base_node.py\", line 107, in load_f5tts_model\n    wrapped_model = load_tts_model(\n                    ^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 282, in load_tts_model\n    return unified_model_interface.load_model(config, force_reload)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 156, in load_model\n    wrapper = tts_model_manager.load_model(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\comfyui_model_wrapper\\model_manager.py\", line 253, in load_model\n    model = model_factory_func(config)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\ComfyUI\\custom_nodes\\tts_audio_suite\\utils\\models\\unified_model_interface.py\", line 479, in f5tts_factory\n    raise RuntimeError(f\"Failed to load F5-TTS model '{model_name}': {e}\")\nRuntimeError: Failed to load F5-TTS model 'F5TTS_v1_Base': Failed to load F5-TTS model 'F5TTS_v1_Base': [Errno 2] No such file or directory: 'D:\\\\ComfyUI\\\\custom_nodes\\\\tts_audio_suite\\\\engines\\\\f5_tts\\\\infer\\\\infer\\\\examples\\\\vocab.txt'","createdAt":"2025-12-31T07:04:29Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/206#issuecomment-3701590129","viewerDidAuthor":false}],"labels":[],"number":206,"title":"üëÑ F5-TTS Speech Editor Workflow  &  Voice Cleaning - ü§ê Noise or Vocal Removal + ü§ê Voice Fixer","updatedAt":"2025-12-31T07:04:29Z"},{"comments":[{"id":"IC_kwDOPZi2kc7bNyxj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Character Voices node, the reference_text is the narrator transcription, just like f5, it can't do zero shot cloning with just the audio. Not the text you want it to speak. The text you want to generate goes into the \"TTS Text\" text field; you can't leave it blank.","createdAt":"2025-12-20T13:32:45Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3677826147","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cP9Wx","author":{"login":"hirowa"},"authorAssociation":"NONE","body":"Hi there!\nStep Audio 2 is out, is there any plan to integrate it?\nhttps://github.com/stepfun-ai/Step-Audio2\n\nHave a great day and awesome new year!","createdAt":"2025-12-29T00:21:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3695170993","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cP_jZ","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@hirowa I might be wrong, but step Audio2 is a different model from step audio editx. And probably older? I don't know, sounds confusing. In any case, if you want it supported, I suggest opening a separate issue requesting it. There are many many new TTS models released every month... it's impossible to support them all. ","createdAt":"2025-12-29T00:31:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3695179993","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cpcZD","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> Character Voices node, the reference_text is the narrator transcription, just like f5, it can't do zero shot cloning with just the audio. Not the text you want it to speak. The text you want to generate goes into the \"TTS Text\" text field; you can't leave it blank.\n\n<img width=\"2528\" height=\"1078\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/73499d92-a669-4b27-8d5b-fdfab9595af6\" />\n\nI noticed that the ‚ÄúStep Audio EditX ‚Äì TTS Cloning‚Äù workflow is missing from your example workflow. Was it removed because the results were not satisfactory? After adjusting the workflow as you suggested, I encountered an OutOfMemoryError. It seems that the chunking system does not work under the Step Audio EditX Engine.","createdAt":"2025-12-31T09:46:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3701851715","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7c4bMh","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"The wprkflow is there, no https://github.com/diodiogod/TTS-Audio-Suite/blob/main/example_workflows/Step%20Audio%20EditX%20Integration.json ?\n\nNow, about the chunk system, I'll have to check, but it should be working under Step Audio EditX.","createdAt":"2026-01-02T16:56:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3705778977","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7c4fZd","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Testing chunk it worked just fine for me on TTS Text:\n```\ngot prompt\n‚öôÔ∏è Step Audio EditX: Configured on auto\n   Model: local:Step-Audio-EditX\n   Precision: bfloat16\n   Generation: temp=0.7, do_sample=True, max_tokens=8192\nüé§ TTS Text: Using voice reference from folder (Tony)\nüé§ Generating Step_Audio_Editx for 'Tony' (lang: en)\nüóëÔ∏è Moving 1 TTS models to CPU to free VRAM\nüîÑ Moved CosyVoice components (llm, flow, hift) to cpu, freed ~3277MB\nüìÅ Using local Step Audio EditX model: D:\\AiSymLink\\TTS\\step_audio_editx\\Step-Audio-EditX\n‚ö†Ô∏è  Detected incorrect weight tying in transformers 4.54+ - restoring original lm_head weights...\n‚úÖ Restored lm_head weights (norm: 264.00 ‚Üí 236.00)\n‚úÖ Step Audio EditX model loaded via unified interface on cuda\nüé® Step Audio EditX: Resampling narrator audio from 44100Hz to 24000Hz\nüîÑ Step Audio EditX: Processing 1 character segments\n\nüé§ Segment 1/1: Character 'narrator'\nüìù Chunking narrator's combined text into 8 chunks\nüîÑ Generating audio tokens for text: 'Testing repeated text for chunk. On Tuesdays, the ...' (input tokens: 521)\n\n[StepAudio] üöÄ Generation started (max 8192 tokens)...\nüîÑ Generating audio tokens for text: 'They debated the ethics of breadcrumbs and the met...' (input tokens: 521)\n\n[StepAudio] üöÄ Generation started (max 8192 tokens)...\nüíæ Using cached Step Audio EditX audio for 'narrator': 'Testing repeated text for chun...'\nüíæ Using cached Step Audio EditX audio for 'narrator': 'They debated the ethics of bre...'\nüíæ Using cached Step Audio EditX audio for 'narrator': 'Testing repeated text for chun...'\nüíæ Using cached Step Audio EditX audio for 'narrator': 'They debated the ethics of bre...'\nüíæ Using cached Step Audio EditX audio for 'narrator': 'Testing repeated text for chun...'\nüíæ Using cached Step Audio EditX audio for 'narrator': 'They debated the ethics of bre...'\n\nüîß EditPostProcessor: Using inline tag settings - precision=auto, device=auto\n‚úÖ Step_Audio_Editx generation complete. Default narrator: Tony\nPrompt executed in 66.18 seconds\n```","createdAt":"2026-01-02T17:02:44Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3705796189","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7c4f9i","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Can you post your full error log so I can see what is happening?","createdAt":"2026-01-02T17:03:16Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3705798498","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7dAF0K","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> Can you post your full error log so I can see what is happening?\n\nworkflow https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3701851715\n```\ngot prompt\n‚öôÔ∏è Step Audio EditX: Configured on cuda\n   Model: local:Step-Audio-EditX\n   Precision: bfloat16\n   Quantization: int4\n   Generation: temp=0.7, do_sample=True, max_tokens=8192\nüéß Processing (2, 11289600) audio at 44100Hz\nsaving sound to D:\\TTS-Audio-Suite\\ComfyUI\\temp\\uvr\\039adf68d3b1b11dff21c32f82f69eaa.wav\nFile saved to $D:\\TTS-Audio-Suite\\ComfyUI\\temp\\uvr\\039adf68d3b1b11dff21c32f82f69eaa.wav\nüéµ Starting vocal separation with MelBandRoformer_fp32.safetensors\nüîß Using MelBandRoFormer separation engine\nD:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\functional.py:730: UserWarning: A window was not provided. A rectangular window will be applied,which is known to cause spectral leakage. Other windows such as torch.hann_window or torch.hamming_window are recommended to reduce spectral leakage.To suppress this warning and use a rectangular window, explicitly set `window=torch.ones(n_fft, device=<device>)`. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\SpectralOps.cpp:842.)\n  return _VF.stft(  # type: ignore[attr-defined]\nüíæ Caching results for faster future processing\nsaving sound to D:\\TTS-Audio-Suite\\ComfyUI\\temp\\uvr\\039adf68d3b1b11dff21c32f82f69eaa\\primary.flac\nFile saved to $D:\\TTS-Audio-Suite\\ComfyUI\\temp\\uvr\\039adf68d3b1b11dff21c32f82f69eaa\\primary.flac\nsaving sound to D:\\TTS-Audio-Suite\\ComfyUI\\temp\\uvr\\039adf68d3b1b11dff21c32f82f69eaa\\secondary.flac\nFile saved to $D:\\TTS-Audio-Suite\\ComfyUI\\temp\\uvr\\039adf68d3b1b11dff21c32f82f69eaa\\secondary.flac\nloading sound fname='D:\\\\TTS-Audio-Suite\\\\ComfyUI\\\\temp\\\\uvr\\\\039adf68d3b1b11dff21c32f82f69eaa\\\\primary.flac' audio.shape=(11289600,) audio.max()=np.float32(0.853733) audio.min()=np.float32(-0.95) audio.dtype=dtype('float32') sr=44100\nloading sound fname='D:\\\\TTS-Audio-Suite\\\\ComfyUI\\\\temp\\\\uvr\\\\039adf68d3b1b11dff21c32f82f69eaa\\\\secondary.flac' audio.shape=(11289600,) audio.max()=np.float32(0.9499999) audio.min()=np.float32(-0.851185) audio.dtype=dtype('float32') sr=44100\nüîÑ Model with inverted outputs detected - swapping (primary=instrumentals, secondary=vocals)\nüé≠ Character Voices: Using direct audio input\nüí¨ Narrator Voice: direct_input ready for F5-TTS, ChatterBox, and future engines\nü©π TTS AUDIO SUITE CUDNN FIX APPLIED\n   Disabled CUDNN benchmark on Python 3.12 to prevent VRAM spikes\n   This fixes ComfyUI v0.3.57+ regression - VRAM spikes eliminated!\nüé§ TTS Text: Using voice reference from Character Voices node (direct_input)\nüé§ Generating Step_Audio_Editx for 'direct_input' (lang: en)\nüìÅ Using local Step Audio EditX model: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\step_audio_editx\\Step-Audio-EditX\nnew registry table has been added: preprocessor_classes\nD:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\jamo\\jamo.py:79: SyntaxWarning: invalid escape sequence '\\w'\n  hcj_name = re.sub(\"(?<=HANGUL )(\\w+)\",\nD:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\jamo\\jamo.py:210: SyntaxWarning: invalid escape sequence '\\w'\n  jamo_name = re.sub(\"(?<=HANGUL )(\\w+)\",\n‚ö†Ô∏è  Detected incorrect weight tying in transformers 4.54+ - restoring original lm_head weights...\n‚úÖ Restored lm_head weights (norm: 263.50 ‚Üí 236.12)\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n‚úÖ Step Audio EditX model loaded via unified interface on cuda\nüé® Step Audio EditX: Resampling narrator audio from 44100Hz to 24000Hz\nüîÑ Step Audio EditX: Processing 37 character segments\n\nüé§ Segment 1/37: Character 'narrator'\nüîç DEBUG: Extracted 0 edit tags from combined_text (len=16)\nüé≠ Step Audio EditX - Generating for 'narrator':\n============================================================\nÂ§¢„Å™„Çâ„Å∞„Å©„Çå„Åª„Å©„Çà„Åã„Å£„Åü„Åß„Åó„Çá„ÅÜ\n============================================================\nüîÑ Generating audio tokens for text: 'Â§¢„Å™„Çâ„Å∞„Å©„Çå„Åª„Å©„Çà„Åã„Å£„Åü„Åß„Åó„Çá„ÅÜ...' (input tokens: 10270)\nClone failed: Allocation on device\n‚ùå TTS Text generation failed: Allocation on device\nTraceback (most recent call last):\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\\modeling_step1.py\", line 106, in forward\n    attn_output = self.flash_attn_func(q, k, v)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\\modeling_step1.py\", line 82, in flash_attn_func\n    return torch.ops.Optimus.fwd(q, k, v, None, dropout_p, softmax_scale, causal, return_attn_probs, None, tp_group_rank, tp_group_size)[0]\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\_ops.py\", line 1353, in __getattr__\n    raise AttributeError(\nAttributeError: '_OpNamespace' 'Optimus' object has no attribute 'fwd'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\unified/tts_text_node.py\", line 964, in generate_speech\n    audio_segments = tts_processor.process_text(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\step_audio_editx\\step_audio_editx_processor.py\", line 126, in process_text\n    return self._process_character_switching(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\step_audio_editx\\step_audio_editx_processor.py\", line 188, in _process_character_switching\n    self._process_character_block(segment.character, segment.text.strip(), voice_mapping,\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\step_audio_editx\\step_audio_editx_processor.py\", line 343, in _process_character_block\n    audio_tensor = self.adapter.generate_with_pause_tags(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\engines\\adapters\\step_audio_editx_adapter.py\", line 161, in generate_with_pause_tags\n    return self._generate_direct(text, voice_ref, params, character_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\engines\\adapters\\step_audio_editx_adapter.py\", line 314, in _generate_direct\n    result = self.engine.clone(\n             ^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\utils\\models\\unified_model_interface.py\", line 944, in clone\n    return self._tts_engine.clone(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\engines\\step_audio_editx\\step_audio_editx_impl\\tts.py\", line 264, in clone\n    output_ids = self.llm.generate(\n                 ^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 120, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py\", line 2564, in generate\n    result = decoding_method(\n             ^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py\", line 2784, in _sample\n    outputs = self(**model_inputs, return_dict=True)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\\modeling_step1.py\", line 379, in forward\n    outputs = self.model(\n              ^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\\modeling_step1.py\", line 304, in forward\n    layer_outputs = decoder_layer(\n                    ^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\\modeling_step1.py\", line 176, in forward\n    hidden_states, self_attn_weights = self.self_attn(hidden_states, past_key_value, attention_mask, cache_position)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\\modeling_step1.py\", line 112, in forward\n    attention_mask = build_alibi_cache(\n                     ^^^^^^^^^^^^^^^^^^\n  File \"D:\\TTS-Audio-Suite\\ComfyUI\\.cache\\huggingface\\modules\\transformers_modules\\Step_hyphen_Audio_hyphen_EditX\\modeling_step1.py\", line 40, in build_alibi_cache\n    bias = bias.view(1, block_size, block_size) * slopes.view(-1, 1, 1)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\ntorch.OutOfMemoryError: Allocation on device\nPrompt executed in 135.99 seconds\n```","createdAt":"2026-01-04T06:35:20Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3707788554","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7jiIKp","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'm sorry, I completely forgot about this. Are you still having the same error on current version?","createdAt":"2026-01-29T12:34:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/204#issuecomment-3817374377","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWvQ","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"LA_kwDOPZi2kc8AAAACJLIGsg","name":"needs-clarification","description":"","color":"fbca04"}],"number":204,"title":"Step Audio EditX - TTS Cloning workflow","updatedAt":"2026-01-29T12:34:29Z"},{"comments":[{"id":"IC_kwDOPZi2kc7avOCX","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Your log show it loading in int4 for inline tags (probably from a previous generation). On int4 will be very slow (on my 4090 it goes to 5it/s or 10it/s, I don't remember right now). But your screenshots show you doing TTS with normal precision. Maybe it didn't reload? IDK. Try rebooting and starting a generation without any quantization. If it is still slow, there isn't much I can do... it is a slow model. On my 4090 it isn't that much slower comparing to the other models, but maybe for lower GPUS it is. I don't see any errors or bugs in your logs. The model speed isn't something I can fix. I've tried making it as efficient as possible.","createdAt":"2025-12-18T11:21:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/200#issuecomment-3669811351","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7bNFoG","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod The model has extremely high VRAM requirements. Even with my 4070 Ti, selecting ‚Äònone‚Äô for quantization results in a speed below 1 it/s, making int4 quantization necessary.\n\n```\ngot prompt\n‚ö†Ô∏è  Detected incorrect weight tying in transformers 4.54+ - restoring original lm_head weights...\n‚úÖ Restored lm_head weights (norm: 264.00 ‚Üí 236.00)\n‚úÖ Step Audio EditX model loaded via unified interface on cuda\nüîÑ Edit iteration 1/1...\n   Resampling audio from 22050Hz to 24000Hz\n\n[StepAudio] üöÄ Generation started (max 8192 tokens)...\nPrompt executed in 236.00 seconds192 | 0.9 it/s | 204s\n```","createdAt":"2025-12-20T09:17:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/200#issuecomment-3677641222","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7bNHgR","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod I suspect that the issue may be caused by the Step Audio EditX Engine failing to release VRAM. As a result, the first execution runs quickly, whereas subsequent executions show a significant drop in speed.\n\nI have tested it, and when using the indextts engine alone, changing the prompt or seed does not affect the speed. However, once the Step Audio EditX Engine is introduced, only the first execution runs at normal speed, while subsequent executions become extremely slow.","createdAt":"2025-12-20T09:29:32Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/200#issuecomment-3677648913","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7bNJrR","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"Here is the output log. From the completion timestamps, you can see that when the workflow passes through the Step Audio EditX Engine, the first execution runs quickly; however, during the second execution, the inference speed of the indextts engine drops sharply.\n\n```\ngot prompt\nüé§ TTS Text: Using voice reference from folder (input)\nüé§ Generating Index_Tts for 'input' (lang: en)\nüîÑ Reusing cached index_tts engine instance (updated with new generation parameters)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 1 character segment(s) - narrator\nüìñ Using connected narrator voice | Ref: 'Ê≠§Ââç‰∏âÂ¶π‰∏∫Áì∂È¢àÊâÄÂõ∞ Êï∞ÂÖÉ‰ºöÊó†Ê≥ïÁ™ÅÁ†¥Êó∂ ‰πüÊõæÁÑ¶ÊÄ•ÂøßËôëËÆ∏‰πÖ Êàë‰æøËøôËà¨ÂÆâÊäöÂ•πÊîæÊùæÂøÉÁ•û...'\nüé≠ No emotion audio for simple text segment (no connected engine emotion)\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\nUse the specified emotion vector\ntorch.Size([1, 218624])\n>> gpt_gen_time: 11.09 seconds\n>> gpt_forward_time: 0.03 seconds\n>> s2mel_time: 1.21 seconds\n>> bigvgan_time: 0.19 seconds\n>> Total inference time: 13.18 seconds\n>> Generated audio length: 9.91 seconds\n>> RTF: 1.3294\n‚úÖ Index_Tts generation complete. Default narrator: input\n‚öôÔ∏è Step Audio EditX: Configured on cuda\n   Model: local:Step-Audio-EditX\n   Precision: bfloat16\n   Quantization: int4\n   Generation: temp=0.7, do_sample=True, max_tokens=8192\nüóëÔ∏è Moving 1 TTS models to CPU to free VRAM\nüîÑ Moved tts model components (index_tts) to CPU, freed 4884MB\nnew registry table has been added: preprocessor_classes\n‚ö†Ô∏è  Detected incorrect weight tying in transformers 4.54+ - restoring original lm_head weights...\n‚úÖ Restored lm_head weights (norm: 263.50 ‚Üí 236.12)\n‚úÖ Step Audio EditX model loaded via unified interface on cuda\nüîÑ Edit iteration 1/1...\n   Resampling audio from 22050Hz to 24000Hz\n\n[StepAudio] üöÄ Generation started (max 8192 tokens)...\nPrompt executed in 82.88 seconds8192 | 10.0 it/s | 46s\ngot prompt\nPrompt executed in 0.01 seconds\ngot prompt\nüé§ TTS Text: Using voice reference from folder (input)\nüé§ Generating Index_Tts for 'input' (lang: en)\nüîÑ Reusing cached index_tts engine instance (updated with new generation parameters)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 1 character segment(s) - narrator\nüìñ Using connected narrator voice | Ref: 'Ê≠§Ââç‰∏âÂ¶π‰∏∫Áì∂È¢àÊâÄÂõ∞ Êï∞ÂÖÉ‰ºöÊó†Ê≥ïÁ™ÅÁ†¥Êó∂ ‰πüÊõæÁÑ¶ÊÄ•ÂøßËôëËÆ∏‰πÖ Êàë‰æøËøôËà¨ÂÆâÊäöÂ•πÊîæÊùæÂøÉÁ•û...'\nüé≠ No emotion audio for simple text segment (no connected engine emotion)\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\nUse the specified emotion vector\ntorch.Size([1, 195328])\n>> gpt_gen_time: 36.16 seconds\n>> gpt_forward_time: 0.02 seconds\n>> s2mel_time: 188.68 seconds\n>> bigvgan_time: 11.95 seconds\n>> Total inference time: 247.12 seconds\n>> Generated audio length: 8.86 seconds\n>> RTF: 27.8964\n‚úÖ Index_Tts generation complete. Default narrator: input\nüîÑ Edit iteration 1/1...\n   Resampling audio from 22050Hz to 24000Hz\n\n[StepAudio] üöÄ Generation started (max 8192 tokens)...\n   Progress: [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 25/8192 | 0.6 it/s | 39s\n```","createdAt":"2025-12-20T09:44:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/200#issuecomment-3677657809","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7bN44I","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Did you watch you VRAM while doing those testings? \nVram management it's a hard thing to get it right, and might need more tweaking. From what I gathered, you are using index2 > Editx (and up untill here, the index2 unloads normally and editx runs normally). But on second generation index2 loads (does it slow down as well, at this point is the VRAM full?) > then Editx overflows VRAM or something... \n\nWhen I get the time, I'll try to reproduce it to fix it, for sure. But for now a suggestion: use a \"Clean VRAM\" node between runs, (easy use nodes have one), or use the clear vram button of ComfyUI Manager.","createdAt":"2025-12-20T14:11:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/200#issuecomment-3677851144","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cpSlk","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> Did you watch you VRAM while doing those testings? Vram management it's a hard thing to get it right, and might need more tweaking. From what I gathered, you are using index2 > Editx (and up untill here, the index2 unloads normally and editx runs normally). But on second generation index2 loads (does it slow down as well, at this point is the VRAM full?) > then Editx overflows VRAM or something...\n> \n> When I get the time, I'll try to reproduce it to fix it, for sure. But for now a suggestion: use a \"Clean VRAM\" node between runs, (easy use nodes have one), or use the clear vram button of ComfyUI Manager.\n\n<img width=\"2096\" height=\"1329\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/750b4741-8cde-4914-9bc9-099bf492512a\" />\n\nThis is the generation speed during the first run.\n```\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\ngot prompt\nüóëÔ∏è Attempting to unload index_tts model (stateless wrapper enabled)\nüîÑ TTS Model unload requested: index_tts tts (_is_loaded_on_gpu=True)\nüîÑ Moved tts model components (index_tts) to CPU, freed 4884MB\n‚úÖ Full unload: freed 4884MB\nüìä VRAM: 5223MB ‚Üí 195MB (freed 5028MB)\n‚öôÔ∏è IndexTTS-2: Configured on cuda\n   Model: local:IndexTTS-2\n   Emotion: alpha=1.0, use_text=False\n   Generation: temp=0.8, top_p=0.8, top_k=30, do_sample=True, num_beams=3\n   Chunking: max_tokens=120, silence=200ms\nüé§ TTS Text: Using voice reference from folder (input)\nüé§ Generating Index_Tts for 'input' (lang: en)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 1 character segment(s) - narrator\nüìñ Using connected narrator voice | Ref: 'Ê≠§Ââç‰∏âÂ¶π‰∏∫Áì∂È¢àÊâÄÂõ∞ Êï∞ÂÖÉ‰ºöÊó†Ê≥ïÁ™ÅÁ†¥Êó∂ ‰πüÊõæÁÑ¶ÊÄ•ÂøßËôëËÆ∏‰πÖ Êàë‰æøËøôËà¨ÂÆâÊäöÂ•πÊîæÊùæÂøÉÁ•û...'\nüé≠ No emotion audio for simple text segment (no connected engine emotion)\nüîÑ IndexTTS-2: Initializing engine (first run may take 2-3 minutes to load models)...\n   Loading: QwenEmotion ‚Üí GPT ‚Üí Semantic Codec ‚Üí S2Mel ‚Üí CampPlus ‚Üí BigVGAN...\n‚ö†Ô∏è Failed to load QwenEmotion model: 'dict' object has no attribute 'model_type'\n‚ÑπÔ∏è Falling back to audio emotion only\nüîÑ IndexTTS-2: Loading GPT model...\nüîÑ IndexTTS-2: Moving GPT to cuda:0...\n>> GPT weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\gpt.pth\nüîÑ Loading W2V-BERT from TTS folder: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\w2v-bert-2.0\nüîÑ Initializing SeamlessM4TFeatureExtractor (this is the slow part)...\n‚úÖ W2V-BERT loaded in 0.0s\n>> semantic_codec weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\\semantic_codec\\model.safetensors\ncfm loaded\nlength_regulator loaded\ngpt_layer loaded\n>> s2mel weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\s2mel.pth\n>> campplus_model weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\\campplus_cn_common.bin\nLoading config.json from local directory\nLoading weights from local directory\nRemoving weight norm...\n>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x\nUsing wetext for text normalization (fallback)\n>> TextNormalizer loaded\n>> bpe model loaded from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\bpe.model\n‚úÖ IndexTTS-2 model loaded via unified interface on cuda:0\n‚úÖ IndexTTS-2 engine loaded via unified interface on cuda:0\n‚ö° Next generations will be much faster (models cached in VRAM)\n‚ö†Ô∏è Performance warning: IndexTTS-2 tested on Python 3.13 performs smoothly\n‚ö†Ô∏è Our Python 3.12 tests showed HIGH VRAM spikes during generation\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\nUse the specified emotion vector\ntorch.Size([1, 121856])\n>> gpt_gen_time: 6.33 seconds\n>> gpt_forward_time: 0.04 seconds\n>> s2mel_time: 0.97 seconds\n>> bigvgan_time: 0.12 seconds\n>> Total inference time: 8.03 seconds\n>> Generated audio length: 5.53 seconds\n>> RTF: 1.4537\n‚úÖ Index_Tts generation complete. Default narrator: input\n‚öôÔ∏è Step Audio EditX: Configured on cuda\n   Model: local:Step-Audio-EditX\n   Precision: bfloat16\n   Quantization: int4\n   Generation: temp=0.7, do_sample=True, max_tokens=8192\nüóëÔ∏è Moving 1 TTS models to CPU to free VRAM\nüîÑ Moved tts model components (index_tts) to CPU, freed 4884MB\nnew registry table has been added: preprocessor_classes\n‚ö†Ô∏è  Detected incorrect weight tying in transformers 4.54+ - restoring original lm_head weights...\n‚úÖ Restored lm_head weights (norm: 263.50 ‚Üí 236.12)\n‚úÖ Step Audio EditX model loaded via unified interface on cuda\nüîÑ Edit iteration 1/1...\n   Resampling audio from 22050Hz to 24000Hz\n\n[StepAudio] üöÄ Generation started (max 8192 tokens)...\nPrompt executed in 75.09 seconds8192 | 12.9 it/s | 17s\n```\nHere I changed the seed of TTS Text from fixed to random.\n```\ngot prompt\nPrompt executed in 0.01 seconds\n```\nIn the second run, nothing changed except the seed, yet the generation speed became extremely slow‚Äîso slow that it was almost unbearable.\n```\ngot prompt\nüé§ TTS Text: Using voice reference from folder (input)\nüé§ Generating Index_Tts for 'input' (lang: en)\nüîÑ Reusing cached index_tts engine instance (updated with new generation parameters)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 1 character segment(s) - narrator\nüìñ Using connected narrator voice | Ref: 'Ê≠§Ââç‰∏âÂ¶π‰∏∫Áì∂È¢àÊâÄÂõ∞ Êï∞ÂÖÉ‰ºöÊó†Ê≥ïÁ™ÅÁ†¥Êó∂ ‰πüÊõæÁÑ¶ÊÄ•ÂøßËôëËÆ∏‰πÖ Êàë‰æøËøôËà¨ÂÆâÊäöÂ•πÊîæÊùæÂøÉÁ•û...'\nüé≠ No emotion audio for simple text segment (no connected engine emotion)\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\nUse the specified emotion vector\ntorch.Size([1, 122368])\n>> gpt_gen_time: 21.15 seconds\n>> gpt_forward_time: 0.02 seconds\n>> s2mel_time: 119.27 seconds\n>> bigvgan_time: 6.30 seconds\n>> Total inference time: 160.38 seconds\n>> Generated audio length: 5.55 seconds\n>> RTF: 28.8998\n‚úÖ Index_Tts generation complete. Default narrator: input\nüîÑ Edit iteration 1/1...\n   Resampling audio from 22050Hz to 24000Hz\n\n[StepAudio] üöÄ Generation started (max 8192 tokens)...\nPrompt executed in 473.34 seconds192 | 0.7 it/s | 295s\n```","createdAt":"2025-12-31T09:20:05Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/200#issuecomment-3701811556","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":200,"title":"The inference speed of Step Audio EditX Engine is extremely slow.","updatedAt":"2025-12-31T09:26:33Z"},{"comments":[],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":198,"title":"Can You add VOXCPM 1.5B ?","updatedAt":"2026-02-06T00:52:00Z"},{"comments":[{"id":"IC_kwDOPZi2kc7aLMbF","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"From my initial analysis, this is a complete new model, a complete new engine. And also it is English only... I'll have to be convinced this is any good in comparison o what we have...\nTo implement this would require coding a whole new engine. Not saying it wouldn't be nice, but there are many other new models out there that are probably better.","createdAt":"2025-12-16T12:47:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/197#issuecomment-3660367557","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7aNMS8","author":{"login":"sudeep333"},"authorAssociation":"NONE","body":"Got it. I usually use voice changer. can you please tell me any other good model better than this ? If multilingual then it would be great.","createdAt":"2025-12-16T14:39:37Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/197#issuecomment-3660891324","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7aPn5r","author":{"login":"trollver9000"},"authorAssociation":"NONE","body":"Yeah if turbo supports voicechange / voice2voice then it would be useful","createdAt":"2025-12-16T17:01:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/197#issuecomment-3661528683","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7aSLPf","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> Yeah if turbo supports voicechange / voice2voice then it would be useful\n\nthat is a good question, I'll investigate. It's true, so far only Chatterbox supports VC in a zero shot way (we have RVC as well, but RVC needs a trained voice model)","createdAt":"2025-12-16T20:10:46Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/197#issuecomment-3662197727","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7aSPtg","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"  Apparently no, Turbo does NOT have a separate VC class.\n\n  Looking at the repo:\n  - Classic ChatterBox: Has ChatterboxVC class (vc.py) for speech-to-speech conversion\n  - Turbo: Only has ChatterboxTurboTTS class (tts_turbo.py) - no VC class","createdAt":"2025-12-16T20:15:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/197#issuecomment-3662216032","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7aW7md","author":{"login":"trollver9000"},"authorAssociation":"NONE","body":"From what i see most audio clones work similar way, so the fastest one is best , my fav ATM is voxcpm 1.5b that clones characteristics very nicely, i check by using mike tysons lisp voice cause most voiceclones remove his lisp or try to normalize into english accent","createdAt":"2025-12-17T03:14:37Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/197#issuecomment-3663444381","viewerDidAuthor":false}],"labels":[],"number":197,"title":"Can you Add Chatterbox Turbo ?","updatedAt":"2025-12-17T03:14:37Z"},{"comments":[{"id":"IC_kwDOPZi2kc7aTV2n","author":{"login":"juangea"},"authorAssociation":"NONE","body":"Agree, this model looks amazing, plus it has 9 languages, something really important right now :)","createdAt":"2025-12-16T21:42:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/195#issuecomment-3662503335","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7aU2wd","author":{"login":"JamesMowery"},"authorAssociation":"NONE","body":"+1","createdAt":"2025-12-16T23:39:16Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/195#issuecomment-3662900253","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cKeLI","author":{"login":"ri498"},"authorAssociation":"NONE","body":"https://github.com/filliptm/ComfyUI_FL-CosyVoice3","createdAt":"2025-12-27T05:58:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/195#issuecomment-3693732552","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7cat_L","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Phew! it's done... v4.16 please test it out.","createdAt":"2025-12-30T01:22:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/195#issuecomment-3697991627","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"},{"id":"LA_kwDOPZi2kc8AAAACOVaPDQ","name":"done","description":"","color":"63028d"}],"number":195,"title":"Fun-CosyVoice 3.0 released","updatedAt":"2025-12-30T01:22:31Z"},{"comments":[{"id":"IC_kwDOPZi2kc7X3R4S","author":{"login":"xueqing0622"},"authorAssociation":"NONE","body":"windows\nTotal VRAM 32607 MB, total RAM 196370 MB\npytorch version: 2.7.0+cu128\nxformers version: 0.0.30\nSet vram state to: NORMAL_VRAM\nDisabling smart memory management\nDevice: cuda:0 NVIDIA GeForce RTX 5090 : cudaMallocAsync\nUsing async weight offloading with 2 streams\nEnabled pinned memory 88366.0\nUsing xformers attention\nPython version: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]\nComfyUI version: 0.3.76\nComfyUI frontend version: 1.33.10\n[Prompt Server] web root: I:\\00Env\\python311b\\Lib\\site-packages\\comfyui_frontend_package\\static\nTotal VRAM 32607 MB, total RAM 196370 MB\npytorch version: 2.7.0+cu128\nxformers version: 0.0.30\nSet vram state to: NORMAL_VRAM\nDisabling smart memory management\nDevice: cuda:0 NVIDIA GeForce RTX 5090 : cudaMallocAsync\nUsing async weight offloading with 2 streams\nEnabled pinned memory 88366.0","createdAt":"2025-12-07T04:43:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3621592594","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7YPd5J","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Do you have the old chatterbox custom node installed as well?","createdAt":"2025-12-08T16:40:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3627933257","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Yp5xq","author":{"login":"xueqing0622"},"authorAssociation":"NONE","body":"no chatterbox custom node,  and I remove the comfyui-indextts and comfyui-megatts , also same error","createdAt":"2025-12-10T00:35:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3634863210","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7YyKsl","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"That is a conflict with other custom nodes because of relative imports of utils. I'll try to fix this by using absolute paths in the next versions after I release Step Audio EditX.","createdAt":"2025-12-10T13:11:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3637029669","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Zewok","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi @xueqing0622,\n\nI've identified and fixed the issue. The problem was caused by a Python import path conflict - another custom node in your ComfyUI installation has a `utils.py` file that was shadowing our `utils/` directory.\n\n**Fix implemented in v4.15.2:**\n- Modified `__init__.py` to use direct file path loading instead of package imports\n- Extension is now immune to Python path pollution from other custom nodes\n\n**Please update to v4.15.2 and test:**\n\n```bash\ncd custom_nodes/ComfyUI_TTS_Audio_Suite\ngit pull\n```\n\nThen restart ComfyUI. You should no longer see the \"'utils' is not a package\" errors, and all engines should load successfully.\n\nLet me know if this resolves the issue for you!","createdAt":"2025-12-13T01:37:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3648719396","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7aDZyB","author":{"login":"xueqing0622"},"authorAssociation":"NONE","body":"   üîá Suppressed torchaudio 2.9 migration warnings\n‚ÑπÔ∏è Critical package versions: NumPy 1.26.4, Librosa 0.10.2, Numba 0.61.0, PyTorch 2.7.0+cu128, TorchAudio 2.7.0+cu128, Transformers 4.57.3, Accelerate 1.10.1, SoundFile 0.13.1\n‚ùå ChatterBox Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå F5 TTS Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Higgs Audio Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Step Audio EditX Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå VibeVoice Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå ChatterBox Official 23-Lang Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå IndexTTS-2 Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Character Voices failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Unified TTS Text failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Unified TTS SRT failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Unified Voice Changer failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Audio Analyzer failed: No module named 'utils.audio'; 'utils' is not a package\n‚ùå F5-TTS Edit failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Step Audio EditX Audio Editor failed: No module named 'utils.audio'; 'utils' is not a package\n‚ùå RVC Engine failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå RVC Pitch Options failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Vocal/Noise Removal failed: No module named 'utils.compatibility'; 'utils' is not a package\n‚ùå Merge Audio failed: No module named 'utils.models'; 'utils' is not a package\n‚ùå Voice Fixer Audio Restoration failed: No module named 'utils.downloads'; 'utils' is not a package\n‚ùå Load RVC Character Model failed: No module named 'utils.models'; 'utils' is not a package\n[LG_HotReload] ÈáçÊñ∞Ê≥®ÂÜåÊ®°ÂùóÂ§±Ë¥•: No module named 'utils.system'; 'utils' is not a package\n\n\n\n> Hi [@xueqing0622](https://github.com/xueqing0622),\n> \n> I've identified and fixed the issue. The problem was caused by a Python import path conflict - another custom node in your ComfyUI installation has a `utils.py` file that was shadowing our `utils/` directory.\n> \n> **Fix implemented in v4.15.2:**\n> \n> * Modified `__init__.py` to use direct file path loading instead of package imports\n> * Extension is now immune to Python path pollution from other custom nodes\n> \n> **Please update to v4.15.2 and test:**\n> \n> cd custom_nodes/ComfyUI_TTS_Audio_Suite\n> git pull\n> Then restart ComfyUI. You should no longer see the \"'utils' is not a package\" errors, and all engines should load successfully.\n> \n> Let me know if this resolves the issue for you!\n\nused lastest this node, still same error","createdAt":"2025-12-16T01:35:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3658325121","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7aEsFU","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"can you please post you full init log. Some other custom node is conflicting, and if you don't post the full log I can't check it","createdAt":"2025-12-16T04:08:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3658662228","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7adtUV","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi @xueqing0622,\n\nI've implemented a potential fix for this issue in v4.15.8. The error appears to be caused by another custom node (possibly LG_HotReload or similar) that has a `utils.py` file which conflicts with TTS Audio Suite's `utils/` directory.\n\n**What the fix does:**\n- Detects if `sys.modules['utils']` contains a conflicting single-file module\n- Automatically removes it before TTS Suite loads\n- Shows a warning message indicating which custom node is causing the conflict\n\n**To test the fix:**\n```bash\ncd custom_nodes/TTS-Audio-Suite\ngit pull\n```\n\nThen restart ComfyUI. You should see:\n1. A warning message if a conflict is detected (showing which node is the source)\n2. TTS Audio Suite loading successfully with all engines working\n\n**Important note:** This fix has been tested with simulated conflict scenarios but not yet confirmed on your specific system. Please test and let me know if it resolves the issue or if you still see errors.\n\nIf it works, all the red ‚ùå errors should be gone and you'll be able to use the TTS nodes normally.","createdAt":"2025-12-17T12:54:33Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/191#issuecomment-3665220885","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWvQ","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"},{"id":"LA_kwDOPZi2kc8AAAACJ-Qoug","name":"confirmed","description":"","color":"b60205"}],"number":191,"title":"'utils' is not a package","updatedAt":"2025-12-17T12:54:33Z"},{"comments":[{"id":"IC_kwDOPZi2kc7XszXx","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"you are missing critical dependencies as the init log shows:\nLibrosa not installed, Numba not installed\n\nThey are installed by running the install.py in your environment (not on windows but inside your confyui env). It should have run by the ComfyUI manager automatically. Unless they changes something in the new versions... \n\nWhat is your comfyui installation? Portable, direct manual venv?","createdAt":"2025-12-05T22:34:17Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3618846193","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Xs-f3","author":{"login":"Poilaucul"},"authorAssociation":"NONE","body":"This is how I've set it up, I've chosen that path to be able to easily deploy it on cloud instances in the future while being in control of conflicting dependencies that may arise.\n\nComfyUI manager should have handled those dependencies indeed and that what worries me.\nI had not noticed any errors in the logs when installing TTS-AS from ComfyUI manager.\n\n\n## Setup\n\n```Bash\nsudo systemctl enable sshd; sudo systemctl start sshd\n\nsudo ufw allow ssh\nsudo ufw allow 8188\n\ngit clone https://github.com/comfyanonymous/ComfyUI\n\ncd ComfyUI\n\nexport NIXPKGS_ALLOW_UNFREE=1\n\nsudo pacman -S nvidia-utils nvidia-settings lib32-nvidia-utils linux-cachyos-nvidia net-tools\n\nldconfig -p | grep libcu*.so*\n```\n\n\n## Configuration\n\n```YAML\ncat << 'EOF' > shell.nix\nwith import <nixpkgs> { config = { allowUnfree = true; }; };\n\nlet\n  pythonPackages = python3Packages;\nin\npkgs.mkShell rec {\n  name = \"impurePythonEnv\";\n  venvDir = \"./.venv\";\n  buildInputs = [\n    # A Python interpreter including the 'venv' module is required to bootstrap\n    # the environment.\n    pythonPackages.python\n\n    # This executes some shell code to initialize a venv in $venvDir before\n    # dropping into the shell\n    pythonPackages.venvShellHook\n\n    # Those are dependencies that we would like to use from nixpkgs, which will\n    # add them to PYTHONPATH and thus make them accessible from within the venv.\n    pythonPackages.numpy\n    pythonPackages.requests\n\n    # In this particular example, in order to compile any binary extensions they may\n    # require, the Python modules listed in the hypothetical requirements.txt need\n    # the following packages to be installed locally:\n    taglib\n    stdenv.cc.cc.lib\n    #gccStdenv\n    openssl\n    git\n    libxml2\n    libxslt\n    libzip\n    zlib\n    libsamplerate       ## For https://github.com/diodiogod/TTS-Audio-Suite?tab=readme-ov-file\n    portaudio           ## For https://github.com/diodiogod/TTS-Audio-Suite?tab=readme-ov-file\n    ffmpeg-headless     ## For https://github.com/diodiogod/TTS-Audio-Suite?tab=readme-ov-file\n\n        # Include the CUDA toolkit and the user-space driver files\n    cudaPackages.cudatoolkit\n    cudaPackages.cuda_cudart\n    patchelf\n  ];\n\n  # Run this command, only after creating the virtual environment\n  postVenvCreation = ''\n      unset SOURCE_DATE_EPOCH\n\n      # --- Setup and Clean Install ---\n\n      echo \"Installing/Reinstalling Python dependencies (forcing rebuild)...\"\n      pip install --upgrade pip\n      pip install -r requirements.txt --force-reinstall  --extra-index-url https://download.pytorch.org/whl/cu121 #https://github.com/diodiogod/TTS-Audio-Suite requires Cuda 1.2.1\n\n      if [ ! -d custom_nodes/comfyui-manager ]; then\n        git clone https://github.com/ltdrdata/ComfyUI-Manager custom_nodes/comfyui-manager\n      fi\n\n      # --- DYNAMIC PATCHING (Derivation-Agnostic) ---\n\n      # 1. Define base paths\n      PYTORCH_LIB_DIR=\"./.venv/lib/python3.13/site-packages/torch/lib\"\n      NVIDIA_ROOT_DIR=\"./.venv/lib/python3.13/site-packages/nvidia\"\n\n      # 2. Dynamically find ALL Venv CUDA component library directories\n      echo \"Dynamically locating Venv NVIDIA component library directories...\"\n      VENV_NVIDIA_LIBS=$(find $NVIDIA_ROOT_DIR -type d -name \"lib\" | tr '\\n' ':')\n\n      # 3. Construct the comprehensive RPATH\n      NIX_CUDA_LIB_PATH=\"${pkgs.cudaPackages.cudatoolkit}/lib\"\n      RPATH=\"$PYTORCH_LIB_DIR:/usr/lib:$NIX_CUDA_LIB_PATH:$VENV_NVIDIA_LIBS\"\n\n      # ** LOGGING: Confirm Nix Store path and final RPATH **\n      echo \"Nix CUDA Toolkit Library Path (resolved via interpolation): $NIX_CUDA_LIB_PATH\"\n      echo \"Final Comprehensive RPATH applied to PyTorch libs: $RPATH\"\n\n      # 4. Patch ALL .so files in the PyTorch directory\n      echo \"Applying patchelf to PyTorch shared objects...\"\n      for file in $(find $PYTORCH_LIB_DIR -name '*.so'); do\n        echo \"-> Patching $file\"\n        patchelf --add-needed /usr/lib/libcuda.so.1 --set-rpath $RPATH $file\n      done\n\n      echo \"Patching complete.\"\n  '';\n\n  # Now we can execute any commands within the virtual environment.\n  # This is optional and can be left out to run pip manually.\n  postShellHook = ''\n\n\n    # Adds the C++ runtime libraries provided by Nixpkgs\n    export LD_LIBRARY_PATH=\"${stdenv.cc.cc.lib}/lib${if stdenv.is64bit then \":${stdenv.cc.cc.lib}/lib64\" else \"\"}:$LD_LIBRARY_PATH\"\n\n    # Ensure PortAudio library path is visible to dynamically linked binaries in the Venv (like Python libraries).\n    export LD_LIBRARY_PATH=${pkgs.portaudio}/lib:$LD_LIBRARY_PATH\n    echo \"LD_LIBRARY_PATH updated to include PortAudio lib: ${pkgs.portaudio}/lib\"\n\n    # Ensure libsamplerate library path is visible to dynamically linked binaries in the Venv (like Python libraries).\n    export LD_LIBRARY_PATH=${pkgs.libsamplerate}/lib:$LD_LIBRARY_PATH\n    echo \"LD_LIBRARY_PATH updated to include PortAudio lib: ${pkgs.libsamplerate}/lib\"\n\n    # Ensure ffmpeg-headless binary path is visible.\n    export LD_LIBRARY_PATH=${pkgs.ffmpeg-headless}/bin:$LD_LIBRARY_PATH\n    echo \"LD_LIBRARY_PATH updated to include ffmpeg-headless bin: ${pkgs.ffmpeg-headless}/bin\"\n\n    # allow pip to install wheels\n    unset SOURCE_DATE_EPOCH\n  '';\n}\nEOF\n```\n\n\n\n## Running\n\n\n```Bash\n\nnix-shell shell.nix\n```\n\n```Bash\npython main.py --listen 0.0.0.0\n```\n\n\n## Test versions\n\n```Shell\n[nix-shell:~/ComfyUI]$ python -c \"import torch, torchaudio; print(torch.__version__, '| CUDA:', torch.version.cuda, '| torch.cuda:', torch.cuda.is_available(), '| torchaudio:', torchaudio.__version__)\"\n2.9.1+cu128 | CUDA: 12.8 | torch.cuda: True | torchaudio: 2.9.1+cu128\n\n[nix-shell:~/ComfyUI]$ python --version\nPython 3.13.9\n\n[nix-shell:~/ComfyUI]$\n```\n","createdAt":"2025-12-05T22:56:38Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3618891767","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Xux4f","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Please run the install.py script and post the full log here.","createdAt":"2025-12-06T02:43:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3619364383","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7XwkR-","author":{"login":"Poilaucul"},"authorAssociation":"NONE","body":"When I manually ran the install.py within the nix shell it ran fine and I could generate, I wonder why ComfyUI manager didn't set it up right away.\n_afk right now will post the full logs later._","createdAt":"2025-12-06T09:59:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3619832958","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Xw07y","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> When I manually ran the install.py within the nix shell it ran fine and I could generate, I wonder why ComfyUI manager didn't set it up right away. _afk right now will post the full logs later._\n\nI'm glad it worked. I don't know really, hopefully they did not remove the call to install.py in new versions. Without it the suite install dependencies won't work as many decencies needs to be handled with pip -no-deps so they don't downgrade one another.","createdAt":"2025-12-06T10:46:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3619901170","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7XxMla","author":{"login":"Poilaucul"},"authorAssociation":"NONE","body":"Here are the install.py logs:\n\n<details>\n  <summary>install.py logs</summary>\n\n```YAML\n\n[nix-shell:~/ComfyUI]$ python custom_nodes/tts_audio_suite/install.py \n\n[i] Starting TTS Audio Suite installation\n[i] Python 3.13.9 detected\n[i] Checking requirements.txt dependencies\n/home/atomix/ComfyUI/.venv/lib/python3.13/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n  import pkg_resources\n  [INF0] torchfcpe.mel_tools.nv_mel_extractor: Librosa not found, use torchfcpe.mel_tools.mel_fn_librosa instead.\n[!] Missing 3 requirements.txt packages: keras, faiss-cpu, praat-parselmouth\n[i] Installing missing requirements individually (preserves ComfyUI Manager safeguards)\n[*] Installing keras...\nRequirement already satisfied: keras>=2.9.0 in ./.venv/lib/python3.13/site-packages (3.12.0)\nRequirement already satisfied: absl-py in ./.venv/lib/python3.13/site-packages (from keras>=2.9.0) (2.3.1)\nRequirement already satisfied: numpy in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from keras>=2.9.0) (2.3.4)\nRequirement already satisfied: rich in ./.venv/lib/python3.13/site-packages (from keras>=2.9.0) (14.2.0)\nRequirement already satisfied: namex in ./.venv/lib/python3.13/site-packages (from keras>=2.9.0) (0.1.0)\nRequirement already satisfied: h5py in ./.venv/lib/python3.13/site-packages (from keras>=2.9.0) (3.15.1)\nRequirement already satisfied: optree in ./.venv/lib/python3.13/site-packages (from keras>=2.9.0) (0.18.0)\nRequirement already satisfied: ml-dtypes in ./.venv/lib/python3.13/site-packages (from keras>=2.9.0) (0.5.4)\nRequirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from keras>=2.9.0) (25.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.13/site-packages (from optree->keras>=2.9.0) (4.15.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich->keras>=2.9.0) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich->keras>=2.9.0) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.9.0) (0.1.2)\n\n[*] Installing faiss-cpu...\nRequirement already satisfied: faiss-cpu>=1.7.4 in ./.venv/lib/python3.13/site-packages (1.13.1)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from faiss-cpu>=1.7.4) (2.3.4)\nRequirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from faiss-cpu>=1.7.4) (25.0)\n\n[*] Installing praat-parselmouth...\nRequirement already satisfied: praat-parselmouth>=0.4.6 in ./.venv/lib/python3.13/site-packages (0.4.7)\nRequirement already satisfied: numpy>=1.7.0 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from praat-parselmouth>=0.4.6) (2.3.4)\n\n[i] Checking Linux system dependencies...\n[+] Linux system dependencies check passed\n[i] Detected CUDA 13.0\n[+] PyTorch 2.9.1+cu128 >= 2.6.0 - secure version, skipping installation\n[i] Checking and installing core dependencies (with smart checking)\n[+] Already satisfied: soundfile, sounddevice, jieba, pypinyin, unidecode and 28 others\n[i] Installing 30 missing core packages\n[*] Installing s3tokenizer>=0.1.7...\nCollecting s3tokenizer>=0.1.7\n  Using cached s3tokenizer-0.2.0-py3-none-any.whl\nCollecting pre-commit (from s3tokenizer>=0.1.7)\n  Using cached pre_commit-4.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: numpy in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from s3tokenizer>=0.1.7) (2.3.4)\nRequirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from s3tokenizer>=0.1.7) (2.9.1)\nCollecting onnx (from s3tokenizer>=0.1.7)\n  Using cached onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\nRequirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from s3tokenizer>=0.1.7) (4.67.1)\nRequirement already satisfied: torchaudio in ./.venv/lib/python3.13/site-packages (from s3tokenizer>=0.1.7) (2.9.1)\nRequirement already satisfied: einops in ./.venv/lib/python3.13/site-packages (from s3tokenizer>=0.1.7) (0.8.1)\nRequirement already satisfied: protobuf>=4.25.1 in ./.venv/lib/python3.13/site-packages (from onnx->s3tokenizer>=0.1.7) (6.33.1)\nRequirement already satisfied: typing_extensions>=4.7.1 in ./.venv/lib/python3.13/site-packages (from onnx->s3tokenizer>=0.1.7) (4.15.0)\nRequirement already satisfied: ml_dtypes>=0.5.0 in ./.venv/lib/python3.13/site-packages (from onnx->s3tokenizer>=0.1.7) (0.5.4)\nCollecting cfgv>=2.0.0 (from pre-commit->s3tokenizer>=0.1.7)\n  Using cached cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting identify>=1.0.0 (from pre-commit->s3tokenizer>=0.1.7)\n  Using cached identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\nCollecting nodeenv>=0.11.1 (from pre-commit->s3tokenizer>=0.1.7)\n  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from pre-commit->s3tokenizer>=0.1.7) (6.0.3)\nCollecting virtualenv>=20.10.0 (from pre-commit->s3tokenizer>=0.1.7)\n  Using cached virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\nCollecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->s3tokenizer>=0.1.7)\n  Using cached distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: filelock<4,>=3.12.2 in ./.venv/lib/python3.13/site-packages (from virtualenv>=20.10.0->pre-commit->s3tokenizer>=0.1.7) (3.20.0)\nRequirement already satisfied: platformdirs<5,>=3.9.1 in ./.venv/lib/python3.13/site-packages (from virtualenv>=20.10.0->pre-commit->s3tokenizer>=0.1.7) (4.5.0)\nRequirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (80.9.0)\nRequirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (3.6)\nRequirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (1.13.1.3)\nRequirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch->s3tokenizer>=0.1.7) (3.5.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->s3tokenizer>=0.1.7) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->s3tokenizer>=0.1.7) (3.0.3)\nUsing cached onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\nUsing cached pre_commit-4.5.0-py2.py3-none-any.whl (226 kB)\nUsing cached cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\nUsing cached identify-2.6.15-py2.py3-none-any.whl (99 kB)\nUsing cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\nUsing cached virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\nUsing cached distlib-0.4.0-py2.py3-none-any.whl (469 kB)\nInstalling collected packages: distlib, virtualenv, nodeenv, identify, cfgv, pre-commit, onnx, s3tokenizer\n\nSuccessfully installed cfgv-3.5.0 distlib-0.4.0 identify-2.6.15 nodeenv-1.9.1 onnx-1.20.0 pre-commit-4.5.0 s3tokenizer-0.2.0 virtualenv-20.35.4\n\n[*] Installing vector-quantize-pytorch...\nCollecting vector-quantize-pytorch\n  Using cached vector_quantize_pytorch-1.27.7-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: einops>=0.8.0 in ./.venv/lib/python3.13/site-packages (from vector-quantize-pytorch) (0.8.1)\nRequirement already satisfied: einx>=0.3.0 in ./.venv/lib/python3.13/site-packages (from vector-quantize-pytorch) (0.3.0)\nRequirement already satisfied: torch>=2.4 in ./.venv/lib/python3.13/site-packages (from vector-quantize-pytorch) (2.9.1)\nRequirement already satisfied: numpy in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from einx>=0.3.0->vector-quantize-pytorch) (2.3.4)\nRequirement already satisfied: sympy in ./.venv/lib/python3.13/site-packages (from einx>=0.3.0->vector-quantize-pytorch) (1.14.0)\nRequirement already satisfied: frozendict in ./.venv/lib/python3.13/site-packages (from einx>=0.3.0->vector-quantize-pytorch) (2.4.7)\nRequirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (4.15.0)\nRequirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (80.9.0)\nRequirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (3.6)\nRequirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (1.13.1.3)\nRequirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.4->vector-quantize-pytorch) (3.5.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy->einx>=0.3.0->vector-quantize-pytorch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=2.4->vector-quantize-pytorch) (3.0.3)\nUsing cached vector_quantize_pytorch-1.27.7-py3-none-any.whl (52 kB)\nInstalling collected packages: vector-quantize-pytorch\nSuccessfully installed vector-quantize-pytorch-1.27.7\n\n[*] Installing resemble-perth...\nCollecting resemble-perth\n  Using cached resemble_perth-1.0.1-py3-none-any.whl.metadata (4.8 kB)\nUsing cached resemble_perth-1.0.1-py3-none-any.whl (34.4 MB)\nInstalling collected packages: resemble-perth\nSuccessfully installed resemble-perth-1.0.1\n\n[*] Installing diffusers>=0.30.0...\nCollecting diffusers>=0.30.0\n  Using cached diffusers-0.35.2-py3-none-any.whl.metadata (20 kB)\nCollecting importlib_metadata (from diffusers>=0.30.0)\n  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from diffusers>=0.30.0) (3.20.0)\nRequirement already satisfied: huggingface-hub>=0.34.0 in ./.venv/lib/python3.13/site-packages (from diffusers>=0.30.0) (0.36.0)\nRequirement already satisfied: numpy in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from diffusers>=0.30.0) (2.3.4)\nRequirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from diffusers>=0.30.0) (2025.11.3)\nRequirement already satisfied: requests in /nix/store/6gp1npnskqxkyfr73isk0vf2ygm976h7-python3.13-requests-2.32.5/lib/python3.13/site-packages (from diffusers>=0.30.0) (2.32.5)\nRequirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.13/site-packages (from diffusers>=0.30.0) (0.7.0)\nRequirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (from diffusers>=0.30.0) (12.0.0)\nRequirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.34.0->diffusers>=0.30.0) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.34.0->diffusers>=0.30.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.34.0->diffusers>=0.30.0) (6.0.3)\nRequirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.34.0->diffusers>=0.30.0) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.34.0->diffusers>=0.30.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.34.0->diffusers>=0.30.0) (1.2.0)\nCollecting zipp>=3.20 (from importlib_metadata->diffusers>=0.30.0)\n  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /nix/store/a08p0c01w52xp24ssf52p9h7scm75g0y-python3.13-charset-normalizer-3.4.3/lib/python3.13/site-packages (from requests->diffusers>=0.30.0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from requests->diffusers>=0.30.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /nix/store/1ghpcxwjqb4prf8ql6in7ccklgil5sfp-python3.13-urllib3-2.5.0/lib/python3.13/site-packages (from requests->diffusers>=0.30.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /nix/store/nwn6w97v5hfmld12zddb6viphvd9hsc8-python3.13-certifi-2025.07.14/lib/python3.13/site-packages (from requests->diffusers>=0.30.0) (2025.7.14)\nUsing cached diffusers-0.35.2-py3-none-any.whl (4.1 MB)\nUsing cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\nUsing cached zipp-3.23.0-py3-none-any.whl (10 kB)\nInstalling collected packages: zipp, importlib_metadata, diffusers\n\nSuccessfully installed diffusers-0.35.2 importlib_metadata-8.7.0 zipp-3.23.0\n\n[*] Installing hydra-core>=1.3.0...\nCollecting hydra-core>=1.3.0\n  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: omegaconf<2.4,>=2.2 in ./.venv/lib/python3.13/site-packages (from hydra-core>=1.3.0) (2.3.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in ./.venv/lib/python3.13/site-packages (from hydra-core>=1.3.0) (4.9.3)\nRequirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from hydra-core>=1.3.0) (25.0)\nRequirement already satisfied: PyYAML>=5.1.0 in ./.venv/lib/python3.13/site-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.0) (6.0.3)\nUsing cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\nInstalling collected packages: hydra-core\nSuccessfully installed hydra-core-1.3.2\n\n[*] Installing lazy_loader>=0.1...\nCollecting lazy_loader>=0.1\n  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from lazy_loader>=0.1) (25.0)\nUsing cached lazy_loader-0.4-py3-none-any.whl (12 kB)\nInstalling collected packages: lazy_loader\nSuccessfully installed lazy_loader-0.4\n\n[*] Installing msgpack>=1.0...\nCollecting msgpack>=1.0\n  Using cached msgpack-1.1.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\nUsing cached msgpack-1.1.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (424 kB)\nInstalling collected packages: msgpack\nSuccessfully installed msgpack-1.1.2\n\n[*] Installing pooch>=1.1...\nCollecting pooch>=1.1\n  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from pooch>=1.1) (4.5.0)\nRequirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from pooch>=1.1) (25.0)\nRequirement already satisfied: requests>=2.19.0 in /nix/store/6gp1npnskqxkyfr73isk0vf2ygm976h7-python3.13-requests-2.32.5/lib/python3.13/site-packages (from pooch>=1.1) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /nix/store/a08p0c01w52xp24ssf52p9h7scm75g0y-python3.13-charset-normalizer-3.4.3/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /nix/store/1ghpcxwjqb4prf8ql6in7ccklgil5sfp-python3.13-urllib3-2.5.0/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /nix/store/nwn6w97v5hfmld12zddb6viphvd9hsc8-python3.13-certifi-2025.07.14/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1) (2025.7.14)\nUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\nInstalling collected packages: pooch\nSuccessfully installed pooch-1.8.2\n\n[*] Installing soxr>=0.3.2...\nCollecting soxr>=0.3.2\n  Using cached soxr-1.0.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\nRequirement already satisfied: numpy in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from soxr>=0.3.2) (2.3.4)\nUsing cached soxr-1.0.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (238 kB)\nInstalling collected packages: soxr\nSuccessfully installed soxr-1.0.0\n\n[*] Installing decorator>=4.3.0...\nCollecting decorator>=4.3.0\n  Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\nUsing cached decorator-5.2.1-py3-none-any.whl (9.2 kB)\nInstalling collected packages: decorator\nSuccessfully installed decorator-5.2.1\n\n[*] Installing ml-collections...\nCollecting ml-collections\n  Using cached ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: absl-py in ./.venv/lib/python3.13/site-packages (from ml-collections) (2.3.1)\nRequirement already satisfied: PyYAML in ./.venv/lib/python3.13/site-packages (from ml-collections) (6.0.3)\nUsing cached ml_collections-1.1.0-py3-none-any.whl (76 kB)\nInstalling collected packages: ml-collections\nSuccessfully installed ml-collections-1.1.0\n\n[*] Installing scikit-learn>=1.1.0...\nCollecting scikit-learn>=1.1.0\n  Using cached scikit_learn-1.7.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numpy>=1.22.0 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from scikit-learn>=1.1.0) (2.3.4)\nRequirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn>=1.1.0) (1.16.3)\nRequirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn>=1.1.0) (1.5.2)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0)\n  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nUsing cached scikit_learn-1.7.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.4 MB)\nUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nInstalling collected packages: threadpoolctl, scikit-learn\n\nSuccessfully installed scikit-learn-1.7.2 threadpoolctl-3.6.0\n\n[*] Installing boto3...\nCollecting boto3\n  Downloading boto3-1.42.4-py3-none-any.whl.metadata (6.8 kB)\nCollecting botocore<1.43.0,>=1.42.4 (from boto3)\n  Downloading botocore-1.42.4-py3-none-any.whl.metadata (5.9 kB)\nCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\nCollecting s3transfer<0.17.0,>=0.16.0 (from boto3)\n  Using cached s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.venv/lib/python3.13/site-packages (from botocore<1.43.0,>=1.42.4->boto3) (2.9.0.post0)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /nix/store/1ghpcxwjqb4prf8ql6in7ccklgil5sfp-python3.13-urllib3-2.5.0/lib/python3.13/site-packages (from botocore<1.43.0,>=1.42.4->boto3) (2.5.0)\nRequirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.4->boto3) (1.17.0)\nDownloading boto3-1.42.4-py3-none-any.whl (140 kB)\nDownloading botocore-1.42.4-py3-none-any.whl (14.5 MB)\n    14.5/14.5 MB 45.5 MB/s  0:00:00\nUsing cached jmespath-1.0.1-py3-none-any.whl (20 kB)\nUsing cached s3transfer-0.16.0-py3-none-any.whl (86 kB)\nInstalling collected packages: jmespath, botocore, s3transfer, boto3\n\nSuccessfully installed boto3-1.42.4 botocore-1.42.4 jmespath-1.0.1 s3transfer-0.16.0\n\n[*] Installing google-cloud-storage...\nCollecting google-cloud-storage\n  Using cached google_cloud_storage-3.6.0-py3-none-any.whl.metadata (13 kB)\nCollecting google-auth<3.0.0,>=2.26.1 (from google-cloud-storage)\n  Using cached google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\nCollecting google-api-core<3.0.0,>=2.27.0 (from google-cloud-storage)\n  Using cached google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\nCollecting google-cloud-core<3.0.0,>=2.4.2 (from google-cloud-storage)\n  Using cached google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\nCollecting google-resumable-media<3.0.0,>=2.7.2 (from google-cloud-storage)\n  Using cached google_resumable_media-2.8.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: requests<3.0.0,>=2.22.0 in /nix/store/6gp1npnskqxkyfr73isk0vf2ygm976h7-python3.13-requests-2.32.5/lib/python3.13/site-packages (from google-cloud-storage) (2.32.5)\nCollecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage)\n  Using cached google_crc32c-1.7.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nCollecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage)\n  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in ./.venv/lib/python3.13/site-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage) (6.33.1)\nCollecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage)\n  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\nCollecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.26.1->google-cloud-storage)\n  Using cached cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.26.1->google-cloud-storage)\n  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.26.1->google-cloud-storage)\n  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /nix/store/a08p0c01w52xp24ssf52p9h7scm75g0y-python3.13-charset-normalizer-3.4.3/lib/python3.13/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /nix/store/1ghpcxwjqb4prf8ql6in7ccklgil5sfp-python3.13-urllib3-2.5.0/lib/python3.13/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /nix/store/nwn6w97v5hfmld12zddb6viphvd9hsc8-python3.13-certifi-2025.07.14/lib/python3.13/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2025.7.14)\nCollecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.26.1->google-cloud-storage)\n  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\nUsing cached google_cloud_storage-3.6.0-py3-none-any.whl (299 kB)\nUsing cached google_api_core-2.28.1-py3-none-any.whl (173 kB)\nUsing cached google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\nUsing cached cachetools-6.2.2-py3-none-any.whl (11 kB)\nUsing cached google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\nUsing cached google_crc32c-1.7.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\nUsing cached google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\nUsing cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\nUsing cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\nUsing cached rsa-4.9.1-py3-none-any.whl (34 kB)\nUsing cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\nUsing cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\nInstalling collected packages: pyasn1, proto-plus, googleapis-common-protos, google-crc32c, cachetools, rsa, pyasn1-modules, google-resumable-media, google-auth, google-api-core, google-cloud-core, google-cloud-storage\n\nSuccessfully installed cachetools-6.2.2 google-api-core-2.28.1 google-auth-2.43.0 google-cloud-core-2.5.0 google-cloud-storage-3.6.0 google-crc32c-1.7.1 google-resumable-media-2.8.0 googleapis-common-protos-1.72.0 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1\n\n[*] Installing argbind>=0.3.7...\nCollecting argbind>=0.3.7\n  Using cached argbind-0.3.9-py2.py3-none-any.whl\nRequirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from argbind>=0.3.7) (6.0.3)\nCollecting docstring-parser (from argbind>=0.3.7)\n  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\nUsing cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\nInstalling collected packages: docstring-parser, argbind\n\nSuccessfully installed argbind-0.3.9 docstring-parser-0.17.0\n\n[*] Installing rotary_embedding_torch...\nCollecting rotary_embedding_torch\n  Using cached rotary_embedding_torch-0.8.9-py3-none-any.whl.metadata (883 bytes)\nRequirement already satisfied: einops>=0.7 in ./.venv/lib/python3.13/site-packages (from rotary_embedding_torch) (0.8.1)\nRequirement already satisfied: torch>=2.0 in ./.venv/lib/python3.13/site-packages (from rotary_embedding_torch) (2.9.1)\nRequirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (4.15.0)\nRequirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (80.9.0)\nRequirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (3.6)\nRequirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (1.13.1.3)\nRequirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.0->rotary_embedding_torch) (3.5.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0->rotary_embedding_torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=2.0->rotary_embedding_torch) (3.0.3)\nUsing cached rotary_embedding_torch-0.8.9-py3-none-any.whl (5.9 kB)\nInstalling collected packages: rotary_embedding_torch\nSuccessfully installed rotary_embedding_torch-0.8.9\n\n[*] Installing matplotlib...\nCollecting matplotlib\n  Using cached matplotlib-3.10.7-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nCollecting contourpy>=1.0.1 (from matplotlib)\n  Using cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting cycler>=0.10 (from matplotlib)\n  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting fonttools>=4.22.0 (from matplotlib)\n  Using cached fonttools-4.61.0-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (113 kB)\nCollecting kiwisolver>=1.3.1 (from matplotlib)\n  Using cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\nRequirement already satisfied: numpy>=1.23 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from matplotlib) (2.3.4)\nRequirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (12.0.0)\nRequirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nUsing cached matplotlib-3.10.7-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\nUsing cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\nUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\nUsing cached fonttools-4.61.0-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\nUsing cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\nInstalling collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n\nSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.0 kiwisolver-1.4.9 matplotlib-3.10.7\n\n[*] Installing audioread>=2.1.9...\nCollecting audioread>=2.1.9\n  Using cached audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting standard-aifc (from audioread>=2.1.9)\n  Using cached standard_aifc-3.13.0-py3-none-any.whl.metadata (969 bytes)\nCollecting standard-sunau (from audioread>=2.1.9)\n  Using cached standard_sunau-3.13.0-py3-none-any.whl.metadata (914 bytes)\nCollecting standard-chunk (from standard-aifc->audioread>=2.1.9)\n  Using cached standard_chunk-3.13.0-py3-none-any.whl.metadata (860 bytes)\nCollecting audioop-lts (from standard-aifc->audioread>=2.1.9)\n  Using cached audioop_lts-0.2.2-cp313-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (2.0 kB)\nUsing cached audioread-3.1.0-py3-none-any.whl (23 kB)\nUsing cached standard_aifc-3.13.0-py3-none-any.whl (10 kB)\nUsing cached audioop_lts-0.2.2-cp313-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (85 kB)\nUsing cached standard_chunk-3.13.0-py3-none-any.whl (4.9 kB)\nUsing cached standard_sunau-3.13.0-py3-none-any.whl (7.4 kB)\nInstalling collected packages: standard-chunk, audioop-lts, standard-sunau, standard-aifc, audioread\n\nSuccessfully installed audioop-lts-0.2.2 audioread-3.1.0 standard-aifc-3.13.0 standard-chunk-3.13.0 standard-sunau-3.13.0\n\n[*] Installing threadpoolctl>=3.1.0...\nRequirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (3.6.0)\n\n[*] Installing flatten-dict...\nCollecting flatten-dict\n  Using cached flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: six<2.0,>=1.12 in ./.venv/lib/python3.13/site-packages (from flatten-dict) (1.17.0)\nUsing cached flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\nInstalling collected packages: flatten-dict\nSuccessfully installed flatten-dict-0.4.2\n\n[*] Installing ffmpy...\nCollecting ffmpy\n  Using cached ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\nUsing cached ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\nInstalling collected packages: ffmpy\nSuccessfully installed ffmpy-1.0.0\n\n[*] Installing importlib-resources...\nCollecting importlib-resources\n  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\nUsing cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\nInstalling collected packages: importlib-resources\nSuccessfully installed importlib-resources-6.5.2\n\n[*] Installing randomname...\nCollecting randomname\n  Using cached randomname-0.2.1-py3-none-any.whl\nCollecting fire (from randomname)\n  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: termcolor in ./.venv/lib/python3.13/site-packages (from fire->randomname) (3.2.0)\nUsing cached fire-0.7.1-py3-none-any.whl (115 kB)\nInstalling collected packages: fire, randomname\n\nSuccessfully installed fire-0.7.1 randomname-0.2.1\n\n[*] Installing markdown2...\nCollecting markdown2\n  Using cached markdown2-2.5.4-py3-none-any.whl.metadata (2.1 kB)\nUsing cached markdown2-2.5.4-py3-none-any.whl (49 kB)\nInstalling collected packages: markdown2\nSuccessfully installed markdown2-2.5.4\n\n[*] Installing pyloudnorm...\nCollecting pyloudnorm\n  Using cached pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: scipy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from pyloudnorm) (1.16.3)\nRequirement already satisfied: numpy>=1.14.2 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from pyloudnorm) (2.3.4)\nCollecting future>=0.16.0 (from pyloudnorm)\n  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\nUsing cached pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\nUsing cached future-1.0.0-py3-none-any.whl (491 kB)\nInstalling collected packages: future, pyloudnorm\n\nSuccessfully installed future-1.0.0 pyloudnorm-0.1.1\n\n[*] Installing pystoi...\nCollecting pystoi\n  Using cached pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: numpy in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from pystoi) (2.3.4)\nRequirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from pystoi) (1.16.3)\nUsing cached pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\nInstalling collected packages: pystoi\nSuccessfully installed pystoi-0.4.1\n\n[*] Installing torch-stoi...\nCollecting torch-stoi\n  Using cached torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: numpy in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from torch-stoi) (2.3.4)\nRequirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from torch-stoi) (2.9.1)\nRequirement already satisfied: pystoi in ./.venv/lib/python3.13/site-packages (from torch-stoi) (0.4.1)\nRequirement already satisfied: torchaudio in ./.venv/lib/python3.13/site-packages (from torch-stoi) (2.9.1)\nRequirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from pystoi->torch-stoi) (1.16.3)\nRequirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (4.15.0)\nRequirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (80.9.0)\nRequirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (3.6)\nRequirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (1.13.1.3)\nRequirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch->torch-stoi) (3.5.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch->torch-stoi) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->torch-stoi) (3.0.3)\nUsing cached torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\nInstalling collected packages: torch-stoi\nSuccessfully installed torch-stoi-0.2.3\n\n[*] Installing ipython...\nCollecting ipython\n  Using cached ipython-9.8.0-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.13/site-packages (from ipython) (5.2.1)\nCollecting ipython-pygments-lexers>=1.0.0 (from ipython)\n  Using cached ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\nCollecting jedi>=0.18.1 (from ipython)\n  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting matplotlib-inline>=0.1.5 (from ipython)\n  Using cached matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting pexpect>4.3 (from ipython)\n  Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython)\n  Using cached prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.13/site-packages (from ipython) (2.19.2)\nCollecting stack_data>=0.6.0 (from ipython)\n  Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\nCollecting traitlets>=5.13.0 (from ipython)\n  Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\nCollecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython)\n  Using cached wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\nCollecting parso<0.9.0,>=0.8.4 (from jedi>=0.18.1->ipython)\n  Using cached parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\nCollecting ptyprocess>=0.5 (from pexpect>4.3->ipython)\n  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting executing>=1.2.0 (from stack_data>=0.6.0->ipython)\n  Using cached executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting asttokens>=2.1.0 (from stack_data>=0.6.0->ipython)\n  Using cached asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\nCollecting pure-eval (from stack_data>=0.6.0->ipython)\n  Using cached pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nUsing cached ipython-9.8.0-py3-none-any.whl (621 kB)\nUsing cached prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\nUsing cached ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\nUsing cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\nUsing cached parso-0.8.5-py2.py3-none-any.whl (106 kB)\nUsing cached matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\nUsing cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\nUsing cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\nUsing cached stack_data-0.6.3-py3-none-any.whl (24 kB)\nUsing cached asttokens-3.0.1-py3-none-any.whl (27 kB)\nUsing cached executing-2.2.1-py2.py3-none-any.whl (28 kB)\nUsing cached traitlets-5.14.3-py3-none-any.whl (85 kB)\nUsing cached pure_eval-0.2.3-py3-none-any.whl (11 kB)\nUsing cached wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\nInstalling collected packages: pure-eval, ptyprocess, wcwidth, traitlets, pexpect, parso, ipython-pygments-lexers, executing, asttokens, stack_data, prompt_toolkit, matplotlib-inline, jedi, ipython\n\nSuccessfully installed asttokens-3.0.1 executing-2.2.1 ipython-9.8.0 ipython-pygments-lexers-1.1.1 jedi-0.19.2 matplotlib-inline-0.2.1 parso-0.8.5 pexpect-4.9.0 prompt_toolkit-3.0.52 ptyprocess-0.7.0 pure-eval-0.2.3 stack_data-0.6.3 traitlets-5.14.3 wcwidth-0.2.14\n\n[*] Installing tensorboard...\nCollecting tensorboard\n  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.13/site-packages (from tensorboard) (2.3.1)\nCollecting grpcio>=1.48.2 (from tensorboard)\n  Using cached grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\nCollecting markdown>=2.6.8 (from tensorboard)\n  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: numpy>=1.12.0 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from tensorboard) (2.3.4)\nRequirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from tensorboard) (25.0)\nRequirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from tensorboard) (12.0.0)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.venv/lib/python3.13/site-packages (from tensorboard) (6.33.1)\nRequirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.13/site-packages (from tensorboard) (80.9.0)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard)\n  Using cached werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: typing-extensions~=4.12 in ./.venv/lib/python3.13/site-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\nRequirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\nUsing cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\nUsing cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\nUsing cached grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\nUsing cached markdown-3.10-py3-none-any.whl (107 kB)\nUsing cached werkzeug-3.1.4-py3-none-any.whl (224 kB)\nInstalling collected packages: werkzeug, tensorboard-data-server, markdown, grpcio, tensorboard\n\nSuccessfully installed grpcio-1.76.0 markdown-3.10 tensorboard-2.20.0 tensorboard-data-server-0.7.2 werkzeug-3.1.4\n\n[*] Installing julius...\nCollecting julius\n  Using cached julius-0.2.7-py3-none-any.whl\nRequirement already satisfied: torch>=1.7.0 in ./.venv/lib/python3.13/site-packages (from julius) (2.9.1)\nRequirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (4.15.0)\nRequirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (80.9.0)\nRequirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (3.6)\nRequirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (1.13.1.3)\nRequirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=1.7.0->julius) (3.5.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.7.0->julius) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.7.0->julius) (3.0.3)\nInstalling collected packages: julius\nSuccessfully installed julius-0.2.7\n\n[i] Checking numpy compatibility\n[i] Python 3.13+ detected - requires NumPy 2.1.0 or newer\n[i] Current numpy version: 2.3.4\n[!] NumPy 2.3.4 may cause issues - constraining to <2.3.0\n[*] Installing numpy with version constraints...\nCollecting numpy<2.3.0,>=2.1.0\n  Using cached numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nUsing cached numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\nInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.3.4\n    Not uninstalling numpy at /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages, outside environment /home/atomix/ComfyUI/.venv\n    Can't uninstall 'numpy'. No files were found to uninstall.\nSuccessfully installed numpy-2.2.6\n\n[i] NumPy compatibility check complete\n[i] NumPy 2.3.4 supports audio-separator - installing\n[*] Installing audio-separator for enhanced vocal removal...\nCollecting audio-separator>=0.35.2\n  Using cached audio_separator-0.40.0-py3-none-any.whl.metadata (36 kB)\nRequirement already satisfied: audioop-lts>=0.2.1 in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (0.2.2)\nCollecting beartype<0.19.0,>=0.18.5 (from audio-separator>=0.35.2)\n  Using cached beartype-0.18.5-py3-none-any.whl.metadata (30 kB)\nCollecting diffq>=0.2 (from audio-separator>=0.35.2)\n  Using cached diffq-0.2.4-cp313-cp313-linux_x86_64.whl\nRequirement already satisfied: einops>=0.7 in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (0.8.1)\nRequirement already satisfied: julius>=0.2 in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (0.2.7)\nCollecting librosa>=0.10 (from audio-separator>=0.35.2)\n  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: ml_collections in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (1.1.0)\nRequirement already satisfied: numpy>=2 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from audio-separator>=0.35.2) (2.3.4)\nCollecting onnx-weekly (from audio-separator>=0.35.2)\n  Using cached onnx_weekly-1.21.0.dev20251201-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.6 kB)\nCollecting onnx2torch-py313>=1.6 (from audio-separator>=0.35.2)\n  Using cached onnx2torch_py313-1.6.0-py3-none-any.whl.metadata (23 kB)\nCollecting pydub>=0.25 (from audio-separator>=0.35.2)\n  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (6.0.3)\nRequirement already satisfied: requests>=2 in /nix/store/6gp1npnskqxkyfr73isk0vf2ygm976h7-python3.13-requests-2.32.5/lib/python3.13/site-packages (from audio-separator>=0.35.2) (2.32.5)\nCollecting resampy>=0.4 (from audio-separator>=0.35.2)\n  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\nCollecting rotary-embedding-torch<0.7.0,>=0.6.1 (from audio-separator>=0.35.2)\n  Using cached rotary_embedding_torch-0.6.5-py3-none-any.whl.metadata (678 bytes)\nCollecting samplerate==0.1.0 (from audio-separator>=0.35.2)\n  Using cached samplerate-0.1.0-py2.py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: scipy<2.0.0,>=1.13.0 in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (1.16.3)\nRequirement already satisfied: six>=1.16 in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (1.17.0)\nRequirement already satisfied: soundfile>=0.12 in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (0.13.1)\nRequirement already satisfied: torch>=2.3 in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (2.9.1)\nRequirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from audio-separator>=0.35.2) (4.67.1)\nRequirement already satisfied: cffi>=1.0.0 in ./.venv/lib/python3.13/site-packages (from samplerate==0.1.0->audio-separator>=0.35.2) (2.0.0)\nRequirement already satisfied: pycparser in ./.venv/lib/python3.13/site-packages (from cffi>=1.0.0->samplerate==0.1.0->audio-separator>=0.35.2) (2.23)\nCollecting Cython (from diffq>=0.2->audio-separator>=0.35.2)\n  Using cached cython-3.2.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: audioread>=2.1.9 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (3.1.0)\nCollecting numba>=0.51.0 (from librosa>=0.10->audio-separator>=0.35.2)\n  Using cached numba-0.62.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\nRequirement already satisfied: scikit-learn>=1.1.0 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (1.7.2)\nRequirement already satisfied: joblib>=1.0 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (1.5.2)\nRequirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (5.2.1)\nRequirement already satisfied: pooch>=1.1 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (1.0.0)\nRequirement already satisfied: typing_extensions>=4.1.1 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (4.15.0)\nRequirement already satisfied: lazy_loader>=0.1 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (0.4)\nRequirement already satisfied: msgpack>=1.0 in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (1.1.2)\nRequirement already satisfied: standard-aifc in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (3.13.0)\nRequirement already satisfied: standard-sunau in ./.venv/lib/python3.13/site-packages (from librosa>=0.10->audio-separator>=0.35.2) (3.13.0)\nRequirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from lazy_loader>=0.1->librosa>=0.10->audio-separator>=0.35.2) (25.0)\nCollecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.51.0->librosa>=0.10->audio-separator>=0.35.2)\n  Using cached llvmlite-0.45.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.13/site-packages (from onnx2torch-py313>=1.6->audio-separator>=0.35.2) (0.24.1)\nRequirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from pooch>=1.1->librosa>=0.10->audio-separator>=0.35.2) (4.5.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /nix/store/a08p0c01w52xp24ssf52p9h7scm75g0y-python3.13-charset-normalizer-3.4.3/lib/python3.13/site-packages (from requests>=2->audio-separator>=0.35.2) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from requests>=2->audio-separator>=0.35.2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /nix/store/1ghpcxwjqb4prf8ql6in7ccklgil5sfp-python3.13-urllib3-2.5.0/lib/python3.13/site-packages (from requests>=2->audio-separator>=0.35.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /nix/store/nwn6w97v5hfmld12zddb6viphvd9hsc8-python3.13-certifi-2025.07.14/lib/python3.13/site-packages (from requests>=2->audio-separator>=0.35.2) (2025.7.14)\nRequirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn>=1.1.0->librosa>=0.10->audio-separator>=0.35.2) (3.6.0)\nRequirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (3.20.0)\nRequirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (80.9.0)\nRequirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (3.6)\nRequirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (1.13.1.3)\nRequirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=2.3->audio-separator>=0.35.2) (3.5.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.3->audio-separator>=0.35.2) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.13/site-packages (from torchvision>=0.9.0->onnx2torch-py313>=1.6->audio-separator>=0.35.2) (12.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=2.3->audio-separator>=0.35.2) (3.0.3)\nRequirement already satisfied: absl-py in ./.venv/lib/python3.13/site-packages (from ml_collections->audio-separator>=0.35.2) (2.3.1)\nRequirement already satisfied: protobuf>=4.25.1 in ./.venv/lib/python3.13/site-packages (from onnx-weekly->audio-separator>=0.35.2) (6.33.1)\nRequirement already satisfied: ml_dtypes>=0.5.0 in ./.venv/lib/python3.13/site-packages (from onnx-weekly->audio-separator>=0.35.2) (0.5.4)\nRequirement already satisfied: standard-chunk in ./.venv/lib/python3.13/site-packages (from standard-aifc->librosa>=0.10->audio-separator>=0.35.2) (3.13.0)\nUsing cached audio_separator-0.40.0-py3-none-any.whl (385 kB)\nUsing cached samplerate-0.1.0-py2.py3-none-any.whl (4.0 MB)\nUsing cached beartype-0.18.5-py3-none-any.whl (917 kB)\nUsing cached rotary_embedding_torch-0.6.5-py3-none-any.whl (5.5 kB)\nUsing cached librosa-0.11.0-py3-none-any.whl (260 kB)\nUsing cached numba-0.62.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\nUsing cached llvmlite-0.45.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\nUsing cached onnx2torch_py313-1.6.0-py3-none-any.whl (81 kB)\nUsing cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\nUsing cached resampy-0.4.3-py3-none-any.whl (3.1 MB)\nUsing cached cython-3.2.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\nUsing cached onnx_weekly-1.21.0.dev20251201-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\nInstalling collected packages: pydub, llvmlite, Cython, beartype, samplerate, onnx-weekly, numba, resampy, librosa, rotary-embedding-torch, diffq, onnx2torch-py313, audio-separator\n  Attempting uninstall: rotary-embedding-torch\n    Found existing installation: rotary-embedding-torch 0.8.9\n    Uninstalling rotary-embedding-torch-0.8.9:\n      Successfully uninstalled rotary-embedding-torch-0.8.9\n\nSuccessfully installed Cython-3.2.2 audio-separator-0.40.0 beartype-0.18.5 diffq-0.2.4 librosa-0.11.0 llvmlite-0.45.1 numba-0.62.1 onnx-weekly-1.21.0.dev20251201 onnx2torch-py313-1.6.0 pydub-0.25.1 resampy-0.4.3 rotary-embedding-torch-0.6.5 samplerate-0.1.0\n\n[i] Installing RVC voice conversion dependencies\n[*] Installing monotonic-alignment-search...\nRequirement already satisfied: monotonic-alignment-search in ./.venv/lib/python3.13/site-packages (0.2.1)\nRequirement already satisfied: numpy>=1.21.6 in /nix/store/qbljpi28kpxkjaibg0avqqn6adqcg744-python3.13-numpy-2.3.4/lib/python3.13/site-packages (from monotonic-alignment-search) (2.3.4)\n\n[i] Detected CUDA 13.0\n[i] Linux + CUDA detected - attempting faiss-gpu for better RVC performance\n[*] Installing faiss-gpu-cu12>=1.7.4 for GPU acceleration (--no-deps)...\nCollecting faiss-gpu-cu12>=1.7.4\n  Using cached faiss_gpu_cu12-1.13.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nUsing cached faiss_gpu_cu12-1.13.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\nInstalling collected packages: faiss-gpu-cu12\nSuccessfully installed faiss-gpu-cu12-1.13.0\n\n[+] faiss-gpu installed with --no-deps - RVC will use GPU acceleration without downgrading numpy\n[i] Pre-installing safe dependencies for gradio and opencv-python\n[*] Pre-installing: fastapi<1.0,>=0.115.2...\nCollecting fastapi<1.0,>=0.115.2\n  Downloading fastapi-0.123.10-py3-none-any.whl.metadata (30 kB)\nCollecting starlette<0.51.0,>=0.40.0 (from fastapi<1.0,>=0.115.2)\n  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in ./.venv/lib/python3.13/site-packages (from fastapi<1.0,>=0.115.2) (2.12.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.13/site-packages (from fastapi<1.0,>=0.115.2) (4.15.0)\nCollecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.2)\n  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0,>=0.115.2) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0,>=0.115.2) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0,>=0.115.2) (0.4.2)\nRequirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.13/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1.0,>=0.115.2) (4.12.0)\nRequirement already satisfied: idna>=2.8 in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1.0,>=0.115.2) (3.11)\nDownloading fastapi-0.123.10-py3-none-any.whl (111 kB)\nUsing cached starlette-0.50.0-py3-none-any.whl (74 kB)\nUsing cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\nInstalling collected packages: annotated-doc, starlette, fastapi\n\nSuccessfully installed annotated-doc-0.0.4 fastapi-0.123.10 starlette-0.50.0\n\n[*] Pre-installing: starlette<0.50.0,>=0.40.0...\nCollecting starlette<0.50.0,>=0.40.0\n  Using cached starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.13/site-packages (from starlette<0.50.0,>=0.40.0) (4.12.0)\nRequirement already satisfied: idna>=2.8 in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0) (3.11)\nUsing cached starlette-0.49.3-py3-none-any.whl (74 kB)\nInstalling collected packages: starlette\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.50.0\n    Uninstalling starlette-0.50.0:\n      Successfully uninstalled starlette-0.50.0\nSuccessfully installed starlette-0.49.3\n\n[*] Pre-installing: gradio-client==1.13.3...\nCollecting gradio-client==1.13.3\n  Using cached gradio_client-1.13.3-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from gradio-client==1.13.3) (2025.10.0)\nRequirement already satisfied: httpx>=0.24.1 in ./.venv/lib/python3.13/site-packages (from gradio-client==1.13.3) (0.28.1)\nRequirement already satisfied: huggingface-hub<2.0,>=0.19.3 in ./.venv/lib/python3.13/site-packages (from gradio-client==1.13.3) (0.36.0)\nRequirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from gradio-client==1.13.3) (25.0)\nRequirement already satisfied: typing-extensions~=4.0 in ./.venv/lib/python3.13/site-packages (from gradio-client==1.13.3) (4.15.0)\nCollecting websockets<16.0,>=13.0 (from gradio-client==1.13.3)\n  Using cached websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.19.3->gradio-client==1.13.3) (3.20.0)\nRequirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.19.3->gradio-client==1.13.3) (6.0.3)\nRequirement already satisfied: requests in /nix/store/6gp1npnskqxkyfr73isk0vf2ygm976h7-python3.13-requests-2.32.5/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.19.3->gradio-client==1.13.3) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.19.3->gradio-client==1.13.3) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.19.3->gradio-client==1.13.3) (1.2.0)\nRequirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx>=0.24.1->gradio-client==1.13.3) (4.12.0)\nRequirement already satisfied: certifi in /nix/store/nwn6w97v5hfmld12zddb6viphvd9hsc8-python3.13-certifi-2025.07.14/lib/python3.13/site-packages (from httpx>=0.24.1->gradio-client==1.13.3) (2025.7.14)\nRequirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx>=0.24.1->gradio-client==1.13.3) (1.0.9)\nRequirement already satisfied: idna in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from httpx>=0.24.1->gradio-client==1.13.3) (3.11)\nRequirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio-client==1.13.3) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /nix/store/a08p0c01w52xp24ssf52p9h7scm75g0y-python3.13-charset-normalizer-3.4.3/lib/python3.13/site-packages (from requests->huggingface-hub<2.0,>=0.19.3->gradio-client==1.13.3) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /nix/store/1ghpcxwjqb4prf8ql6in7ccklgil5sfp-python3.13-urllib3-2.5.0/lib/python3.13/site-packages (from requests->huggingface-hub<2.0,>=0.19.3->gradio-client==1.13.3) (2.5.0)\nUsing cached gradio_client-1.13.3-py3-none-any.whl (325 kB)\nUsing cached websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\nInstalling collected packages: websockets, gradio-client\n\nSuccessfully installed gradio-client-1.13.3 websockets-15.0.1\n\n[*] Pre-installing: websockets<16.0,>=13.0...\nRequirement already satisfied: websockets<16.0,>=13.0 in ./.venv/lib/python3.13/site-packages (15.0.1)\n\n[*] Pre-installing: python-multipart>=0.0.18...\nCollecting python-multipart>=0.0.18\n  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nUsing cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\nInstalling collected packages: python-multipart\nSuccessfully installed python-multipart-0.0.20\n\n[*] Pre-installing: uvicorn>=0.14.0...\nCollecting uvicorn>=0.14.0\n  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: click>=7.0 in ./.venv/lib/python3.13/site-packages (from uvicorn>=0.14.0) (8.3.1)\nRequirement already satisfied: h11>=0.8 in ./.venv/lib/python3.13/site-packages (from uvicorn>=0.14.0) (0.16.0)\nUsing cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\nInstalling collected packages: uvicorn\nSuccessfully installed uvicorn-0.38.0\n\n[*] Pre-installing: annotated-doc>=0.0.2...\nRequirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.13/site-packages (0.0.4)\n\n[!] Installing problematic packages with --no-deps to prevent conflicts\n[*] Installing librosa (--no-deps)...\nRequirement already satisfied: librosa in ./.venv/lib/python3.13/site-packages (0.11.0)\n\n[*] Installing descript-audio-codec (--no-deps)...\nCollecting descript-audio-codec\n  Using cached descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\nUsing cached descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\nInstalling collected packages: descript-audio-codec\nSuccessfully installed descript-audio-codec-1.0.0\n\n[*] Installing descript-audiotools (--no-deps)...\nCollecting descript-audiotools\n  Using cached descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\nUsing cached descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\nInstalling collected packages: descript-audiotools\nSuccessfully installed descript-audiotools-0.7.2\n\n[*] Installing cached-path (--no-deps)...\nCollecting cached-path\n  Using cached cached_path-1.8.0-py3-none-any.whl.metadata (19 kB)\nUsing cached cached_path-1.8.0-py3-none-any.whl (37 kB)\nInstalling collected packages: cached-path\nSuccessfully installed cached-path-1.8.0\n\n[*] Installing torchcrepe (--no-deps)...\nCollecting torchcrepe\n  Using cached torchcrepe-0.0.24-py3-none-any.whl.metadata (8.3 kB)\nUsing cached torchcrepe-0.0.24-py3-none-any.whl (72.3 MB)\nInstalling collected packages: torchcrepe\nSuccessfully installed torchcrepe-0.0.24\n\n[*] Installing onnxruntime (--no-deps)...\nCollecting onnxruntime\n  Using cached onnxruntime-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nUsing cached onnxruntime-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\nInstalling collected packages: onnxruntime\nSuccessfully installed onnxruntime-1.23.2\n\n[*] Installing opencv-python (--no-deps)...\nCollecting opencv-python\n  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\nUsing cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.12.0.88\n\n[*] Installing gradio (--no-deps)...\nCollecting gradio\n  Using cached gradio-6.0.2-py3-none-any.whl.metadata (16 kB)\nUsing cached gradio-6.0.2-py3-none-any.whl (21.6 MB)\nInstalling collected packages: gradio\nSuccessfully installed gradio-6.0.2\n\n[i] Installing VibeVoice TTS engine\n[i] Installing VibeVoice safe dependencies first\n[*] Installing aiortc...\nCollecting aiortc\n  Using cached aiortc-1.14.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting aioice<1.0.0,>=0.10.1 (from aiortc)\n  Using cached aioice-0.10.2-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: av<17.0.0,>=14.0.0 in ./.venv/lib/python3.13/site-packages (from aiortc) (16.0.1)\nRequirement already satisfied: cryptography>=44.0.0 in ./.venv/lib/python3.13/site-packages (from aiortc) (46.0.3)\nRequirement already satisfied: google-crc32c>=1.1 in ./.venv/lib/python3.13/site-packages (from aiortc) (1.7.1)\nCollecting pyee>=13.0.0 (from aiortc)\n  Using cached pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting pylibsrtp>=0.10.0 (from aiortc)\n  Using cached pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (4.0 kB)\nCollecting pyopenssl>=25.0.0 (from aiortc)\n  Using cached pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\nCollecting dnspython>=2.0.0 (from aioice<1.0.0,>=0.10.1->aiortc)\n  Using cached dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\nCollecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.10.1->aiortc)\n  Using cached ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.13/site-packages (from cryptography>=44.0.0->aiortc) (2.0.0)\nRequirement already satisfied: pycparser in ./.venv/lib/python3.13/site-packages (from cffi>=2.0.0->cryptography>=44.0.0->aiortc) (2.23)\nRequirement already satisfied: typing-extensions in ./.venv/lib/python3.13/site-packages (from pyee>=13.0.0->aiortc) (4.15.0)\nUsing cached aiortc-1.14.0-py3-none-any.whl (93 kB)\nUsing cached aioice-0.10.2-py3-none-any.whl (24 kB)\nUsing cached dnspython-2.8.0-py3-none-any.whl (331 kB)\nUsing cached ifaddr-0.2.0-py3-none-any.whl (12 kB)\nUsing cached pyee-13.0.0-py3-none-any.whl (15 kB)\nUsing cached pylibsrtp-1.0.0-cp310-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\nUsing cached pyopenssl-25.3.0-py3-none-any.whl (57 kB)\nInstalling collected packages: ifaddr, pyee, dnspython, pylibsrtp, aioice, pyopenssl, aiortc\n\nSuccessfully installed aioice-0.10.2 aiortc-1.14.0 dnspython-2.8.0 ifaddr-0.2.0 pyee-13.0.0 pylibsrtp-1.0.0 pyopenssl-25.3.0\n\n[*] Installing pyee...\nRequirement already satisfied: pyee in ./.venv/lib/python3.13/site-packages (13.0.0)\nRequirement already satisfied: typing-extensions in ./.venv/lib/python3.13/site-packages (from pyee) (4.15.0)\n\n[*] Installing dnspython...\nRequirement already satisfied: dnspython in ./.venv/lib/python3.13/site-packages (2.8.0)\n\n[*] Installing ifaddr...\nRequirement already satisfied: ifaddr in ./.venv/lib/python3.13/site-packages (0.2.0)\n\n[*] Installing pylibsrtp...\nRequirement already satisfied: pylibsrtp in ./.venv/lib/python3.13/site-packages (1.0.0)\nRequirement already satisfied: cffi>=1.0.0 in ./.venv/lib/python3.13/site-packages (from pylibsrtp) (2.0.0)\nRequirement already satisfied: pycparser in ./.venv/lib/python3.13/site-packages (from cffi>=1.0.0->pylibsrtp) (2.23)\n\n[*] Installing pyopenssl...\nRequirement already satisfied: pyopenssl in ./.venv/lib/python3.13/site-packages (25.3.0)\nRequirement already satisfied: cryptography<47,>=45.0.7 in ./.venv/lib/python3.13/site-packages (from pyopenssl) (46.0.3)\nRequirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.13/site-packages (from cryptography<47,>=45.0.7->pyopenssl) (2.0.0)\nRequirement already satisfied: pycparser in ./.venv/lib/python3.13/site-packages (from cffi>=2.0.0->cryptography<47,>=45.0.7->pyopenssl) (2.23)\n\n[!] Installing VibeVoice with --no-deps to prevent package downgrades\n[*] Installing VibeVoice (--no-deps)...\nCollecting git+https://github.com/FushionHub/VibeVoice.git\n  Cloning https://github.com/FushionHub/VibeVoice.git to /tmp/nix-shell-2550-1491292131/pip-req-build-r21_jb8d\n  Resolved https://github.com/FushionHub/VibeVoice.git to commit 3dd860579757310343749cba9623afde9e69c657\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nBuilding wheels for collected packages: vibevoice\n  Building wheel for vibevoice (pyproject.toml): started\n  Building wheel for vibevoice (pyproject.toml): finished with status 'done'\n  Created wheel for vibevoice: filename=vibevoice-0.0.1-py3-none-any.whl size=79270 sha256=eca631ab78eda49df4bda583a111076a4991a731e5ab3e620673f04c1b13753d\n  Stored in directory: /tmp/nix-shell-2550-1491292131/pip-ephem-wheel-cache-vjh6ve_g/wheels/d7/5a/ca/0bfc24101e26701f720fb4f13de377d6c6774b99e8d8fd655b\nSuccessfully built vibevoice\nInstalling collected packages: vibevoice\nSuccessfully installed vibevoice-0.0.1\n\n[i] Installing F5-TTS multilingual phonemization support\n[i] Linux/Mac detected - installing phonemizer for multilingual F5-TTS support\n[*] Installing phonemizer package...\nRequirement already satisfied: phonemizer in ./.venv/lib/python3.13/site-packages (3.3.0)\nRequirement already satisfied: joblib in ./.venv/lib/python3.13/site-packages (from phonemizer) (1.5.2)\nRequirement already satisfied: segments in ./.venv/lib/python3.13/site-packages (from phonemizer) (2.3.0)\nRequirement already satisfied: attrs>=18.1 in ./.venv/lib/python3.13/site-packages (from phonemizer) (25.4.0)\nRequirement already satisfied: dlinfo in ./.venv/lib/python3.13/site-packages (from phonemizer) (2.0.0)\nRequirement already satisfied: typing-extensions in ./.venv/lib/python3.13/site-packages (from phonemizer) (4.15.0)\nRequirement already satisfied: regex in ./.venv/lib/python3.13/site-packages (from segments->phonemizer) (2025.11.3)\nRequirement already satisfied: csvw>=1.5.6 in ./.venv/lib/python3.13/site-packages (from segments->phonemizer) (3.7.0)\nRequirement already satisfied: isodate in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (0.7.2)\nRequirement already satisfied: python-dateutil in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\nRequirement already satisfied: rfc3986<2 in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (1.5.0)\nRequirement already satisfied: uritemplate>=3.0.0 in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (4.2.0)\nRequirement already satisfied: babel in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\nRequirement already satisfied: requests in /nix/store/6gp1npnskqxkyfr73isk0vf2ygm976h7-python3.13-requests-2.32.5/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (2.32.5)\nRequirement already satisfied: language-tags in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (1.2.0)\nRequirement already satisfied: rdflib in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (7.5.0)\nRequirement already satisfied: termcolor in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (3.2.0)\nRequirement already satisfied: jsonschema in ./.venv/lib/python3.13/site-packages (from csvw>=1.5.6->segments->phonemizer) (4.25.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.13/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.13/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.13/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.30.0)\nRequirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\nRequirement already satisfied: pyparsing<4,>=2.1.0 in ./.venv/lib/python3.13/site-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.2.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /nix/store/a08p0c01w52xp24ssf52p9h7scm75g0y-python3.13-charset-normalizer-3.4.3/lib/python3.13/site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /nix/store/zqv9mpx4g328f24wnhdh232nsaj9mx8b-python3.13-idna-3.11/lib/python3.13/site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /nix/store/1ghpcxwjqb4prf8ql6in7ccklgil5sfp-python3.13-urllib3-2.5.0/lib/python3.13/site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /nix/store/nwn6w97v5hfmld12zddb6viphvd9hsc8-python3.13-certifi-2025.07.14/lib/python3.13/site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2025.7.14)\n\n[!] phonemizer installed but system espeak dependency missing\n[i] To enable multilingual F5-TTS support, install system espeak:\n   sudo apt-get install espeak espeak-data  # Ubuntu/Debian\n   sudo dnf install espeak espeak-devel     # Fedora/RHEL\n[!] Non-English F5-TTS models will fall back to character-based processing\n[i] Installing IndexTTS-2 text normalization support\n[*] Installing WeTextProcessing (Chinese/English normalization)...\n[!] Warning: Installing WeTextProcessing (Chinese/English normalization) failed (continuing anyway): error: subprocess-exited-with-error\n  \n  √ó Building wheel for pynini (pyproject.toml) did not run successfully.\n   exit code: 1\n  > [108 lines of output]\n      /tmp/nix-shell-2550-1491292131/pip-build-env-7mpm9wgy/overlay/lib/python3.13/site-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n      !!\n      \n              ********************************************************************************\n              Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n      \n              By 2026-Feb-18, you need to update your project and remove deprecated calls\n              or your builds will no longer be supported.\n      \n              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n              ********************************************************************************\n      \n      !!\n        corresp(dist, value, root_dir)\n      /tmp/nix-shell-2550-1491292131/pip-build-env-7mpm9wgy/overlay/lib/python3.13/site-packages/setuptools/config/_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n      !!\n      \n              ********************************************************************************\n              Please consider removing the following classifiers in favor of a SPDX license expression:\n      \n              License :: OSI Approved :: Apache Software License\n      \n              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n              ********************************************************************************\n      \n      !!\n        dist._finalize_license_expression()\n      /tmp/nix-shell-2550-1491292131/pip-build-env-7mpm9wgy/overlay/lib/python3.13/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n      !!\n      \n              ********************************************************************************\n              Please consider removing the following classifiers in favor of a SPDX license expression:\n      \n              License :: OSI Approved :: Apache Software License\n      \n              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n              ********************************************************************************\n      \n      !!\n        self._finalize_license_expression()\n      running bdist_wheel\n      running build\n      running build_py\n      creating build/lib.linux-x86_64-cpython-313/pywrapfst\n      copying pywrapfst/__init__.py -> build/lib.linux-x86_64-cpython-313/pywrapfst\n      creating build/lib.linux-x86_64-cpython-313/pynini\n      copying pynini/__init__.py -> build/lib.linux-x86_64-cpython-313/pynini\n      creating build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/utf8.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/tagger.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/stringfile.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/rule_cascade.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/rewrite.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/pynutil.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/paradigms.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/features.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/edit_transducer.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/byte.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/__init__.py -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      creating build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/multi_grm_example.py -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/multi_grm.py -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/grm_example.py -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/grm.py -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/export.py -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/__init__.py -> build/lib.linux-x86_64-cpython-313/pynini/export\n      creating build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/weather.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/t9.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/plurals.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/numbers.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/g2p.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/dates.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/chatspeak_model.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/chatspeak.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/case.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/__init__.py -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      running egg_info\n      writing pynini.egg-info/PKG-INFO\n      writing dependency_links to pynini.egg-info/dependency_links.txt\n      writing top-level names to pynini.egg-info/top_level.txt\n      reading manifest file 'pynini.egg-info/SOURCES.txt'\n      reading manifest template 'MANIFEST.in'\n      adding license file 'LICENSE'\n      adding license file 'AUTHORS'\n      writing manifest file 'pynini.egg-info/SOURCES.txt'\n      copying pywrapfst/BUILD.bazel -> build/lib.linux-x86_64-cpython-313/pywrapfst\n      copying pywrapfst/__init__.pyi -> build/lib.linux-x86_64-cpython-313/pywrapfst\n      copying pywrapfst/py.typed -> build/lib.linux-x86_64-cpython-313/pywrapfst\n      copying pynini/BUILD.bazel -> build/lib.linux-x86_64-cpython-313/pynini\n      copying pynini/__init__.pyi -> build/lib.linux-x86_64-cpython-313/pynini\n      copying pynini/py.typed -> build/lib.linux-x86_64-cpython-313/pynini\n      copying pynini/lib/BUILD.bazel -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/lib/py.typed -> build/lib.linux-x86_64-cpython-313/pynini/lib\n      copying pynini/export/BUILD.bazel -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/grm_py_build_defs.bzl -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/export/py.typed -> build/lib.linux-x86_64-cpython-313/pynini/export\n      copying pynini/examples/BUILD.bazel -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      copying pynini/examples/py.typed -> build/lib.linux-x86_64-cpython-313/pynini/examples\n      running build_ext\n      building '_pywrapfst' extension\n      creating build/temp.linux-x86_64-cpython-313/extensions\n      g++ -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O3 -Wall -fPIC -I/home/atomix/ComfyUI/.venv/include -I/nix/store/3lll9y925zz9393sa59h653xik66srjb-python3-3.13.9/include/python3.13 -c extensions/_pywrapfst.cpp -o build/temp.linux-x86_64-cpython-313/extensions/_pywrapfst.o -std=c++17 -Wno-register -Wno-deprecated-declarations -Wno-unused-function -Wno-unused-local-typedefs -funsigned-char\n      extensions/_pywrapfst.cpp:1188:10: fatal error: fst/util.h: No such file or directory\n       1188 | #include <fst/util.h>\n            |          ^~~~~~~~~~~~\n      compilation terminated.\n      error: command '/nix/store/vr15iyyykg9zai6fpgvhcgyw7gckl78w-gcc-wrapper-14.3.0/bin/g++' failed with exit code 1\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for pynini\n\n[notice] A new release of pip is available: 25.2 -> 25.3\n[notice] To update, run: pip install --upgrade pip\nerror: failed-wheel-build-for-install\n\n√ó Failed to build installable wheels for some pyproject.toml based projects\n> pynini\n[*] Installing wetext (fallback text normalization)...\nCollecting wetext\n  Using cached wetext-0.1.2-py3-none-any.whl.metadata (4.9 kB)\nCollecting contractions (from wetext)\n  Using cached contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting kaldifst (from wetext)\n  Using cached kaldifst-1.7.17-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting textsearch>=0.0.21 (from contractions->wetext)\n  Using cached textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting anyascii (from textsearch>=0.0.21->contractions->wetext)\n  Using cached anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\nCollecting pyahocorasick (from textsearch>=0.0.21->contractions->wetext)\n  Using cached pyahocorasick-2.2.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nUsing cached wetext-0.1.2-py3-none-any.whl (1.8 MB)\nUsing cached contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\nUsing cached textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\nUsing cached anyascii-0.3.3-py3-none-any.whl (345 kB)\nUsing cached kaldifst-1.7.17-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.6 MB)\nUsing cached pyahocorasick-2.2.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\nInstalling collected packages: pyahocorasick, kaldifst, anyascii, textsearch, contractions, wetext\n\nSuccessfully installed anyascii-0.3.3 contractions-0.1.73 kaldifst-1.7.17 pyahocorasick-2.2.0 textsearch-0.0.24 wetext-0.1.2\n\n[+] wetext fallback working - IndexTTS-2 will have basic text normalization\n[i] Checking and fixing wandb import issues\n[+] wandb import test passed\n[!] Python 3.13 detected - applying compatibility measures\n[!] MediaPipe is incompatible with Python 3.13\n[i] OpenSeeFace will be used automatically for mouth movement analysis\n[!] Note: OpenSeeFace is experimental and may be less accurate than MediaPipe\n[*] Installing onnxruntime for OpenSeeFace (Python 3.13)...\nCollecting onnxruntime\n  Using cached onnxruntime-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nUsing cached onnxruntime-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\nInstalling collected packages: onnxruntime\n  Attempting uninstall: onnxruntime\n    Found existing installation: onnxruntime 1.23.2\n    Uninstalling onnxruntime-1.23.2:\n      Successfully uninstalled onnxruntime-1.23.2\nSuccessfully installed onnxruntime-1.23.2\n\n[i] Checking for version conflicts...\n[!] WARNING: NumPy 2.3.4 detected - may cause numba conflicts\n[!] Consider downgrading: pip install 'numpy>=2.2.0,<2.3.0'\n[i] Validating installation...\n[+] PyTorch: OK\n[+] TorchAudio: OK\n[+] Transformers: OK\n[+] SoundFile: OK\n[+] NumPy: OK\n[+] Librosa: OK\n[+] OmegaConf: OK\n[+] ONNXRuntime (OpenSeeFace): OK\n[+] Monotonic Alignment Search (RVC): OK\n\n======================================================================\n                    TTS AUDIO SUITE INSTALLATION\n======================================================================\n[+] Installation completed successfully!\n\n>>> Python version: 3.13.9\n\n--------------------------------------------------\n   PYTHON 3.13 COMPATIBILITY STATUS\n--------------------------------------------------\n  [+] All TTS engines: WORKING\n      (ChatterBox, F5-TTS, Higgs Audio)\n  [+] RVC voice conversion: WORKING\n  [+] OpenSeeFace mouth movement: WORKING (experimental)\n  [+] Numba/Librosa compatibility: FIXED\n      -> Automatic JIT disabling for Python 3.13\n  [X] MediaPipe mouth movement: INCOMPATIBLE\n      -> Use OpenSeeFace alternative\n\n>> Want MediaPipe Python 3.13 support? Vote at:\n   https://github.com/google-ai-edge/mediapipe/issues/5708\n\n======================================================================\n               READY TO USE TTS AUDIO SUITE IN COMFYUI!\n======================================================================\n\n[+] Installation completed successfully!\n\n\n[nix-shell:~/ComfyUI]$\n\n```\n\n</details>","createdAt":"2025-12-06T11:37:50Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3619998042","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Xzi0N","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Good it should now all be working right? The only thing you should consider is for but I don't think it is super necessary, but if you want to try f5 phonemization:\n\n[i] To enable multilingual F5-TTS support, install system espeak:\n   sudo apt-get install espeak espeak-data  # Ubuntu/Debian\n   sudo dnf install espeak espeak-devel     # Fedora/RHEL","createdAt":"2025-12-06T15:51:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3620613389","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7X14CP","author":{"login":"Poilaucul"},"authorAssociation":"NONE","body":"Yes, thank you.\nIt's working fine so far, I have generated in Chatterbox.\n\nIs espeak-data a necessity for espeak to work? those are the packages that are available: https://search.nixos.org/packages?channel=unstable&query=espeak","createdAt":"2025-12-06T21:40:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/189#issuecomment-3621224591","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACRuPrGg","name":"Dependencies-help","description":"","color":"d3aba3"}],"number":189,"title":"ChatterboxTTS not available: No module named 'librosa'","updatedAt":"2025-12-06T21:40:38Z"},{"comments":[{"id":"IC_kwDOPZi2kc7Xu4r-","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'll look into it as soon as I can, hopefully it's a matter of simply adding another vibevoice model as an option and not a new engine... if it needs to be a whole new engine, I don't think this is worth it as the advertisement of it is for streaming(real time) generation. And I don't think this makes much sense in ComfyUI.","createdAt":"2025-12-06T03:16:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/185#issuecomment-3619392254","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7XvB4N","author":{"login":"Vollond"},"authorAssociation":"NONE","body":"That could be a great model for low-VRAM systems","createdAt":"2025-12-06T03:58:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/185#issuecomment-3619429901","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7aLXy_","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"After analyzing the VibeVoice-Realtime-0.5B model, here's what I found:\n\n## Architecture Differences\n\nThe Realtime model is **fundamentally different** from the existing VibeVoice 1.5B/7B models:\n\n- **Different model class**: `VibeVoiceStreamingForConditionalGenerationInference` (vs standard inference class)\n- **Different processor**: `VibeVoiceStreamingProcessor` with streaming-specific logic\n- **No semantic tokenizer**: Uses acoustic tokenizer only (architecture change)\n- **Different voice format**: Uses pre-cached `.pt` embeddings (though we could convert from .wav on first use)\n- **Streaming windowed generation**: Optimized for real-time use cases\n\n## Integration Assessment\n\n**This would need to be a separate engine**, not just an option. It can't be added as a model variant because:\n\n1. Completely different model/processor classes\n2. Different generation methods and parameters\n3. Different architecture (no semantic tokenizer)\n4. Would require extensive conditionals throughout the code\n\n## Practical Considerations\n\n**Pros:**\n- ‚úÖ Lower VRAM (0.5B parameters)\n- ‚úÖ Good for low-end systems\n- ‚úÖ Completes VibeVoice family support\n\n**Cons:**\n- ‚ö†Ô∏è Single-speaker only (though our character switching could work around this)\n- ‚ö†Ô∏è 10-min max vs 90-min for regular VibeVoice\n- ‚ö†Ô∏è Streaming optimizations don't benefit batch ComfyUI workflows\n- ‚ö†Ô∏è Significant development and maintenance effort\n\n## Decision\n\n**Not implementing right now.** The use case (streaming/real-time voice agents) doesn't align well with ComfyUI's batch processing nature, and the limitations (single-speaker, shorter max length) outweigh the benefits for typical TTS workflows.\n\nHowever, **this could be added as a new engine in the future** when time permits - mainly for completeness of VibeVoice family support and low-VRAM use cases.\n\nFor now, users with VRAM constraints should use **F5-TTS** - it's the smallest and most efficient model currently supported.\n\nKeeping this issue open for potential future implementation.","createdAt":"2025-12-16T13:00:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/185#issuecomment-3660414143","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJLHnXQ","name":"low-priority","description":"","color":"f9d0c4"},{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":185,"title":"New model, microsoft/VibeVoice-Realtime-0.5B","updatedAt":"2025-12-16T13:00:55Z"},{"comments":[{"id":"IC_kwDOPZi2kc7WlF5U","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Fixed in v4.14.32\n\nAll the issues you reported have been resolved:\n\n### 1. Japanese HuBERT Download (401 Unauthorized)\n**Fixed**: Changed to public repository `prj-beatrice/japanese-hubert-base-phoneme-ctc-v4`\n- The old `rinna/japanese-hubert-base` repo was gated (required approval)\n- New repo is publicly accessible and works without authentication\n\n### 2. HuBERT Model Selection Ignored\n**Fixed**: Added proper parameter passthrough in the conversion pipeline\n- Your selected HuBERT model is now properly used during conversion\n- Parameters flow through: `voice_changer_node.py` ‚Üí `rvc_adapter.py` ‚Üí `minimal_reference_wrapper.py`\n\n### 3. Transformers Models Support\n**Added**: Full support for language-specific HuBERT models\n- Japanese: `hubert-base-japanese` (768-dim)\n- Korean: `hubert-base-korean` (1024-dim) \n- Chinese: `chinese-hubert-base` (768-dim)\n- Large: `hubert-large` (1024-dim, highest quality)\n\nThese models now load correctly with:\n- Automatic `config.json` download from HuggingFace\n- TransformersHubertWrapper for RVC compatibility\n- Proper dtype conversion (float16 ‚Üî float32)\n\n### 4. Config.json Conflicts\n**Fixed**: Implemented subdirectory structure\n- Each transformers model gets its own subdirectory with isolated config\n- Example structure:\n  ```\n  models/TTS/hubert/\n  ‚îú‚îÄ‚îÄ content-vec-best.safetensors (RVC format, no subdirectory needed)\n  ‚îú‚îÄ‚îÄ hubert_base_jp/\n  ‚îÇ   ‚îú‚îÄ‚îÄ hubert_base_jp.safetensors\n  ‚îÇ   ‚îî‚îÄ‚îÄ config.json (Japanese-specific)\n  ‚îú‚îÄ‚îÄ hubert_large/\n  ‚îÇ   ‚îú‚îÄ‚îÄ hubert_large.safetensors\n  ‚îÇ   ‚îî‚îÄ‚îÄ config.json (Large-specific)\n  ```\n- Auto-migration: Existing models are automatically moved to subdirectories on first load\n\n### 5. Dimension Mismatch Detection\n**Added**: Helpful error messages when HuBERT/RVC model don't match\n- If you try to use HuBERT Large (1024-dim) with an RVC model trained on content-vec (768-dim), you'll get:\n  ```\n  ‚ùå HuBERT/RVC Model Mismatch!\n     HuBERT output: 1024 dimensions\n     RVC index expects: 768 dimensions\n  \n  üí° Solution:\n     This RVC model was trained with content-vec-best (768-dim)\n     Please select 'content-vec-best' as your HuBERT model\n  ```\n\n### Important Notes\n\n**RVC Model Compatibility**: RVC models are tied to the HuBERT model they were trained with. Most RVC models use content-vec-best (768-dim). Only use language-specific or Large HuBERT models if your RVC model was specifically trained with them.\n\n**Testing Japanese HuBERT**: While it now downloads and loads correctly, using Japanese HuBERT with non-Japanese audio or with an RVC model trained on different HuBERT will produce garbled audio (expected behavior - language/dimension mismatch).\n\nPlease update and test! Let me know if you encounter any issues.","createdAt":"2025-12-02T03:43:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3600047700","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7WlZ_s","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> ave been resolved:\n> \n> ### 1. Japanese HuBERT Download (401 Unauthorized)\n> **Fixed**: Changed to public repository `prj-beatrice/japanese-hubert-base-phoneme-ctc-v4`\n> \n> * The old `rinna/japanese-hubert-base` repo was gated (required approval)\n> * New repo is publicly accessible and works without authentication\n> \n> ### 2. HuBERT Model Selection Ignored\n> **Fixed**: Added proper parameter passthrough in the conversion pipeline\n> \n> * Your selected HuBERT model is now properly used during conversion\n> * Parameters flow through: `voice_changer_node.py` ‚Üí `rvc_adapter.py` ‚Üí `minimal_reference_wrapper.py`\n> \n> ### 3. Transformers Models Support\n> **Added**: Full support for language-specific HuBERT models\n> \n> * Japanese: `hubert-base-japanese` (768-dim)\n> * Korean: `hubert-base-korean` (1024-dim)\n> * Chinese: `chinese-hubert-base` (768-dim)\n> * Large: `hubert-large` (1024-dim, highest quality)\n> \n> These models now load correctly with:\n> \n> * Automatic `config.json` download from HuggingFace\n> * TransformersHubertWrapper for RVC compatibility\n> * Proper dtype conversion (float16 ‚Üî float32)\n> \n> ### 4. Config.json Conflicts\n> **Fixed**: Implemented subdirectory structure\n> \n> * Each transformers model gets its own subdirectory with isolated config\n> * Example structure:\n>   ```\n>   models/TTS/hubert/\n>   ‚îú‚îÄ‚îÄ content-vec-best.safetensors (RVC format, no subdirectory needed)\n>   ‚îú‚îÄ‚îÄ hubert_base_jp/\n>   ‚îÇ   ‚îú‚îÄ‚îÄ hubert_base_jp.safetensors\n>   ‚îÇ   ‚îî‚îÄ‚îÄ config.json (Japanese-specific)\n>   ‚îú‚îÄ‚îÄ hubert_large/\n>   ‚îÇ   ‚îú‚îÄ‚îÄ hubert_large.safetensors\n>   ‚îÇ   ‚îî‚îÄ‚îÄ config.json (Large-specific)\n>   ```\n> * Auto-migration: Existing models are automatically moved to subdirectories on first load\n> \n> ### 5. Dimension Mismatch Detection\n> **Added**: Helpful error messages when HuBERT/RVC model don't match\n> \n> * If you try to use HuBERT Large (1024-dim) with an RVC model trained on content-vec (768-dim), you'll get:\n>   ```\n>   ‚ùå HuBERT/RVC Model Mismatch!\n>      HuBERT output: 1024 dimensions\n>      RVC index expects: 768 dimensions\n>   \n>   üí° Solution:\n>      This RVC model was trained with content-vec-best (768-dim)\n>      Please select 'content-vec-best' as your HuBERT model\n>   ```\n> \n> ### Important Notes\n> **RVC Model Compatibility**: RVC models are tied to the HuBERT model they were trained with. Most RVC models use content-vec-best (768-dim). Only use language-specific or Large HuBERT models if your RVC model was specifically trained with them.\n> \n> **Testing Japanese HuBERT**: While it now downloads and loads correctly, using Japanese HuBERT with non-Japanese audio or with an RVC model trained on different HuBERT will produce garbled audio (expected behavior - language/dimension mismatch).\n> \n> Please update and test! Let me know if you encounter any issues.\n\nI used a Japanese song as input and selected the Japanese HuBERT model, but the results were terrible.\n\n<img width=\"1920\" height=\"998\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e57f723f-05a8-498a-83ad-50ae5bc2fe48\" />\n\n[ComfyUI_00001_.mp3](https://github.com/user-attachments/files/23871210/ComfyUI_00001_.mp3)","createdAt":"2025-12-02T04:25:07Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3600130028","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Wle0m","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod \n\nSelecting the Chinese and Korean HuBERT model for a Chinese song produced equally poor results, and the model enters a download loop during automatic **downloading.**\n\n<img width=\"657\" height=\"247\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cc3b8d1f-02f0-43fb-8312-126d5b6d2030\" />\n\n<img width=\"613\" height=\"242\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8d102f8c-db5b-4e2e-8849-9959dd060dab\" />\n\n<img width=\"638\" height=\"247\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/de58e461-7626-4401-b4f4-5a56310171ea\" />","createdAt":"2025-12-02T04:35:41Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3600149798","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7WrHlf","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I had a feeling the Japanese was giving weird results... but I did not have a trained model on the japanese Hubert to really test it. Are you sure your model (the RVC voice reference) was trained with a custom hubert? Because if not, even if your song is japanese, yo should use the standard hubert.","createdAt":"2025-12-02T11:44:53Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3601627487","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7WrI_z","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod)\n> \n> Selecting the Chinese and Korean HuBERT model for a Chinese song produced equally poor results, and the model enters a download loop during automatic **downloading.**\n> \n\nWhat do you mean \"download loop\"? In the console, you see it downloading the model multiple times?","createdAt":"2025-12-02T11:46:29Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3601633267","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Wr_fw","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> What do you mean \"download loop\"? In the console, you see it downloading the model multiple times?\n\nCorrect ‚Äî the RVC engine node is repeatedly downloading models. As shown in images one and two, there are two instances of the hubert chinese model, and in image three it again downloads the hubert large model.","createdAt":"2025-12-02T12:46:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3601856496","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7WsCuL","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> I had a feeling the Japanese was giving weird results... but I did not have a trained model on the japanese Hubert to really test it. Are you sure your model (the RVC voice reference) was trained with a custom hubert? Because if not, even if your song is japanese, yo should use the standard hubert.\n\nNo, I‚Äôm using your default RVC model Monika. I‚Äôll look for some Japanese RVC models and retest the hubert Japanese model.","createdAt":"2025-12-02T12:49:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3601869707","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7W70H7","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod \n\nThe issue of models being repeatedly downloaded still persists.\n\n<img width=\"641\" height=\"269\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/06aa04c4-a874-4cb5-af15-59dbca529a18\" />\n\n<img width=\"1176\" height=\"690\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5957a3c4-9a2a-4429-9da1-e76c6ffb80cd\" />","createdAt":"2025-12-03T09:57:10Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3606004219","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7W73PC","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod \n\nThe input song and model are both in Japanese, but the conversion result is poor.\n\nhttps://voice-models.com/model/1pVQLG8s30g\n\n<img width=\"1658\" height=\"759\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ba698790-9e72-4b15-a080-57399e097acf\" />\n\n[ComfyUI_00001_.mp3](https://github.com/user-attachments/files/23902995/ComfyUI_00001_.mp3)","createdAt":"2025-12-03T09:59:54Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/183#issuecomment-3606016962","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWvQ","name":"bug","description":"Something isn't working","color":"d73a4a"}],"number":183,"title":"[BUG] RVC Engine node fails to apply Japanese Hubert model","updatedAt":"2025-12-06T03:14:58Z"},{"comments":[{"id":"IC_kwDOPZi2kc7WCw2V","author":{"login":"JaneDoe84"},"authorAssociation":"NONE","body":"**Comfyui was restored all night, and in the end that brought the solution:**\npip uninstall onnx -y\npip install onnx==1.16.1\n\nI have no idea if this version will work with your node, so I'm not going to touch it for now. First, i make a safe backup of ComfyUI; things can always go wrong. But now, i need some sleep first :-)\n","createdAt":"2025-11-29T06:39:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/182#issuecomment-3591048597","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Xu36F","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi! I'm sorry, dependencies is a hard thing to deal with when using many nodes. But I have TTS Suite in my main comfyui installation + nunchaku and many many other nodes and it works.\n\nI'll evaluate the 'onnx==1.16.1' you reported in the future to see if a newer version of it causes conflicts. Any more information you give us could be helpful. Thanks.","createdAt":"2025-12-06T03:12:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/182#issuecomment-3619389061","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACRuPrGg","name":"Dependencies-help","description":"","color":"d3aba3"}],"number":182,"title":"module 'onnx.onnx_cpp2py_export.shape_inference' has no attribute 'GraphInferencer'","updatedAt":"2025-12-06T03:14:07Z"},{"comments":[{"id":"IC_kwDOPZi2kc7WjG-v","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"You should not connect the IndexTTS-2 Text Emotion to the \"opt_narrator\". Opt_narrator is your reference audio to be cloned, it has nothing to do with the text emotion or anything related to emotion_control.\n\nAlso, anything you type inside the \"IndexTTS-2 Text Emotion\" node will be translated by the qwenEmotion model to a single emotion vector combination. Meaning, if your text feels \"angry\", it will apply angriness to your generation. When you include {seg}, what that means is that your segmented text will be pasted there and accounted when translating to an emotion vector.","createdAt":"2025-12-02T00:11:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3599527855","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7WjIPj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"you can see this discussion for further clarification https://github.com/diodiogod/TTS-Audio-Suite/discussions/177","createdAt":"2025-12-02T00:12:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3599533027","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Wk4Ir","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> you can see this discussion for further clarification [#177](https://github.com/diodiogod/TTS-Audio-Suite/discussions/177)\n\n<img width=\"1672\" height=\"650\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a2405e5b-8250-47a4-8f0b-a2f2eb401584\" />\n\nI checked the discussion link you sent, but I can't understand it at all. The issue with your IndexTTS-2 Text Emotion is that if I leave the emotion text empty, it should automatically analyze the emotion from the TTS text and generate speech, but in reality the Qwen emotion model is neither downloaded locally nor doing anything.","createdAt":"2025-12-02T03:16:50Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3599991339","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Wk9Ln","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> you can see this discussion for further clarification [#177](https://github.com/diodiogod/TTS-Audio-Suite/discussions/177)\n\n<img width=\"1920\" height=\"998\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d802e2fb-3d2e-45ea-aa60-d705544dfc2c\" />\n\nFor example, with the nodes connected like this, I clearly intend for the Qwen emotion model to take effect and automatically generate emotions for the TTS text. But the backend error message is: \"‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\"","createdAt":"2025-12-02T03:28:51Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3600012007","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7WlJ38","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"<img width=\"1920\" height=\"998\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/da70f255-4a89-4f2f-b531-6e2b34faea09\" />\n\nNo surprise: \"QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True.\" Nothing changed ‚Äî it's the same as removing the \"üåà IndexTTS-2 Text Emotion\" node.","createdAt":"2025-12-02T03:52:36Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3600063996","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7WlK5W","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> > you can see this discussion for further clarification [#177](https://github.com/diodiogod/TTS-Audio-Suite/discussions/177)\n> \n> <img alt=\"Image\" width=\"1920\" height=\"998\" src=\"https://private-user-images.githubusercontent.com/72290820/521107286-d802e2fb-3d2e-45ea-aa60-d705544dfc2c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ2NDc3MzAsIm5iZiI6MTc2NDY0NzQzMCwicGF0aCI6Ii83MjI5MDgyMC81MjExMDcyODYtZDgwMmUyZmItM2QyZS00NWVhLWFhNjAtZDcwNTU0NGRmYzJjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjAyVDAzNTAzMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwNWY5YWFlODkzY2NlYzM0ZjIwN2UzYzI5ODkzNjJiMTgzNDY5NWE3ZGM5NjI4MWMwYTBjNGMyODJjODA0YjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.baMvA8MDwc_IzAJUShcutrXERBXsZpomxRxBKnQtCfk\">\n> \n> For example, with the nodes connected like this, I clearly intend for the Qwen emotion model to take effect and automatically generate emotions for the TTS text. But the backend error message is: \"‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\"\n\n1- you need a narrator. Either choose one from the 'narrator_voice' drop-down on the 'TTS text' node or connect a narrator on the opt_narrator\n\n2- If you want the qwenemotion model to analyze your text content only, just leave {seg} on the \"Index2 Text Emotion\" node. \n\nI'll see if I can reproduce your error about it saying '\"‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\"'","createdAt":"2025-12-02T03:54:46Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3600068182","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7WlNMe","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> > you can see this discussion for further clarification [#177](https://github.com/diodiogod/TTS-Audio-Suite/discussions/177)\n> \n> <img alt=\"Image\" width=\"1920\" height=\"998\" src=\"https://private-user-images.githubusercontent.com/72290820/521107286-d802e2fb-3d2e-45ea-aa60-d705544dfc2c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ2NDc3MzAsIm5iZiI6MTc2NDY0NzQzMCwicGF0aCI6Ii83MjI5MDgyMC81MjExMDcyODYtZDgwMmUyZmItM2QyZS00NWVhLWFhNjAtZDcwNTU0NGRmYzJjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjAyVDAzNTAzMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwNWY5YWFlODkzY2NlYzM0ZjIwN2UzYzI5ODkzNjJiMTgzNDY5NWE3ZGM5NjI4MWMwYTBjNGMyODJjODA0YjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.baMvA8MDwc_IzAJUShcutrXERBXsZpomxRxBKnQtCfk\">\n> \n> For example, with the nodes connected like this, I clearly intend for the Qwen emotion model to take effect and automatically generate emotions for the TTS text. But the backend error message is: \"‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\"\n\nI'll see, but in any case, this [A] [B] [C] [D] Logic you have there is not how it works. You just write {seg} and qwenemotion model will analyze the content of each of your segments. [A] [B] etc will only work if you have a Character named A or B. And even in that case, you do not use A or B on the  \"Index2 Text Emotion\" node.","createdAt":"2025-12-02T03:58:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3600077598","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7WlQcQ","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I could not reproduce your error, qwenemotion works as intended. It analyses the segment text and transforms it into emotion vectors... you can see it in the console output:\n```\n>> starting inference...\ndetected emotion vectors from text: {'happy': 0.0, 'angry': 0.2, 'sad': 0.25, 'afraid': 0.1, 'disgusted': 0.1, 'melancholic': 0.3, 'surprised': 0.05, 'calm': 0.0}\nüé≠ Emotion vectors normalized: sum 1.0 ‚Üí 0.8 (max 0.8): [0.0, 0.15, 0.214, 0.086, 0.08, 0.241, 0.029, 0.0]\nüé≠ Scaled by alpha 0.7: [0.0, 0.105, 0.15, 0.06, 0.056, 0.169, 0.021, 0.0]\nUse the specified emotion vector\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 22.38it/s]\n```\n\n Use the template workflow to undertand how it should be, like this: \n\n[üåà IndexTTS-2 integration.json](https://github.com/user-attachments/files/23870980/IndexTTS-2.integration.json)","createdAt":"2025-12-02T04:03:52Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3600090896","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7WlqAs","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"\n> > > you can see this discussion for further clarification [#177](https://github.com/diodiogod/TTS-Audio-Suite/discussions/177)\n> > \n> > \n> > <img alt=\"Image\" width=\"1920\" height=\"998\" src=\"https://private-user-images.githubusercontent.com/72290820/521107286-d802e2fb-3d2e-45ea-aa60-d705544dfc2c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjQ2NDc3MzAsIm5iZiI6MTc2NDY0NzQzMCwicGF0aCI6Ii83MjI5MDgyMC81MjExMDcyODYtZDgwMmUyZmItM2QyZS00NWVhLWFhNjAtZDcwNTU0NGRmYzJjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjAyVDAzNTAzMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwNWY5YWFlODkzY2NlYzM0ZjIwN2UzYzI5ODkzNjJiMTgzNDY5NWE3ZGM5NjI4MWMwYTBjNGMyODJjODA0YjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.baMvA8MDwc_IzAJUShcutrXERBXsZpomxRxBKnQtCfk\">\n> > For example, with the nodes connected like this, I clearly intend for the Qwen emotion model to take effect and automatically generate emotions for the TTS text. But the backend error message is: \"‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\"\n> \n> I'll see, but in any case, this [A] [B] [C] [D] Logic you have there is not how it works. You just write {seg} and qwenemotion model will analyze the content of each of your segments. [A] [B] etc will only work if you have a Character named A or B. And even in that case, you do not use A or B on the \"Index2 Text Emotion\" node.\n\n\n\n> I could not reproduce your error, qwenemotion works as intended. It analyses the segment text and transforms it into emotion vectors... you can see it in the console output:\n> \n> ```\n> >> starting inference...\n> detected emotion vectors from text: {'happy': 0.0, 'angry': 0.2, 'sad': 0.25, 'afraid': 0.1, 'disgusted': 0.1, 'melancholic': 0.3, 'surprised': 0.05, 'calm': 0.0}\n> üé≠ Emotion vectors normalized: sum 1.0 ‚Üí 0.8 (max 0.8): [0.0, 0.15, 0.214, 0.086, 0.08, 0.241, 0.029, 0.0]\n> üé≠ Scaled by alpha 0.7: [0.0, 0.105, 0.15, 0.06, 0.056, 0.169, 0.021, 0.0]\n> Use the specified emotion vector\n> 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 22.38it/s]\n> ```\n> \n> Use the template workflow to undertand how it should be, like this:\n> \n> [üåà IndexTTS-2 integration.json](https://github.com/user-attachments/files/23870980/IndexTTS-2.integration.json)\n\n\nThe workflow is yours.\n\n[üåà IndexTTS-2 integration.json](https://github.com/user-attachments/files/23871699/IndexTTS-2.integration.json)\n\n```\n[START] Security scan\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2025-12-02 12:52:27.696\n** Platform: Windows\n** Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n** Python executable: D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Scripts\\Python.exe\n** ComfyUI Path: D:\\TTS-Audio-Suite\\ComfyUI\n** ComfyUI Base Folder Path: D:\\TTS-Audio-Suite\\ComfyUI\n** User directory: D:\\TTS-Audio-Suite\\ComfyUI\\user\n** ComfyUI-Manager config path: D:\\TTS-Audio-Suite\\ComfyUI\\user\\default\\ComfyUI-Manager\\config.ini\n** Log path: D:\\TTS-Audio-Suite\\ComfyUI\\user\\comfyui.log\n\nPrestartup times for custom nodes:\n  12.8 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Manager\n\nCheckpoint files will always be loaded safely.\nTotal VRAM 12282 MB, total RAM 16106 MB\npytorch version: 2.8.0+cu128\nxformers version: 0.0.32.post2\nEnabled fp16 accumulation.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 NVIDIA GeForce RTX 4070 Ti : cudaMallocAsync\nUsing async weight offloading with 2 streams\nEnabled pinned memory 7247.0\nUsing xformers attention\nPython version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\nComfyUI version: 0.3.76\nComfyUI frontend version: 1.33.10\n[Prompt Server] web root: D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\comfyui_frontend_package\\static\nTotal VRAM 12282 MB, total RAM 16106 MB\npytorch version: 2.8.0+cu128\nxformers version: 0.0.32.post2\nEnabled fp16 accumulation.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 NVIDIA GeForce RTX 4070 Ti : cudaMallocAsync\nUsing async weight offloading with 2 streams\nEnabled pinned memory 7247.0\n### Loading: ComfyUI-Manager (V3.37.2)\n[ComfyUI-Manager] network_mode: public\n[ComfyUI-Manager] Since --preview-method is set, ComfyUI-Manager's preview method feature will be ignored.\n### ComfyUI Version: v0.3.76-4-ga17cf1c38 | Released on '2025-12-01'\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n‚ÑπÔ∏è Critical package versions: NumPy 2.2.6, Librosa 0.11.0, Numba 0.62.1, PyTorch 2.8.0+cu128, TorchAudio 2.8.0+cu128, Transformers 4.57.2, Accelerate 1.12.0, SoundFile 0.13.1\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\nFETCH ComfyRegistry Data: 5/109\nAPEX FusedRMSNorm not available, using native implementation\nFETCH ComfyRegistry Data: 10/109\n======================================================================\nüöÄ TTS Audio Suite v4.14.33\nUniversal multi-engine TTS extension for ComfyUI\n‚úÖ TTS Audio Suite v4.14.33 loaded with 27 nodes:\n   ‚Ä¢ ‚öôÔ∏è ChatterBox Official 23-Lang Engine\n   ‚Ä¢ ‚öôÔ∏è ChatterBox TTS Engine\n   ‚Ä¢ ‚öôÔ∏è F5 TTS Engine\n   ‚Ä¢ ‚öôÔ∏è Higgs Audio 2 Engine\n   ‚Ä¢ ‚öôÔ∏è IndexTTS-2 Engine\n   ‚Ä¢ ‚öôÔ∏è RVC Engine\n   ‚Ä¢ ‚öôÔ∏è VibeVoice Engine\n   ‚Ä¢ üåà IndexTTS-2 Emotion Vectors\n   ‚Ä¢ üåà IndexTTS-2 Text Emotion\n   ‚Ä¢ üåä Audio Wave Analyzer\n   ‚Ä¢ üéôÔ∏è Voice Capture\n   ‚Ä¢ üé§ TTS Text\n   ‚Ä¢ üé≠ Character Voices\n   ‚Ä¢ üé≠ Load RVC Character Model\n   ‚Ä¢ üè∑Ô∏è Multiline TTS Tag Editor\n   ‚Ä¢ üëÑ F5-TTS Speech Editor\n   ‚Ä¢ üìù Phoneme Text Normalizer\n   ‚Ä¢ üì∫ TTS SRT\n   ‚Ä¢ üîÑ Voice Changer\n   ‚Ä¢ üîß Audio Analyzer Options\n   ‚Ä¢ üîß F5-TTS Edit Options\n   ‚Ä¢ üîß RVC Pitch Extraction Options\n   ‚Ä¢ üîß Viseme Mouth Shape Options\n   ‚Ä¢ üó£Ô∏è Silent Speech Analyzer\n   ‚Ä¢ ü§ê Noise or Vocal Removal\n   ‚Ä¢ ü§ê Voice Fixer\n   ‚Ä¢ ü•™ Merge Audio\n======================================================================\n\nImport times for custom nodes:\n   0.0 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\websocket_image_save.py\n   0.5 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Manager\n  10.0 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\n\nContext impl SQLiteImpl.\nWill assume non-transactional DDL.\nNo target revision found.\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\n[TTS Audio Suite] üé≠ Character voices: Found 26 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/groupNode.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\nLoading faiss with AVX2 support.\nSuccessfully loaded faiss with AVX2 support.\nFETCH ComfyRegistry Data: 15/109\nCannot connect to comfyregistry.\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n[ComfyUI-Manager] All startup tasks have been completed.\ngot prompt\nüåà IndexTTS-2 Text Emotion: Dynamic per-segment analysis with model 'local:qwen0.6bemo4-merge' - template: 'Happy character speaking: {seg}'\n‚öôÔ∏è IndexTTS-2: Configured on auto\n   Model: local:IndexTTS-2\n   Emotion: alpha=0.7, use_text=True (dynamic template)\n   Generation: temp=0.8, top_p=0.8, top_k=30, do_sample=True, num_beams=3\n   Chunking: max_tokens=120, silence=200ms\nü©π TTS AUDIO SUITE CUDNN FIX APPLIED\n   Disabled CUDNN benchmark on Python 3.12 to prevent VRAM spikes\n   This fixes ComfyUI v0.3.57+ regression - VRAM spikes eliminated!\n‚ö†Ô∏è TTS Text: No voice reference provided - this may cause issues with some engines\nüé§ Generating Index_Tts for 'narrator' (lang: en)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 8 character segment(s) - narrator\nüìñ Using mapped narrator voice: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\voices_examples\\David_Attenborough CC3.wav | Ref: '...'\nüé≠ No emotion audio for simple text segment (no connected engine emotion)\nüåà Dynamic Text Emotion: 'I have a dream that one day th...' ‚Üí 'Happy character speaking: I have a dream that one ...'\nüîÑ IndexTTS-2: Initializing engine (first run may take 2-3 minutes to load models)...\n   Loading: QwenEmotion ‚Üí GPT ‚Üí Semantic Codec ‚Üí S2Mel ‚Üí CampPlus ‚Üí BigVGAN...\n‚ö†Ô∏è Failed to load QwenEmotion model: 'dict' object has no attribute 'model_type'\n‚ÑπÔ∏è Falling back to audio emotion only\nüîÑ IndexTTS-2: Loading GPT model...\nüîÑ IndexTTS-2: Moving GPT to GPU...\n>> GPT weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\gpt.pth\n>> Failed to load DeepSpeed. Falling back to normal inference. Error: No module named 'deepspeed'\nüîÑ Loading W2V-BERT from TTS folder: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\w2v-bert-2.0\nüîÑ Initializing SeamlessM4TFeatureExtractor (this is the slow part)...\n‚úÖ W2V-BERT loaded in 0.0s\n>> semantic_codec weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\\semantic_codec\\model.safetensors\ncfm loaded\nlength_regulator loaded\ngpt_layer loaded\n>> s2mel weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\s2mel.pth\n>> campplus_model weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\\campplus_cn_common.bin\nLoading config.json from local directory\nLoading weights from local directory\nRemoving weight norm...\n>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x\nUsing wetext for text normalization (fallback)\n>> TextNormalizer loaded\n>> bpe model loaded from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\bpe.model\n‚úÖ IndexTTS-2 model loaded via unified interface on cuda:0\n‚úÖ IndexTTS-2 engine loaded via unified interface on cuda:0\n‚ö° Next generations will be much faster (models cached in VRAM)\n‚ö†Ô∏è Performance warning: IndexTTS-2 tested on Python 3.13 performs smoothly\n‚ö†Ô∏è Our Python 3.12 tests showed HIGH VRAM spikes during generation\n‚úÖ Re-registered Index-TTS with ComfyUI model management\n>> starting inference...\n```\n```\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\n```\n```\nUse the specified emotion vector\n`BeamSearchScorer` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\n`BeamHypotheses` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\ntorch.Size([1, 416512])\nUse the specified emotion vector\ntorch.Size([1, 428288])\nUse the specified emotion vector\ntorch.Size([1, 461824])\nUse the specified emotion vector\ntorch.Size([1, 349952])\n>> gpt_gen_time: 76.19 seconds\n>> gpt_forward_time: 0.09 seconds\n>> s2mel_time: 8.01 seconds\n>> bigvgan_time: 1.81 seconds\n>> Total inference time: 89.07 seconds\n>> Generated audio length: 75.73 seconds\n>> RTF: 1.1762\n‚úÖ Index_Tts generation complete. Default narrator: narrator\nPrompt executed in 110.29 seconds\n```","createdAt":"2025-12-02T04:58:53Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3600195628","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7W6psH","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod I still don‚Äôt understand how to use the ‚ÄòText Emotion‚Äô node, nor do I know how to make the ‚Äòqwen0.6bemo4‚Äëmerge‚Äô model work. In the workflow below, is the narration part based on the voice features from the ‚ÄòCharacter Voices‚Äô node, and is it also processed by the ‚Äúqwen0.6bemo4‚Äëmerge‚Äù model? And are Alice and Bob‚Äôs voices processed through the ‚Äúqwen0.6bemo4‚Äëmerge‚Äù model as well?\n\n<img width=\"1761\" height=\"829\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e5f36f9a-cf7f-4322-a29e-4947ba92b178\" />","createdAt":"2025-12-03T08:44:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3605699335","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7W68WI","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"<img width=\"1726\" height=\"795\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/75cdeae8-dd3a-4ed1-a101-26b54c11a429\" />\n\n[ComfyUI_00001_.mp3](https://github.com/user-attachments/files/23901153/ComfyUI_00001_.mp3)","createdAt":"2025-12-03T09:03:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3605775752","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7W682o","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"<img width=\"1634\" height=\"741\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9bb2aa69-b686-4887-a07f-f3cfe3cc07c9\" />\n\n[ComfyUI_00002_.mp3](https://github.com/user-attachments/files/23901163/ComfyUI_00002_.mp3)","createdAt":"2025-12-03T09:03:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3605777832","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7W6-jV","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"<img width=\"1789\" height=\"723\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9fa857d4-4d83-4828-ab9e-2fe1d663bc77\" />\n\n[ComfyUI_00003_.mp3](https://github.com/user-attachments/files/23901200/ComfyUI_00003_.mp3)","createdAt":"2025-12-03T09:04:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3605784789","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7W7Al8","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"All of these results are the same.","createdAt":"2025-12-03T09:06:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3605793148","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Xu2ni","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod) I still don‚Äôt understand how to use the ‚ÄòText Emotion‚Äô node, nor do I know how to make the ‚Äòqwen0.6bemo4‚Äëmerge‚Äô model work. \n>\nI'm at a loss here, you probably have a corrupted download. Try deleting the whole Index2 model from the Models/TTS/Index2WhateverTheNameIs and let it download the model again. If you still get an error, try to search in your .cache folder (ask an llm to help you get there), it might be trying to read from a currupted model on the cache folder.\n\n>In the workflow below, is the narration part based on the voice features from the ‚ÄòCharacter Voices‚Äô node, and is it also processed by the ‚Äúqwen0.6bemo4‚Äëmerge‚Äù model? \n>\nQwen will only read the text and give you \"emotional\" vectors based on what it thinks the content feels like. It's like an LLM deciding what emotion vectors you will be using for that segment.\n\n>And are Alice and Bob‚Äôs voices processed through the ‚Äúqwen0.6bemo4‚Äëmerge‚Äù model as well?\n>\nyes, each character switch makes a new segment, and all segments get affected by the emotion vectors.\n","createdAt":"2025-12-06T03:06:04Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3619383778","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Xu3OT","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> All of these results are the same.\n\nI see no obvious reasons to why these are failing. I suggest trying to delete and redownload your qwen model. If it still fails this might be a specific bug related to dependencies, in which case please post again and we can try to think of a solution.","createdAt":"2025-12-06T03:09:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3619386259","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7XxoJB","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> > All of these results are the same.\n> \n> I see no obvious reasons to why these are failing. I suggest trying to delete and redownload your qwen model. If it still fails this might be a specific bug related to dependencies, in which case please post again and we can try to think of a solution.\n\nIs there a download link for qwen0.6bemo4-merge? The README is the only place that doesn‚Äôt provide one. Maybe the automatically downloaded file was corrupted, so I‚Äôd like to try downloading it manually.","createdAt":"2025-12-06T12:28:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3620110913","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7XzocI","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Manual Download Instructions for QwenEmotion Model\n\n### Step 1: Delete the Corrupted Model\n\nFirst, delete the entire corrupted `qwen0.6bemo4-merge` folder:\n\n**On Windows:**\n```\nD:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\qwen0.6bemo4-merge\\\n```\nDelete this entire folder.\n\n---\n\n### Step 2: Download All Required Files\n\nYou need to download **11 files** from HuggingFace. The easiest method is using the **HuggingFace CLI** (recommended):\n\n**Option A: Using HuggingFace CLI (EASIEST - Downloads all files at once)**\n\nRun this in PowerShell:\n```powershell\nhuggingface-cli download IndexTeam/IndexTTS-2 --include \"qwen0.6bemo4-merge/*\" --local-dir \"D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\" --local-dir-use-symlinks False\n```\n\n**Option B: Manual Download (if CLI doesn't work)**\n\nDownload each file individually from the HuggingFace repository at:\n`https://huggingface.co/IndexTeam/IndexTTS-2/tree/main/qwen0.6bemo4-merge`\n\nFiles to download (in order of importance):\n\n| Priority | Filename | Size |\n|----------|----------|------|\n| **CRITICAL** | `model.safetensors` | 1.19 GB |\n| **CRITICAL** | `config.json` | 727 B |\n| **CRITICAL** | `tokenizer.json` | 11.4 MB |\n| **CRITICAL** | `tokenizer_config.json` | 5.43 kB |\n| Important | `vocab.json` | 2.78 MB |\n| Important | `merges.txt` | 1.67 MB |\n| Important | `generation_config.json` | 117 B |\n| Important | `special_tokens_map.json` | 616 B |\n| Important | `added_tokens.json` | 707 B |\n| Important | `chat_template.jinja` | 550 B |\n| Important | `Modelfile` | 360 B |\n\n---\n\n### Step 3: Place Files in Correct Directory\n\nAfter downloading, place all files in:\n\n```\nD:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\qwen0.6bemo4-merge\\\n```\n\nYour folder structure should look like:\n```\nD:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\\n‚îú‚îÄ‚îÄ qwen0.6bemo4-merge\\\n‚îÇ   ‚îú‚îÄ‚îÄ model.safetensors          (1.19 GB)\n‚îÇ   ‚îú‚îÄ‚îÄ config.json                (727 B)\n‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json             (11.4 MB)\n‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_config.json      (5.43 kB)\n‚îÇ   ‚îú‚îÄ‚îÄ vocab.json                 (2.78 MB)\n‚îÇ   ‚îú‚îÄ‚îÄ merges.txt                 (1.67 MB)\n‚îÇ   ‚îú‚îÄ‚îÄ generation_config.json     (117 B)\n‚îÇ   ‚îú‚îÄ‚îÄ special_tokens_map.json    (616 B)\n‚îÇ   ‚îú‚îÄ‚îÄ added_tokens.json          (707 B)\n‚îÇ   ‚îú‚îÄ‚îÄ chat_template.jinja        (550 B)\n‚îÇ   ‚îî‚îÄ‚îÄ Modelfile                  (360 B)\n```\n\n---\n\n### Step 4: Verify & Restart ComfyUI\n\n1. Make sure all 11 files are in the folder\n2. Close ComfyUI completely\n3. Restart ComfyUI\n4. Try using the \"IndexTTS-2 Text Emotion\" node again\n\n---\n\n**Total Download Size:** ~1.21 GB\n\nIf you continue to have issues after this, please report back with the error message and we can investigate further.","createdAt":"2025-12-06T16:06:59Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3620636424","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Xz893","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> ## Manual Download Instructions for QwenEmotion Model\n> \n> ### Step 1: Delete the Corrupted Model\n> \n> First, delete the entire corrupted `qwen0.6bemo4-merge` folder:\n> \n> **On Windows:**\n> ```\n> D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\qwen0.6bemo4-merge\\\n> ```\n> Delete this entire folder.\n> \n> ---\n> \n> ### Step 2: Download All Required Files\n> \n> You need to download **11 files** from HuggingFace. The easiest method is using the **HuggingFace CLI** (recommended):\n> \n> **Option A: Using HuggingFace CLI (EASIEST - Downloads all files at once)**\n> \n> Run this in PowerShell:\n> ```powershell\n> huggingface-cli download IndexTeam/IndexTTS-2 --include \"qwen0.6bemo4-merge/*\" --local-dir \"D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\" --local-dir-use-symlinks False\n> ```\n> \n> **Option B: Manual Download (if CLI doesn't work)**\n> \n> Download each file individually from the HuggingFace repository at:\n> `https://huggingface.co/IndexTeam/IndexTTS-2/tree/main/qwen0.6bemo4-merge`\n> \n> Files to download (in order of importance):\n> \n> | Priority | Filename | Size |\n> |----------|----------|------|\n> | **CRITICAL** | `model.safetensors` | 1.19 GB |\n> | **CRITICAL** | `config.json` | 727 B |\n> | **CRITICAL** | `tokenizer.json` | 11.4 MB |\n> | **CRITICAL** | `tokenizer_config.json` | 5.43 kB |\n> | Important | `vocab.json` | 2.78 MB |\n> | Important | `merges.txt` | 1.67 MB |\n> | Important | `generation_config.json` | 117 B |\n> | Important | `special_tokens_map.json` | 616 B |\n> | Important | `added_tokens.json` | 707 B |\n> | Important | `chat_template.jinja` | 550 B |\n> | Important | `Modelfile` | 360 B |\n> \n> ---\n> \n> ### Step 3: Place Files in Correct Directory\n> \n> After downloading, place all files in:\n> \n> ```\n> D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\qwen0.6bemo4-merge\\\n> ```\n> \n> Your folder structure should look like:\n> ```\n> D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\\n> ‚îú‚îÄ‚îÄ qwen0.6bemo4-merge\\\n> ‚îÇ   ‚îú‚îÄ‚îÄ model.safetensors          (1.19 GB)\n> ‚îÇ   ‚îú‚îÄ‚îÄ config.json                (727 B)\n> ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json             (11.4 MB)\n> ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_config.json      (5.43 kB)\n> ‚îÇ   ‚îú‚îÄ‚îÄ vocab.json                 (2.78 MB)\n> ‚îÇ   ‚îú‚îÄ‚îÄ merges.txt                 (1.67 MB)\n> ‚îÇ   ‚îú‚îÄ‚îÄ generation_config.json     (117 B)\n> ‚îÇ   ‚îú‚îÄ‚îÄ special_tokens_map.json    (616 B)\n> ‚îÇ   ‚îú‚îÄ‚îÄ added_tokens.json          (707 B)\n> ‚îÇ   ‚îú‚îÄ‚îÄ chat_template.jinja        (550 B)\n> ‚îÇ   ‚îî‚îÄ‚îÄ Modelfile                  (360 B)\n> ```\n> \n> ---\n> \n> ### Step 4: Verify & Restart ComfyUI\n> \n> 1. Make sure all 11 files are in the folder\n> 2. Close ComfyUI completely\n> 3. Restart ComfyUI\n> 4. Try using the \"IndexTTS-2 Text Emotion\" node again\n> \n> ---\n> \n> **Total Download Size:** ~1.21 GB\n> \n> If you continue to have issues after this, please report back with the error message and we can investigate further.\n\nMany thanks; the explanation has been provided with exceptional clarity and specificity.","createdAt":"2025-12-06T17:19:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3620720503","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7X0R9w","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'm still not completely sure it is a corrupted model, but let's hope üòÖ","createdAt":"2025-12-06T17:45:52Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3620806512","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7YIHoZ","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> I'm still not completely sure it is a corrupted model, but let's hope üòÖ\n\n```\ngot prompt\nWARNING: 'NoneType' object is not subscriptable\nüåà IndexTTS-2 Text Emotion: Dynamic per-segment analysis with model 'local:qwen0.6bemo4-merge' - template: 'Happy character speaking: {seg}'\n‚öôÔ∏è IndexTTS-2: Configured on auto\n   Model: local:IndexTTS-2\n   Emotion: alpha=0.7, use_text=True (dynamic template)\n   Generation: temp=0.8, top_p=0.8, top_k=30, do_sample=True, num_beams=3\n   Chunking: max_tokens=120, silence=200ms\nü©π TTS AUDIO SUITE CUDNN FIX APPLIED\n   Disabled CUDNN benchmark on Python 3.12 to prevent VRAM spikes\n   This fixes ComfyUI v0.3.57+ regression - VRAM spikes eliminated!\n‚ö†Ô∏è TTS Text: No voice reference provided - this may cause issues with some engines\nüé§ Generating Index_Tts for 'narrator' (lang: en)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ Character 'Alice' auto-switching to üö® alias default language 'de'\nüé≠ Character 'Bob' auto-switching to üö® alias default language 'fr'\nüé≠ IndexTTS-2: Processing 4 character segment(s) - female_01, male_01, narrator\nüìñ Using mapped narrator voice: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\voices_examples\\David_Attenborough CC3.wav | Ref: '...'\nüé≠ male_01: Loaded voice reference\nüé≠ female_01: Loaded voice reference\nüé≠ No emotion audio for character: narrator (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'Hello! This is unified TTS wit...' ‚Üí 'Happy character speaking: Hello! This is unified T...'\nüîÑ IndexTTS-2: Initializing engine (first run may take 2-3 minutes to load models)...\n   Loading: QwenEmotion ‚Üí GPT ‚Üí Semantic Codec ‚Üí S2Mel ‚Üí CampPlus ‚Üí BigVGAN...\n‚ö†Ô∏è Failed to load QwenEmotion model: 'dict' object has no attribute 'model_type'\n‚ÑπÔ∏è Falling back to audio emotion only\nüîÑ IndexTTS-2: Loading GPT model...\nüîÑ IndexTTS-2: Moving GPT to GPU...\n>> GPT weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\gpt.pth\n>> Failed to load DeepSpeed. Falling back to normal inference. Error: No module named 'deepspeed'\nüîÑ Loading W2V-BERT from TTS folder: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\w2v-bert-2.0\nüîÑ Initializing SeamlessM4TFeatureExtractor (this is the slow part)...\n‚úÖ W2V-BERT loaded in 0.0s\nüì• Downloading IndexTTS-2 model: MaskGCT\nüìÅ Target directory: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\nüì• Downloading MaskGCT/semantic_codec/model.safetensors directly (no cache)\nüì• Downloading model.safetensors: 100.0%\n‚úÖ Downloaded: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\\semantic_codec/model.safetensors\n‚ÑπÔ∏è QwenEmotion model not found - audio emotion only\n‚úÖ Model verification passed\n‚úÖ MaskGCT model downloaded successfully\nüìÅ Model path: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\n>> semantic_codec weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\\semantic_codec\\model.safetensors\ncfm loaded\nlength_regulator loaded\ngpt_layer loaded\n>> s2mel weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\s2mel.pth\nüì• Downloading IndexTTS-2 model: campplus\nüìÅ Target directory: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\nüì• Downloading campplus/campplus_cn_common.bin directly (no cache)\nüì• Downloading campplus_cn_common.bin: 100.0%\n‚úÖ Downloaded: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\\campplus_cn_common.bin\n‚ÑπÔ∏è QwenEmotion model not found - audio emotion only\n‚úÖ Model verification passed\n‚úÖ campplus model downloaded successfully\nüìÅ Model path: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\n>> campplus_model weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\\campplus_cn_common.bin\nüì• Downloading IndexTTS-2 model: bigvgan_v2_22khz_80band_256x\nüìÅ Target directory: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\bigvgan_v2_22khz_80band_256x\nüì• Downloading bigvgan_v2_22khz_80band_256x/config.json directly (no cache)\n\n‚úÖ Downloaded: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\bigvgan_v2_22khz_80band_256x\\config.json\nüì• Downloading bigvgan_v2_22khz_80band_256x/bigvgan_generator.pt directly (no cache)\nüì• Downloading bigvgan_generator.pt: 100.0%\n‚úÖ Downloaded: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\bigvgan_v2_22khz_80band_256x\\bigvgan_generator.pt\n‚ÑπÔ∏è QwenEmotion model not found - audio emotion only\n‚úÖ Model verification passed\n‚úÖ bigvgan_v2_22khz_80band_256x model downloaded successfully\nüìÅ Model path: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\bigvgan_v2_22khz_80band_256x\nLoading config.json from local directory\nLoading weights from local directory\nRemoving weight norm...\n>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x\nUsing wetext for text normalization (fallback)\n>> TextNormalizer loaded\n>> bpe model loaded from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\bpe.model\n‚úÖ IndexTTS-2 model loaded via unified interface on cuda:0\n‚úÖ IndexTTS-2 engine loaded via unified interface on cuda:0\n‚ö° Next generations will be much faster (models cached in VRAM)\n‚ö†Ô∏è Performance warning: IndexTTS-2 tested on Python 3.13 performs smoothly\n‚ö†Ô∏è Our Python 3.12 tests showed HIGH VRAM spikes during generation\n‚úÖ Re-registered Index-TTS with ComfyUI model management\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\n`BeamSearchScorer` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\n`BeamHypotheses` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\ntorch.Size([1, 117504])\n>> gpt_gen_time: 9.65 seconds\n>> gpt_forward_time: 0.04 seconds\n>> s2mel_time: 1.14 seconds\n>> bigvgan_time: 0.19 seconds\n>> Total inference time: 12.78 seconds\n>> Generated audio length: 5.33 seconds\n>> RTF: 2.3978\nüé≠ No emotion audio for character: female_01 (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'Hi there! I'm Alice speaking w...' ‚Üí 'Happy character speaking: Hi there! I'm Alice spea...'\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\ntorch.Size([1, 80384])\n>> gpt_gen_time: 6.46 seconds\n>> gpt_forward_time: 0.04 seconds\n>> s2mel_time: 0.92 seconds\n>> bigvgan_time: 0.09 seconds\n>> Total inference time: 7.88 seconds\n>> Generated audio length: 3.65 seconds\n>> RTF: 2.1611\nüé≠ No emotion audio for character: male_01 (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'And I'm Bob! This works with a...' ‚Üí 'Happy character speaking: And I'm Bob! This works ...'\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\ntorch.Size([1, 66304])\n>> gpt_gen_time: 5.28 seconds\n>> gpt_forward_time: 0.02 seconds\n>> s2mel_time: 1.13 seconds\n>> bigvgan_time: 0.16 seconds\n>> Total inference time: 6.90 seconds\n>> Generated audio length: 3.01 seconds\n>> RTF: 2.2960\nüé≠ No emotion audio for character: narrator (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'Back to the main narrator voic...' ‚Üí 'Happy character speaking: Back to the main narrato...'\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\ntorch.Size([1, 82688])\n>> gpt_gen_time: 6.70 seconds\n>> gpt_forward_time: 0.01 seconds\n>> s2mel_time: 0.85 seconds\n>> bigvgan_time: 0.08 seconds\n>> Total inference time: 7.88 seconds\n>> Generated audio length: 3.75 seconds\n>> RTF: 2.1004\n‚úÖ Index_Tts generation complete. Default narrator: narrator\nPrompt executed in 128.49 seconds\n```","createdAt":"2025-12-08T09:51:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3626007065","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7YIMHs","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod The QwenEmotion file is not damaged, and the workflow is fine. Now, I don't know what to do.\n\n<img width=\"1846\" height=\"713\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d7458f08-a912-497e-9b0a-06079a58dc76\" />","createdAt":"2025-12-08T09:55:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3626025452","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7YzOr_","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I've improved the download system to be more reliable - it now prioritizes HuggingFace CLI over direct HTTP, which handles network issues better.\n\nHowever, since your issue was that the files downloaded successfully but still failed to load, this may not directly solve your problem. The loading error (`'dict' object has no attribute 'model_type'`) suggests something different.\n\n## To Help Debug Further\n\nIf you want to test the improved downloader, you'll need the nightly build since we haven't bumped the version yet (still working on Step Audio EditX implementation).\n\nTo test:\n1. Delete: `J:\\...\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\qwen0.6bemo4-merge\\`\n2. Update to latest from main branch\n3. Try IndexTTS-2 Text Emotion again\n\nIf the loading error persists, we may need to investigate what's specific to your environment that's causing the model loading to fail.","createdAt":"2025-12-10T14:18:48Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3637308159","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7ZGtsc","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> I've improved the download system to be more reliable - it now prioritizes HuggingFace CLI over direct HTTP, which handles network issues better.\n> \n> However, since your issue was that the files downloaded successfully but still failed to load, this may not directly solve your problem. The loading error (`'dict' object has no attribute 'model_type'`) suggests something different.\n> \n> ## To Help Debug Further\n> \n> If you want to test the improved downloader, you'll need the nightly build since we haven't bumped the version yet (still working on Step Audio EditX implementation).\n> \n> To test:\n> 1. Delete: `J:\\...\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\qwen0.6bemo4-merge\\`\n> 2. Update to latest from main branch\n> 3. Try IndexTTS-2 Text Emotion again\n> \n> If the loading error persists, we may need to investigate what's specific to your environment that's causing the model loading to fail.\n\nI plan to test Qwen Emotion after merging the night branch into the main branch. Right now, I‚Äôm more interested in Step Audio EditX, so I‚Äôm going to give it a try.","createdAt":"2025-12-11T15:18:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3642415900","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7aLii6","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi @Amazon90 v4.13 now have EditX full support. Please test it, and then test Qwen Emotion model on Index2 again to see if it is working so we can try to resolve this issue.","createdAt":"2025-12-16T13:11:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3660458170","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7aZ363","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> Hi @Amazon90 v4.13 now have EditX full support. Please test it, and then test Qwen Emotion model on Index2 again to see if it is working so we can try to resolve this issue.\n\nI‚Äôm sorting through and trying to understand the workflow you provided, and this will take some time.","createdAt":"2025-12-17T08:28:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3664215735","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7abstY","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod One possible improvement is that the ‚ÄòStep Audio EditX Engine‚Äô node has a default ‚Äòmax_new_tokens‚Äô value of 8192. With my 4070ti GPU, the inference speed is 2.5 it/s, which means it takes nearly an hour to complete. I hope there is a way to automatically calculate the tokens from the input ‚ÄòTTS Text‚Äô node and apply them to the ‚ÄòStep Audio EditX Engine‚Äô.\n\n---\n\nI see where the problem is: in the process, input_token = 594, but inference is calculated based on max_new_tokens.","createdAt":"2025-12-17T10:28:02Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3664694104","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7acpnQ","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod) One possible improvement is that the ‚ÄòStep Audio EditX Engine‚Äô node has a default ‚Äòmax_new_tokens‚Äô value of 8192. With my 4070ti GPU, the inference speed is 2.5 it/s, which means it takes nearly an hour to complete. I hope there is a way to automatically calculate the tokens from the input ‚ÄòTTS Text‚Äô node and apply them to the ‚ÄòStep Audio EditX Engine‚Äô.\n> \n> I see where the problem is: in the process, input_token = 594, but inference is calculated based on max_new_tokens.\n\nmax new token is just the total max number it can potentially generate. But it should be stopping as soon as it generated enough tokens to make your TTS. If your generation is not stopping automatically much sooner, there is a problem, and it is probably just generating silence.  If that is the case, please report back, tell me what is your transformers version. This is normally result of the transformers bug that I though I have fixed... you can try to downgrade to transformers 4.53.3 to see if it changes anything... if it does, than my bug fix is wrong and I need to make some more modifications...\n\nAlso 2.5 it/s is very slow. On a 4090 I get 20-22 it/s, and it goes down as the generation proceeds but never this low. Unless you are using quantization.","createdAt":"2025-12-17T11:35:33Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3664943568","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7acrxT","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"In any case, we should stick to this issue problem about index2, if you need support on step editx please open another issue.","createdAt":"2025-12-17T11:38:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3664952403","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7bMnhJ","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod To thoroughly test why the QwenEmotion model isn‚Äôt functioning, I deleted the previously downloaded version of the model. After rerunning the workflow, the model no longer downloads automatically, which contradicts your earlier claim that the model download issue had been fixed\n\n<img width=\"1347\" height=\"586\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/049da960-99a2-4f58-9c9c-4100e9238b89\" />\n\n```\n[START] Security scan\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2025-12-20 15:19:55.106\n** Platform: Windows\n** Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n** Python executable: D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Scripts\\Python.exe\n** ComfyUI Path: D:\\TTS-Audio-Suite\\ComfyUI\n** ComfyUI Base Folder Path: D:\\TTS-Audio-Suite\\ComfyUI\n** User directory: D:\\TTS-Audio-Suite\\ComfyUI\\user\n** ComfyUI-Manager config path: D:\\TTS-Audio-Suite\\ComfyUI\\user\\__manager\\config.ini\n** Log path: D:\\TTS-Audio-Suite\\ComfyUI\\user\\comfyui.log\n\nPrestartup times for custom nodes:\n   0.0 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\n  24.6 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Manager\n\nCheckpoint files will always be loaded safely.\nTotal VRAM 12282 MB, total RAM 16106 MB\npytorch version: 2.8.0+cu128\nxformers version: 0.0.32.post2\nEnabled fp16 accumulation.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 NVIDIA GeForce RTX 4070 Ti : cudaMallocAsync\nUsing async weight offloading with 2 streams\nEnabled pinned memory 7247.0\nUsing xformers attention\nPython version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\nComfyUI version: 0.5.1\nComfyUI frontend version: 1.34.9\n[Prompt Server] web root: D:\\TTS-Audio-Suite\\ComfyUI\\venv\\Lib\\site-packages\\comfyui_frontend_package\\static\nTotal VRAM 12282 MB, total RAM 16106 MB\npytorch version: 2.8.0+cu128\nxformers version: 0.0.32.post2\nEnabled fp16 accumulation.\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 NVIDIA GeForce RTX 4070 Ti : cudaMallocAsync\nUsing async weight offloading with 2 streams\nEnabled pinned memory 7247.0\n[ComfyUI-Easy-Use] server: v1.3.4 Loaded\n[ComfyUI-Easy-Use] web root: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\\web_version/v2 Loaded\n### Loading: ComfyUI-Manager (V3.39)\n[ComfyUI-Manager] network_mode: public\n[ComfyUI-Manager] ComfyUI per-queue preview override detected (PR #11261). Manager's preview method feature is disabled. Use ComfyUI's --preview-method CLI option or 'Settings > Execution > Live preview method'.\n### ComfyUI Version: v0.5.1-20-g0899012ad | Released on '2025-12-19'\n   üîá Suppressed torchaudio 2.9 migration warnings\nAPEX FusedRMSNorm not available, using native implementation\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n‚ÑπÔ∏è Critical package versions: NumPy 2.2.6, Librosa 0.11.0, Numba 0.62.1, PyTorch 2.8.0+cu128, TorchAudio 2.8.0+cu128, Transformers 4.57.2, Accelerate 1.12.0, SoundFile 0.13.1\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n======================================================================\nüöÄ TTS Audio Suite v4.15.12\nUniversal multi-engine TTS extension for ComfyUI\n‚úÖ TTS Audio Suite v4.15.12 loaded with 29 nodes:\n   ‚Ä¢ ‚öôÔ∏è ChatterBox Official 23-Lang Engine\n   ‚Ä¢ ‚öôÔ∏è ChatterBox TTS Engine\n   ‚Ä¢ ‚öôÔ∏è F5 TTS Engine\n   ‚Ä¢ ‚öôÔ∏è Higgs Audio 2 Engine\n   ‚Ä¢ ‚öôÔ∏è IndexTTS-2 Engine\n   ‚Ä¢ ‚öôÔ∏è RVC Engine\n   ‚Ä¢ ‚öôÔ∏è Step Audio EditX Engine\n   ‚Ä¢ ‚öôÔ∏è VibeVoice Engine\n   ‚Ä¢ üåà IndexTTS-2 Emotion Vectors\n   ‚Ä¢ üåà IndexTTS-2 Text Emotion\n   ‚Ä¢ üåä Audio Wave Analyzer\n   ‚Ä¢ üéôÔ∏è Voice Capture\n   ‚Ä¢ üé§ TTS Text\n   ‚Ä¢ üé® Step Audio EditX - Audio Editor\n   ‚Ä¢ üé≠ Character Voices\n   ‚Ä¢ üé≠ Load RVC Character Model\n   ‚Ä¢ üè∑Ô∏è Multiline TTS Tag Editor\n   ‚Ä¢ üëÑ F5-TTS Speech Editor\n   ‚Ä¢ üìù Phoneme Text Normalizer\n   ‚Ä¢ üì∫ TTS SRT\n   ‚Ä¢ üîÑ Voice Changer\n   ‚Ä¢ üîß Audio Analyzer Options\n   ‚Ä¢ üîß F5-TTS Edit Options\n   ‚Ä¢ üîß RVC Pitch Extraction Options\n   ‚Ä¢ üîß Viseme Mouth Shape Options\n   ‚Ä¢ üó£Ô∏è Silent Speech Analyzer\n   ‚Ä¢ ü§ê Noise or Vocal Removal\n   ‚Ä¢ ü§ê Voice Fixer\n   ‚Ä¢ ü•™ Merge Audio\n======================================================================\n\nImport times for custom nodes:\n   0.0 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\websocket_image_save.py\n   0.0 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Custom-Scripts\n   0.9 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Manager\n   7.5 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\n   9.7 seconds: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\n\nContext impl SQLiteImpl.\nWill assume non-transactional DDL.\nNo target revision found.\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\n[TTS Audio Suite] üé≠ Character voices: Found 27 characters, 10 aliases (cached)\n[TTS Audio Suite] üîÑ Updating character discovery in background...\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/groupNode.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\nFETCH ComfyRegistry Data: 5/114\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\nLoading faiss with AVX2 support.\nSuccessfully loaded faiss with AVX2 support.\nüîß Settings endpoint called\nüîß Received settings: precision=auto, device=auto\nüé® Step Audio EditX inline tags: precision=auto, device=auto\nFETCH ComfyRegistry Data: 10/114\nFETCH ComfyRegistry Data: 15/114\nFETCH ComfyRegistry Data: 20/114\nFETCH ComfyRegistry Data: 25/114\nFETCH ComfyRegistry Data: 30/114\nFETCH ComfyRegistry Data: 35/114\nFETCH ComfyRegistry Data: 40/114\nFETCH ComfyRegistry Data: 45/114\nFETCH ComfyRegistry Data: 50/114\nFETCH ComfyRegistry Data: 55/114\nFETCH ComfyRegistry Data: 60/114\nFETCH ComfyRegistry Data: 65/114\nFETCH ComfyRegistry Data: 70/114\nFETCH ComfyRegistry Data: 75/114\nFETCH ComfyRegistry Data: 80/114\nüîß Settings endpoint called\nüîß Received settings: precision=auto, device=auto\nüé® Step Audio EditX inline tags: precision=auto, device=auto\nFETCH ComfyRegistry Data: 85/114\nFETCH ComfyRegistry Data: 90/114\nFETCH ComfyRegistry Data: 95/114\nFETCH ComfyRegistry Data: 100/114\nFETCH ComfyRegistry Data: 105/114\nFETCH ComfyRegistry Data: 110/114\nFETCH ComfyRegistry Data [DONE]\n[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n[ComfyUI-Manager] All startup tasks have been completed.\ngot prompt\nüåà IndexTTS-2 Text Emotion: Dynamic per-segment analysis with model 'qwen0.6bemo4-merge' - template: 'Worried parent: {seg}'\n‚öôÔ∏è IndexTTS-2: Configured on auto\n   Model: local:IndexTTS-2\n   Emotion: alpha=0.7, use_text=True (dynamic template)\n   Generation: temp=0.8, top_p=0.8, top_k=30, do_sample=True, num_beams=3\n   Chunking: max_tokens=120, silence=200ms\nü©π TTS AUDIO SUITE CUDNN FIX APPLIED\n   Disabled CUDNN benchmark on Python 3.12 to prevent VRAM spikes\n   This fixes ComfyUI v0.3.57+ regression - VRAM spikes eliminated!\n‚ö†Ô∏è TTS Text: No voice reference provided - this may cause issues with some engines\nüé§ Generating Index_Tts for 'narrator' (lang: en)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 4 character segment(s) - narrator\nüìñ Using mapped narrator voice: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\voices_examples\\David_Attenborough CC3.wav | Ref: '...'\nüé≠ No emotion audio for simple text segment (no connected engine emotion)\nüåà Dynamic Text Emotion: 'On Tuesdays, the pigeons held ...' ‚Üí 'Worried parent: On Tuesdays, the pigeons held parl...'\nüîÑ IndexTTS-2: Initializing engine (first run may take 2-3 minutes to load models)...\n   Loading: QwenEmotion ‚Üí GPT ‚Üí Semantic Codec ‚Üí S2Mel ‚Üí CampPlus ‚Üí BigVGAN...\n‚ÑπÔ∏è QwenEmotion model not available - audio emotion only\nüîÑ IndexTTS-2: Loading GPT model...\nüîÑ IndexTTS-2: Moving GPT to cuda:0...\n>> GPT weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\gpt.pth\n>> Failed to load DeepSpeed. Falling back to normal inference. Error: No module named 'deepspeed'\nüîÑ Loading W2V-BERT from TTS folder: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\w2v-bert-2.0\nüîÑ Initializing SeamlessM4TFeatureExtractor (this is the slow part)...\n‚úÖ W2V-BERT loaded in 0.0s\n>> semantic_codec weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\\semantic_codec\\model.safetensors\ncfm loaded\nlength_regulator loaded\ngpt_layer loaded\n>> s2mel weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\s2mel.pth\n>> campplus_model weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\\campplus_cn_common.bin\nLoading config.json from local directory\nLoading weights from local directory\nRemoving weight norm...\n>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x\nUsing wetext for text normalization (fallback)\n>> TextNormalizer loaded\n>> bpe model loaded from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\bpe.model\n‚úÖ IndexTTS-2 model loaded via unified interface on cuda:0\n‚úÖ IndexTTS-2 engine loaded via unified interface on cuda:0\n‚ö° Next generations will be much faster (models cached in VRAM)\n‚ö†Ô∏è Performance warning: IndexTTS-2 tested on Python 3.13 performs smoothly\n‚ö†Ô∏è Our Python 3.12 tests showed HIGH VRAM spikes during generation\n‚úÖ Re-registered Index-TTS with ComfyUI model management\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\n`BeamSearchScorer` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\n`BeamHypotheses` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\ntorch.Size([1, 266752])\nUse the specified emotion vector\ntorch.Size([1, 143360])\n>> gpt_gen_time: 17.36 seconds\n>> gpt_forward_time: 0.05 seconds\n>> s2mel_time: 2.46 seconds\n>> bigvgan_time: 0.58 seconds\n>> Total inference time: 21.77 seconds\n>> Generated audio length: 18.80 seconds\n>> RTF: 1.1579\n‚úÖ Index_Tts generation complete. Default narrator: narrator\nPrompt executed in 39.61 seconds\n```","createdAt":"2025-12-20T07:25:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3677517897","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7bMsmm","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"@diodiogod I manually downloaded the QwenEmotion model again, and from the output logs it‚Äôs clear the issue is the same as before: the model is still not actually being used. I hope you can thoroughly investigate what‚Äôs causing this.\n\n<img width=\"1582\" height=\"655\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3ca4f464-9fec-4218-a4d5-0a3a6bedfe6b\" />\n\n```\ngot prompt\nüåà IndexTTS-2 Text Emotion: Dynamic per-segment analysis with model 'local:qwen0.6bemo4-merge' - template: 'Worried parent: {seg}'\n‚öôÔ∏è IndexTTS-2: Configured on auto\n   Model: local:IndexTTS-2\n   Emotion: alpha=0.7, use_text=True (dynamic template)\n   Generation: temp=0.8, top_p=0.8, top_k=30, do_sample=True, num_beams=3\n   Chunking: max_tokens=120, silence=200ms\nü©π TTS AUDIO SUITE CUDNN FIX APPLIED\n   Disabled CUDNN benchmark on Python 3.12 to prevent VRAM spikes\n   This fixes ComfyUI v0.3.57+ regression - VRAM spikes eliminated!\n‚ö†Ô∏è TTS Text: No voice reference provided - this may cause issues with some engines\nüé§ Generating Index_Tts for 'narrator' (lang: en)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 4 character segment(s) - narrator\nüìñ Using mapped narrator voice: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\voices_examples\\David_Attenborough CC3.wav | Ref: '...'\nüé≠ No emotion audio for simple text segment (no connected engine emotion)\nüåà Dynamic Text Emotion: 'On Tuesdays, the pigeons held ...' ‚Üí 'Worried parent: On Tuesdays, the pigeons held parl...'\nüîÑ IndexTTS-2: Initializing engine (first run may take 2-3 minutes to load models)...\n   Loading: QwenEmotion ‚Üí GPT ‚Üí Semantic Codec ‚Üí S2Mel ‚Üí CampPlus ‚Üí BigVGAN...\n‚ö†Ô∏è Failed to load QwenEmotion model: 'dict' object has no attribute 'model_type'\n‚ÑπÔ∏è Falling back to audio emotion only\nüîÑ IndexTTS-2: Loading GPT model...\nüîÑ IndexTTS-2: Moving GPT to cuda:0...\n>> GPT weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\gpt.pth\n>> Failed to load DeepSpeed. Falling back to normal inference. Error: No module named 'deepspeed'\nüîÑ Loading W2V-BERT from TTS folder: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\w2v-bert-2.0\nüîÑ Initializing SeamlessM4TFeatureExtractor (this is the slow part)...\n‚úÖ W2V-BERT loaded in 0.0s\n>> semantic_codec weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\MaskGCT\\semantic_codec\\model.safetensors\ncfm loaded\nlength_regulator loaded\ngpt_layer loaded\n>> s2mel weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\s2mel.pth\n>> campplus_model weights restored from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\campplus\\campplus_cn_common.bin\nLoading config.json from local directory\nLoading weights from local directory\nRemoving weight norm...\n>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x\nUsing wetext for text normalization (fallback)\n>> TextNormalizer loaded\n>> bpe model loaded from: D:\\TTS-Audio-Suite\\ComfyUI\\models\\TTS\\IndexTTS\\IndexTTS-2\\bpe.model\n‚úÖ IndexTTS-2 model loaded via unified interface on cuda:0\n‚úÖ IndexTTS-2 engine loaded via unified interface on cuda:0\n‚ö° Next generations will be much faster (models cached in VRAM)\n‚ö†Ô∏è Performance warning: IndexTTS-2 tested on Python 3.13 performs smoothly\n‚ö†Ô∏è Our Python 3.12 tests showed HIGH VRAM spikes during generation\n‚úÖ Re-registered Index-TTS with ComfyUI model management\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\n`BeamSearchScorer` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\n`BeamHypotheses` is deprecated and will be removed in v4.62.0, as constrained beam search has been moved to the Hub: https://hf.co/transformers-community/constrained-beam-search.\ntorch.Size([1, 266752])\nUse the specified emotion vector\ntorch.Size([1, 143360])\n>> gpt_gen_time: 21.21 seconds\n>> gpt_forward_time: 0.05 seconds\n>> s2mel_time: 2.45 seconds\n>> bigvgan_time: 0.59 seconds\n>> Total inference time: 25.93 seconds\n>> Generated audio length: 18.80 seconds\n>> RTF: 1.3792\n‚úÖ Index_Tts generation complete. Default narrator: narrator\nPrompt executed in 42.29 seconds\nException in callback _ProactorBasePipeTransport._call_connection_lost(None)\nhandle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\nTraceback (most recent call last):\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n    self._sock.shutdown(socket.SHUT_RDWR)\n```","createdAt":"2025-12-20T07:44:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3677538726","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7ca1eE","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Tentative Fix in v4.16.1\n\nChanged the QwenEmotion model loader from `modelscope.AutoModelForCausalLM` to `transformers.AutoModelForCausalLM`. This may resolve the `'dict' object has no attribute 'model_type'` error.\n\n**Please test:**\n1. Update to v4.16.1 (`git pull`)\n2. Restart ComfyUI and try your Text Emotion workflow\n3. Report if it works or still fails\n\n**If it still fails**, please share your modelscope and transformers versions (check with your ComfyUI Python environment).","createdAt":"2025-12-30T01:47:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3698022276","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7cpNz3","author":{"login":"Amazon90"},"authorAssociation":"NONE","body":"> ## Tentative Fix in v4.16.1\n> Changed the QwenEmotion model loader from `modelscope.AutoModelForCausalLM` to `transformers.AutoModelForCausalLM`. This may resolve the `'dict' object has no attribute 'model_type'` error.\n> \n> **Please test:**\n> \n> 1. Update to v4.16.1 (`git pull`)\n> 2. Restart ComfyUI and try your Text Emotion workflow\n> 3. Report if it works or still fails\n> \n> **If it still fails**, please share your modelscope and transformers versions (check with your ComfyUI Python environment).\n\nCould the problem lie within my workflow? The error remains unchanged: ‚ÄúQwenEmotion model not available.‚Äù I have already updated both the ComfyUI version and your TTS-Audio-Suite to their latest releases.\n\n<img width=\"1898\" height=\"797\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3541dcf1-279d-49e6-a269-18eb39370e2f\" />\n\n```\ngot prompt\n‚ö†Ô∏è TTS Text: No voice reference provided - this may cause issues with some engines\nüé§ Generating Index_Tts for 'narrator' (lang: en)\nüîÑ Reusing cached index_tts engine instance (updated with new generation parameters)\nü§ñ IndexTTS-2: Processing text with emotion support\nüìù IndexTTS-2: Using native token chunking (120 tokens), disabling character chunking\nüé≠ IndexTTS-2: Processing 4 character segment(s) - female_01, male_01, narrator\nüìñ Using mapped narrator voice: D:\\TTS-Audio-Suite\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\voices_examples\\David_Attenborough CC3.wav | Ref: 'The first one who physical contact was with a fema...'\nüé≠ female_01: Loaded voice reference\nüé≠ male_01: Loaded voice reference\nüé≠ No emotion audio for character: narrator (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'Hello! This is unified TTS wit...' ‚Üí 'Happy character speaking: Hello! This is unified T...'\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\ntorch.Size([1, 128000])\n>> gpt_gen_time: 8.27 seconds\n>> gpt_forward_time: 0.02 seconds\n>> s2mel_time: 0.87 seconds\n>> bigvgan_time: 0.12 seconds\n>> Total inference time: 9.61 seconds\n>> Generated audio length: 5.80 seconds\n>> RTF: 1.6561\nüé≠ No emotion audio for character: female_01 (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'Hi there! I'm Alice speaking w...' ‚Üí 'Happy character speaking: Hi there! I'm Alice spea...'\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\ntorch.Size([1, 81408])\n>> gpt_gen_time: 4.32 seconds\n>> gpt_forward_time: 0.02 seconds\n>> s2mel_time: 0.85 seconds\n>> bigvgan_time: 0.10 seconds\n>> Total inference time: 5.51 seconds\n>> Generated audio length: 3.69 seconds\n>> RTF: 1.4924\nüé≠ No emotion audio for character: male_01 (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'And I'm Bob! This works with a...' ‚Üí 'Happy character speaking: And I'm Bob! This works ...'\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\ntorch.Size([1, 59648])\n>> gpt_gen_time: 2.88 seconds\n>> gpt_forward_time: 0.02 seconds\n>> s2mel_time: 0.67 seconds\n>> bigvgan_time: 0.09 seconds\n>> Total inference time: 3.84 seconds\n>> Generated audio length: 2.71 seconds\n>> RTF: 1.4205\nüé≠ No emotion audio for character: narrator (no tag emotion, no connected engine emotion)\nüåà Dynamic Text Emotion: 'Back to the main narrator voic...' ‚Üí 'Happy character speaking: Back to the main narrato...'\n‚úÖ Reloaded Index-TTS via existing ComfyUI wrapper\n>> starting inference...\n‚ö†Ô∏è QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True\nUse the specified emotion vector\ntorch.Size([1, 75264])\n>> gpt_gen_time: 3.54 seconds\n>> gpt_forward_time: 0.03 seconds\n>> s2mel_time: 0.78 seconds\n>> bigvgan_time: 0.09 seconds\n>> Total inference time: 4.63 seconds\n>> Generated audio length: 3.41 seconds\n>> RTF: 1.3556\n‚úÖ Index_Tts generation complete. Default narrator: narrator\nPrompt executed in 23.75 seconds\n```","createdAt":"2025-12-31T09:08:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3701791991","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7dNIh7","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Your workflow looks fine (apart for not choosing a narrator, I don't see any problem). I run your workflow from your image just fine... I'll try investigating further, but I'm at a loss here. It might obviously be related to not recognizing your model. But since you've deleted it and redownloaded it, I don't know what else could it be.\nI'll try adding some debug info in the next version to expose your model path so we can compare and see what is wrong.","createdAt":"2026-01-05T16:37:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3711207547","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7dNdNI","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Debug Logging Added in v4.16.8\n\nI've added debug output to help identify why the QwenEmotion model isn't being detected on your system.\n\n**Please test:**\n\n1. Update to v4.16.8:\n   ```bash\n   cd /path/to/TTS-Audio-Suite\n   git pull\n   ```\n\n2. Restart ComfyUI completely\n\n3. Run your IndexTTS-2 Text Emotion workflow again\n\n4. **Look for these new debug lines** in your console output during model loading:\n   ```\n   üîç DEBUG: Looking for QwenEmotion model at: <path>\n   üîç DEBUG: Path exists: True/False\n   üîç DEBUG: Is directory: True/False\n   ```\n\n5. **Report back with:**\n   - The complete debug output (those 3 lines)\n   - Whether the path shown matches where you actually have the qwen0.6bemo4-merge folder\n\nThis will help us identify if there's a path mismatch or configuration issue specific to your environment.","createdAt":"2026-01-05T16:59:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3711292232","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7jiKqy","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"any news on this? @Amazon90 ","createdAt":"2026-01-29T12:35:48Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/181#issuecomment-3817384626","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWvQ","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"LA_kwDOPZi2kc8AAAACJLIGsg","name":"needs-clarification","description":"","color":"fbca04"}],"number":181,"title":"QwenEmotion model not available - cannot use text emotion. Ignoring use_emo_text=True","updatedAt":"2026-01-29T12:35:49Z"},{"comments":[{"id":"IC_kwDOPZi2kc7U_CW5","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Index2 does not recognize tags for laughing as far as I know. Chatterbox Multilangual v2 introduced tags I've coded them lik e <>:\n\nhttps://github.com/diodiogod/TTS-Audio-Suite/blob/main/docs/CHATTERBOX_V2_SPECIAL_TOKENS.md\n\n Yet still, it's basically a dead code as the model doesn't do anything with it really. From all our 7 engines, none can do it reliably as you want. I would try Index2 not with vectors but with a happy laughing person as Emotion reference, emotional audio reference in my testings worked better than vectors. And maybe experiment with \"ahaha\" or something in the text itself. IDK really.\n\nThere are other new models that I have not implemented yet that suppose can do it with tags, if I remember correctly maybe Maya or Step Audio Editx..","createdAt":"2025-11-25T00:40:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/175#issuecomment-3573294521","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7U_Dwq","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"And no Index2 is trained in English and Chinese as far as I know.","createdAt":"2025-11-25T00:42:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/175#issuecomment-3573300266","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7U_alQ","author":{"login":"NewbieOnCMD"},"authorAssociation":"NONE","body":"I was checking this, https://github.com/2noise/ChatTTS Look the example, seems really good, it sounds natural and can do laugh!!\nIs it implemented on Audio Suite or I'm just blind and cant find it? haha","createdAt":"2025-11-25T01:25:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/175#issuecomment-3573393744","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7U_lUg","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"No it is not. There are many many new tts engine like every week. I have a poll on discord for you guys to vote on the next one to be implemented.","createdAt":"2025-11-25T01:49:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/175#issuecomment-3573437728","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7aLgpR","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi @NewbieOnCMD , since then I've implemented Step Audio EditX. It's an engine that does not generate paralinguistics on it's own TTS, but it has a Edit capability to add in a second pass paralinguistic to ANY audio. Meaning, you can achieve what you wanted. Check v4.13! (it does have language restrains).","createdAt":"2025-12-16T13:09:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/175#issuecomment-3660450385","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7aLhDo","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'll keep this issue open as a suggestion of a new engine ChatTTS","createdAt":"2025-12-16T13:09:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/175#issuecomment-3660452072","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":175,"title":"Which TTS model is capable of laughing and speaking naturally? [ChatTTS new engine suggestion]","updatedAt":"2025-12-16T13:10:18Z"},{"comments":[{"id":"IC_kwDOPZi2kc7QzzGt","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## XPU Support Implementation Complete - Tentative\n\nI've implemented comprehensive Intel XPU (Intel GPU) support across the entire project. **This is tentative support** - we don't have Intel GPU hardware to validate on, so feedback from users with Intel GPUs is essential.\n\n### What Was Changed:\n\n**Core Device Resolution** (`utils/device/torch_device_resolver.py`)\n- Updated `resolve_torch_device()` to detect and prioritize XPU in auto selection\n- Device priority chain: MPS > CUDA > XPU > CPU\n- Uses defensive `hasattr(torch, \"xpu\")` checks for safe detection on systems without XPU\n\n**All UI Nodes Updated** (16 files total)\n- Added \"xpu\" to device dropdowns across all TTS and processing nodes\n- Updated tooltips to document XPU availability\n- Files include: ChatterBox, ChatterBox Official 23-Lang, F5-TTS, Higgs Audio, IndexTTS-2, RVC, VibeVoice\n\n### Important Notes:\n\n1. **Requires separate installation**: Users need `intel-extension-for-pytorch` installed separately - not handled in install.py\n2. **Tested pattern**: Follows existing XPU patterns already in IndexTTS-2 and F5-TTS engines\n3. **Defensive fallback**: If XPU not available, gracefully falls back to next device in chain\n4. **No breaking changes**: Default behavior unchanged, completely backward compatible\n\n### Version Bumped:\n- v4.14.18 ‚Üí v4.14.19 (patch release)\n- Tagged as \"tentative\" in changelog pending user validation\n\n### Next Steps:\n- Users with Intel GPUs can test by selecting \"xpu\" device in node configs\n- Feedback on compatibility, performance, or issues is welcome\n- May need adjustments based on real-world testing\n\nLooking forward to validation from Intel GPU users!","createdAt":"2025-11-07T15:36:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/167#issuecomment-3503239597","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Tqgwm","author":{"login":"Nuitari"},"authorAssociation":"NONE","body":"I finally got a chance to use this again on XPU, I had to move the hardware and rebuild my ComfyUI install. \n\nOn pytorch 2.8.0+xpu with the intel-extension-for-pytorch\nI was hitting issues where a CPU core would end up pinned at 100% by python and things never finishing. After a long debug session with ChatGPT, I had to edit the code so that the calls to mel_spectrogram and torchaudio.compliance.kaldi.fbank in indextts2 in engines/index_tts/indextts/infer_v2.py are made on the CPU. \n\nOn pytorch 2.9.0+xpu, the mel_spectrogram works fine on XPU. However, the call to torchaudio.compliance.kaldi.fbank still fails. \nIt also hangs during the generation where its doing # 13. run beam sample in indextts/gpt/transformers_generation_utils.py. I've yet to find a fix there. \n\nAnother issue is that if I set the device to cpu, some of the tensors still end up on xpu:0\n  File \"engines/index_tts/indextts/infer_v2.py\", line 318, in get_emb\n    vq_emb = self.semantic_model(\n        input_features=input_features,\n        attention_mask=attention_mask,\n        output_hidden_states=True,\n    )\n\n\n","createdAt":"2025-11-19T07:11:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/167#issuecomment-3551136806","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7T7JdB","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## XPU Compatibility Improvements Implemented (v4.14.29)\n\nI've implemented comprehensive XPU compatibility fixes for IndexTTS-2 based on your detailed feedback. **Important: These changes are untested since I don't have Intel GPU hardware** - they're based entirely on the issues you reported.\n\n### What Was Fixed:\n\n**1. PyTorch 2.8.0+xpu CPU Pinning (100% core usage)**\n- `mel_spectrogram` and `torchaudio.compliance.kaldi.fbank` now automatically run on CPU when XPU is detected\n- Results are transferred back to XPU after processing\n- This should eliminate the CPU core pinning issue you experienced\n\n**2. PyTorch 2.9.0+xpu kaldi.fbank Failures**\n- Same CPU fallback applies to prevent kaldi.fbank crashes\n- `mel_spectrogram` should now work on XPU for PyTorch 2.9.0 (based on your report that it works)\n\n**3. Tensor Device Leakage (CPU ‚Üí XPU)**\n- Added defensive `.to(self.device)` calls in `get_emb()` method\n- Added environment variable setting (`ONEAPI_DEVICE_SELECTOR=opencl:cpu`) when CPU is explicitly requested\n- This should prevent tensors from incorrectly ending up on XPU when you select CPU device\n\n**4. Device-Agnostic Cache Management**\n- Replaced hardcoded `torch.cuda.empty_cache()` with device-aware clearing\n- Now properly calls `torch.xpu.empty_cache()` when using XPU device\n\n**5. Beam Sampling Hang Warning (PyTorch 2.9.0+xpu)**\n- Added informative warning on startup for PyTorch 2.9.0+xpu users\n- Suggests workarounds: downgrade to 2.8.0, use `num_beams=1`, or switch to CPU\n- I cannot fix the beam sampling hang without Intel hardware - it's likely deep in transformers library\n\n### Files Modified:\n\n- `engines/index_tts/indextts/infer_v2.py` - All XPU compatibility logic\n\n### Changes Available:\n\nVersion 4.14.29 has been pushed to the repository. You can update and test:\n\n```bash\ncd ComfyUI/custom_nodes/ComfyUI_TTS_Audio_Suite\ngit pull\n```\n\n### Testing Request:\n\nSince I cannot test on Intel GPUs, I need your feedback on:\n\n1. **PyTorch 2.8.0+xpu**: Does audio processing still pin CPU at 100%?\n2. **PyTorch 2.9.0+xpu**: Does kaldi.fbank work now? Does generation still hang at beam sampling?\n3. **Device selection**: When you set device to \"cpu\", do tensors stay on CPU (no XPU leakage)?\n4. **Audio quality**: Is quality maintained with CPU fallback for audio operations?\n\nPlease test and report back with any issues or confirmations. If the beam sampling hang persists on 2.9.0, the only workarounds are downgrading PyTorch or using `num_beams=1` in generation parameters.","createdAt":"2025-11-20T02:29:10Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/167#issuecomment-3555497793","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7URU1P","author":{"login":"Nuitari"},"authorAssociation":"NONE","body":"1. Nope, this one works fine now, thank you! \nUnfortunately, I learned that the intel extension for pytorch has been mainlined in torch 2.9 and intel is sunsetting that package. The SSL for the website expired a few days ago. \n\n2. fbank works, but the generation still hangs at the beam sampling. This also happens with num_beams=1\n3. No Partial backtrace shows: \n```\n  File \"/home/nuitari/ai/ComfyUI/custom_nodes/TTS-Audio-Suite/engines/index_tts/indextts/infer_v2.py\", line 593, in infer_generator\n    spk_cond_emb = self.get_emb(input_features, attention_mask)\n```\n\n4. Can't answer that one yet. \n\nThe quality of num_beams=1 is quite worst though. \n\nI've tried python 3.12, no change. Python 3.14 fails when installing numba. \n\nI'll play more with it, if I find anything relevant I'll post more. ","createdAt":"2025-11-21T04:07:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/167#issuecomment-3561311567","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7UiIF-","author":{"login":"Nuitari"},"authorAssociation":"NONE","body":"Welp, I finally found the actual problem. I had rusticl.icd installed alongside the intel.icd to support the GPU I actually use for graphics. It also includes CPU support. \n\nFor some reason I cannot even begin to fathom,  some, but not all, XPU workloads ended up on that library, on the CPU (cause why not). \n\nI've reverted to commit 5c5a139 and things just work (overall). \n\nI think the compatibility patches for mel_spectrogram, kaldi.fbank, the hang warning for 2.9.0+xpu could be reverted. It doesn't stop it from working though. \n\nSome quick benchmark showed some potential speed gain on 2.8.0+xpu to keep them on the cpu, but no significant difference on 2.10.0+xpu\n\nSelecting cpu for the generation device still has leakage though on main. \n\nReally sorry for the waste of time. ","createdAt":"2025-11-22T05:38:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/167#issuecomment-3565715838","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7UlvTw","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"No problem @Nuitari I'll have a look into all your recent finds and check what we can do in our end here when I get the time!","createdAt":"2025-11-22T12:11:53Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/167#issuecomment-3566662896","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":167,"title":"Patch to Add XPU Support","updatedAt":"2025-11-22T12:11:53Z"},{"comments":[],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACKotBIg","name":"not an error","description":"","color":"aaaaaa"}],"number":166,"title":"Refactor cache key generation to use configuration registry pattern","updatedAt":"2025-11-20T02:30:57Z"},{"comments":[{"id":"IC_kwDOPZi2kc7QcyLj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I have tried once making VibeVoice use GGUF but it was out of my league. (I'm not even sure the model would work anyway). But if you have an already working project that loads GGUF for one of our engines that we can analyze and borrow the code, then yes, it should be possible. \n\nIn your link case, it's another TTS engine, and it could go on the list, but I can't promise when I'll have time to add another.","createdAt":"2025-11-06T13:12:25Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/164#issuecomment-3497206499","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7TGe7K","author":{"login":"Bliip-Studio"},"authorAssociation":"NONE","body":"I think Maya1 is now availble in safetensors on their hugging face, can u check if we can integrate this model ?\n\nhttps://huggingface.co/maya-research/maya1/tree/main","createdAt":"2025-11-17T12:53:16Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/164#issuecomment-3541692106","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":164,"title":"gguf tts models [maya1-GGUF]","updatedAt":"2025-11-17T12:53:17Z"},{"comments":[{"id":"IC_kwDOPZi2kc7P6dGx","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Implemented in v4.14.5.\n\n**What was added:**\n- Created torch_device_resolver.py - centralized device detection utility\n- All 7 TTS engine nodes now expose 'mps' as a device option\n- Intelligent auto-detection: MPS (Apple Silicon) > CUDA (NVIDIA) > CPU fallback\n\n**How it works:**\nWhen you select \"auto\" on a Mac with Apple Silicon:\n1. Checks for MPS availability - uses it if available\n2. Falls back to CUDA on other systems\n3. Falls back to CPU if no GPU available\n\n**Backward compatible:**\n- Existing workflows unchanged\n- MPS added as final option to prevent dropdown reordering\n- Linux/Windows users unaffected\n- \"auto\" mode now smarter on all platforms\n\n**Testing:** I cannot test this on actual Apple Silicon hardware. The implementation uses PyTorch's standard torch.backends.mps.is_available() detection, which should work correctly. Testing on a Mac with Apple Silicon would be necessary to confirm functionality.\n\nTest steps on Mac:\n1. Update to v4.14.5\n2. Create a TTS engine node (any engine)\n3. Set device to \"auto\" or select \"mps\" directly\n4. Check console output to verify which device was selected\n5. Generate TTS to confirm it works\n\nPlease report results if you test this.","createdAt":"2025-11-04T22:19:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3488207281","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7P6r9_","author":{"login":"LG1234"},"authorAssociation":"NONE","body":"Thank you. Running the 4.14.5 and selecting auto in the Chatterbox engine still runs on CPU (M4 Max, 128GB GPU)\n\nFrom the log:\nüé§ Generating Chatterbox_Official_23Lang for 'narrator' (lang: ge)\nüåç Loading ChatterBox Official 23-Lang model for German on auto\nüåç Loading ChatterBox Official 23-Lang model for German on cpu","createdAt":"2025-11-04T22:44:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3488268159","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7P8U3Q","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"if you choose MPS what happens? This is going to be really hard for me to implement because I can't test it on my own... so I don't really know if I can make it. I would love someone with a Mac to do a PR....","createdAt":"2025-11-05T01:26:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3488697808","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7QABD6","author":{"login":"LG1234"},"authorAssociation":"NONE","body":"MPS is not a selectable option in the engines currently. The only options are auto and cuda, and auto defaults to CPU. I implemented an MPS option myself, which vastly accelerates performance (>2-3 fold on M4 Max), but degrades for longer prompts due to VRAM/RAM overload, so this needs adjustment to, but probably exceeds my scope if it should be stable.","createdAt":"2025-11-05T07:03:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3489665274","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7QB_aQ","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Fixed in v4.14.8 - Comprehensive MPS Support\n\n**What was the issue:**\nThe 'torch_device_resolver' utility was implemented in v4.14.5 to detect MPS, but it wasn't being used consistently across all TTS engines. Many engines had hardcoded device selection that always chose CUDA or CPU, completely ignoring MPS availability.\n\n**What was fixed:**\nAdded proper device resolution across ALL TTS engines:\n- **ChatterBox**: Added resolve_torch_device() in from_local() \n- **F5-TTS**: Added resolve_torch_device() in __init__()\n- **RVC**: Fixed 5 locations where device was hardcoded to cuda/cpu\n- **IndexTTS**: Fixed target_device resolution\n- **VibeVoice**: Fixed device resolution in __init__() and target_device checks\n- **VibeVoice & Higgs Audio adapters**: Fixed device resolution in 3 locations\n\n**How it works now:**\nWhen you select \"auto\" device on ANY engine, it properly detects:\n1. MPS available ‚Üí uses it (Apple Silicon)\n2. CUDA available ‚Üí uses it (NVIDIA)\n3. Neither ‚Üí falls back to CPU\n\n**Testing on Mac with M-series chip:**\n1. Update to v4.14.8\n2. Create a TTS engine node (ChatterBox, F5-TTS, etc.)\n3. Set device to \"auto\"\n4. Check console output - should see \"mps\" in logs instead of \"cpu\"\n5. Generate TTS - should use GPU acceleration\n\nPlease report results!","createdAt":"2025-11-05T09:41:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3490182800","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7QJ4Az","author":{"login":"LG1234"},"authorAssociation":"NONE","body":"MPS is now available and the performance is increased. After all chunks are processed (tested for chatterbox), I now get:\n\n‚ùå TTS Text generation failed: Node processing failed: ValueError: too many values to unpack (expected 3)\nTraceback:\nTraceback (most recent call last):\n  File \"/Users/XX/PycharmProjects/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/base/base_node.py\", line 328, in process_with_error_handling\n    return process_func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/XX/PycharmProjects/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/chatterbox_official_23lang/chatterbox_official_23lang_processor.py\", line 1210, in _process\n    processed_text_segments = [segment_text for _, segment_text, _ in character_segments_with_lang]\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/XX/PycharmProjects/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/chatterbox_official_23lang/chatterbox_official_23lang_processor.py\", line 1210, in <listcomp>\n    processed_text_segments = [segment_text for _, segment_text, _ in character_segments_with_lang]\n                                                ^^^^^^^^^^^^^^^^^^\nValueError: too many values to unpack (expected 3)\n\nPrompt executed in 03:13:58\n\nI need to test the other engines further.","createdAt":"2025-11-05T16:42:33Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3492249651","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Qk9OP","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> MPS is now available and the performance is increased. After all chunks are processed (tested for chatterbox), I now get:\n> \n> ‚ùå TTS Text generation failed: Node processing failed: ValueError: too many values to unpack (expected 3) Traceback: Traceback (most recent call last): File \"/Users/XX/PycharmProjects/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/base/base_node.py\", line 328, in process_with_error_handling return process_func(*args, **kwargs) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/Users/XX/PycharmProjects/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/chatterbox_official_23lang/chatterbox_official_23lang_processor.py\", line 1210, in _process processed_text_segments = [segment_text for _, segment_text, _ in character_segments_with_lang] ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"/Users/XX/PycharmProjects/ComfyUI/custom_nodes/TTS-Audio-Suite/nodes/chatterbox_official_23lang/chatterbox_official_23lang_processor.py\", line 1210, in processed_text_segments = [segment_text for _, segment_text, _ in character_segments_with_lang] ^^^^^^^^^^^^^^^^^^ ValueError: too many values to unpack (expected 3)\n> \n> Prompt executed in 03:13:58\n> \n> I need to test the other engines further.\n\ngood lord did it take 3h to run this??? ","createdAt":"2025-11-06T20:52:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3499348879","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Ql1IH","author":{"login":"LG1234"},"authorAssociation":"NONE","body":"Yes, that was a 40 page document still loaded in the workflow. Performance degrades heavily with longer runtimes (down to 5-10% of the initial performance).","createdAt":"2025-11-06T22:10:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3499577863","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7QmQNc","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Please test with a simpler text just so we can get this working. can you test the other engines? I'll investigate it further as soon as I get the time.","createdAt":"2025-11-06T22:41:25Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3499688796","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7SxsTP","author":{"login":"LG1234"},"authorAssociation":"NONE","body":"Ok - I had implemented some superficial fixes myself to get them working, but I doubt they are production quality. Ill set up a new .venv soon to test all engines with MPS. Sorry for the delay.","createdAt":"2025-11-15T09:18:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/160#issuecomment-3536241871","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":160,"title":"MPS Support?","updatedAt":"2025-12-22T19:27:36Z"},{"comments":[{"id":"IC_kwDOPZi2kc7PwIpu","author":{"login":"ShimamuX"},"authorAssociation":"NONE","body":"and cause : \n‚ôªÔ∏è Using cached Hubert model\nüîÑ Reloading cached Hubert model from cpu to cuda\n‚úÖ Re-registered Hubert model with ComfyUI model management\nüîß RVC: rmvpe method requires RMVPE model, checking availability...\n‚úÖ RMVPE model already exists: E:\\Ai\\ComfyUI\\ComfyUI\\models\\TTS\\RVC\\rmvpe.pt\n‚úÖ RMVPE model ready at: E:\\Ai\\ComfyUI\\ComfyUI\\models\\TTS\\RVC\\rmvpe.pt\nvc_single unused args: {}\nüîß vc_single: Starting conversion - version: v2, f0_method: rmvpe\nüîß RVC Audio: Resampled 44100Hz -> 16000Hz using torchaudio\nüîß vc_single: About to call vc.pipeline - if_f0: 1\nUsing preloaded file index.\nget_f0 rmvpe unused params: {}\nvc torch.Size([1, 6720, 768]) torch.Size([1, 6720]) torch.Size([1, 6720])\n‚ùå vc_single: Pipeline error: Allocation on device\nüîß Pipeline error type: OutOfMemoryError\nTraceback (most recent call last):\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\vc_infer_pipeline.py\", line 333, in vc_single\n        audio_opt = vc.pipeline(\n                    ~~~~~~~~~~~^\n        hubert_model,\n        ^^^^^^^^^^^^^\n    ...<17 lines>...\n        f0_file=f0_file,\n        ^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\vc_infer_pipeline.py\", line 179, in pipeline\n    audio_opt.append(self.vc(model, net_g, sid, audio_slice, pitch_slice, pitchf_slice, times, index, big_npy, index_rate, version, protect)[self.t_pad_tgt : -self.t_pad_tgt])\n                     ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\vc_infer_pipeline.py\", line 106, in vc\n    (net_g.infer(feats, p_len, pitch, pitchf, sid)[0][0, 0])\n     ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\lib\\infer_pack\\models.py\", line 800, in infer\n    m_p, logs_p, x_mask = self.enc_p(phone, pitch, phone_lengths)\n                          ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\lib\\infer_pack\\models.py\", line 101, in forward\n    x = self.encoder(x * x_mask, x_mask)\n  File \"E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\lib\\infer_pack\\attentions.py\", line 61, in forward\n    y = self.attn_layers[i](x, x, attn_mask)\n  File \"E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\lib\\infer_pack\\attentions.py\", line 217, in forward\n    x, self.attn = self.attention(q, k, v, mask=attn_mask)\n                   ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\lib\\infer_pack\\attentions.py\", line 261, in attention\n    relative_weights = self._absolute_position_to_relative_position(p_attn)\n  File \"E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\tts_audio_suite\\engines\\rvc\\impl\\lib\\infer_pack\\attentions.py\", line 342, in _absolute_position_to_relative_position\n    x_flat = F.pad(x_flat, convert_pad_shape([[0, 0], [0, 0], [length, 0]]))\n  File \"E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\torch\\nn\\functional.py\", line 5290, in pad\n    return torch._C._nn.pad(input, pad, mode, value)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: Allocation on device\n‚ùå RVC conversion returned None\n‚ùå RVC conversion failed: RVC conversion failed - no output from minimal wrapper\n\nInt logs :\n```\nTotal VRAM 6140 MB, total RAM 24296 MB\npytorch version: 2.8.0+cu129\nEnabled fp16 accumulation.\nSet vram state to: LOW_VRAM\nDevice: cuda:0 NVIDIA GeForce RTX 4050 Laptop GPU : cudaMallocAsync\nUsing sage attention\nPython version: 3.13.6 (tags/v3.13.6:4e66535, Aug  6 2025, 14:36:00) [MSC v.1944 64 bit (AMD64)]\nComfyUI version: 0.3.67\nComfyUI frontend version: 1.28.8\n[Prompt Server] web root: E:\\Ai\\ComfyUI\\python_embeded\\Lib\\site-packages\\comfyui_frontend_package\\static\n[AudioSeparation] Registering 6 node(s) for version 1.1.2.\nComfyUI Audio Quality Enhancer: Successfully loaded nodes\nAvailable nodes: ['AudioQualityEnhancer', 'AudioQualityEffects']\n[Crystools INFO] Crystools version: 1.27.4\n[Crystools INFO] Platform release: 11\n[Crystools INFO] JETSON: Not detected.\n[Crystools INFO] CPU: 13th Gen Intel(R) Core(TM) i9-13900HX - Arch: AMD64 - OS: Windows 11\n[Crystools INFO] pynvml (NVIDIA) initialized.\n[Crystools INFO] GPU/s:\n[Crystools INFO] 0) NVIDIA GeForce RTX 4050 Laptop GPU\n[Crystools INFO] NVIDIA Driver: 576.88\n[ComfyUI-Easy-Use] server: v1.3.4 Loaded\n[ComfyUI-Easy-Use] web root: E:\\Ai\\ComfyUI\\ComfyUI\\custom_nodes\\comfyui-easy-use\\web_version/v2 Loaded\nComfyUI-GGUF: Allowing full torch compile\n\n\n‚ÑπÔ∏è Critical package versions: NumPy 2.3.4, Librosa 0.11.0, Numba 0.62.1, PyTorch 2.8.0+cu129, TorchAudio 2.8.0+cu129, Transformers 4.57.1, Accelerate 1.11.0, SoundFile 0.13.1\nTensorFlow version 2.20.0 available.\nAPEX FusedRMSNorm not available, using native implementation\nSageAttention: Using SM89 (Ada) FP8 kernel with pv_accum_dtype='fp32+fp32'.\nFETCH ComfyRegistry Data: 20/104\n======================================================================\nüöÄ TTS Audio Suite v4.14.3\nUniversal multi-engine TTS extension for ComfyUI\nüêç Python 3.13.6 detected\n‚úÖ TTS Audio Suite v4.14.3 loaded with 27 nodes:\n   ‚Ä¢ ‚öôÔ∏è ChatterBox Official 23-Lang Engine\n   ‚Ä¢ ‚öôÔ∏è ChatterBox TTS Engine\n   ‚Ä¢ ‚öôÔ∏è F5 TTS Engine\n   ‚Ä¢ ‚öôÔ∏è Higgs Audio 2 Engine\n   ‚Ä¢ ‚öôÔ∏è IndexTTS-2 Engine\n   ‚Ä¢ ‚öôÔ∏è RVC Engine\n   ‚Ä¢ ‚öôÔ∏è VibeVoice Engine\n   ‚Ä¢ üåà IndexTTS-2 Emotion Vectors\n   ‚Ä¢ üåà IndexTTS-2 Text Emotion\n   ‚Ä¢ üåä Audio Wave Analyzer\n   ‚Ä¢ üéôÔ∏è Voice Capture\n   ‚Ä¢ üé§ TTS Text\n   ‚Ä¢ üé≠ Character Voices\n   ‚Ä¢ üé≠ Load RVC Character Model\n   ‚Ä¢ üè∑Ô∏è Multiline TTS Tag Editor\n   ‚Ä¢ üëÑ F5-TTS Speech Editor\n   ‚Ä¢ üìù Phoneme Text Normalizer\n   ‚Ä¢ üì∫ TTS SRT\n   ‚Ä¢ üîÑ Voice Changer\n   ‚Ä¢ üîß Audio Analyzer Options\n   ‚Ä¢ üîß F5-TTS Edit Options\n   ‚Ä¢ üîß RVC Pitch Extraction Options\n   ‚Ä¢ üîß Viseme Mouth Shape Options\n   ‚Ä¢ üó£Ô∏è Silent Speech Analyzer\n   ‚Ä¢ ü§ê Noise or Vocal Removal\n   ‚Ä¢ ü§ê Voice Fixer\n   ‚Ä¢ ü•™ Merge Audio\n======================================================================\n```","createdAt":"2025-11-04T11:29:01Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3485502062","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7PyF18","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Thanks for the detailed report, I'll look into it","createdAt":"2025-11-04T13:29:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3486014844","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7QSsfi","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Issue Resolved ‚úÖ\n\n**Version 4.14.12** - VRAM buildup fix deployed\n\n### Root Cause\nPitch extraction models (RMVPE, FCPE) were cached as instance variables in the `VC/FeatureExtractor` class and never explicitly freed between conversions. Each conversion would accumulate intermediate tensors in VRAM, causing progressive memory buildup.\n\n### Solution Implemented\nModified `engines/rvc/minimal_reference_wrapper.py` to explicitly clear pitch extraction model cache after each conversion completes:\n- Delete cached RMVPE and FCPE models from the VC instance\n- Force garbage collection\n- Clear CUDA cache\n\nThis preserves the performance benefit of caching RVC and Hubert models while preventing pitch extraction models from accumulating in VRAM.\n\n### Testing\n- Tested with multiple consecutive RVC conversions using different pitch extraction methods (RMVPE, FCPE, Crepe, PM)\n- No VRAM accumulation observed after many generations\n- Pitch models (RMVPE, FCPE) are now being cleared after each conversion\n- Model caching performance maintained\n\nNote: The system tested has abundant VRAM (24GB), so visible accumulation is harder to detect, but the fix ensures pitch models are properly freed after each conversion.\n\nThe fix is now available in v4.14.12.","createdAt":"2025-11-06T02:21:16Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3494561762","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7QSslr","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Please test and report back!","createdAt":"2025-11-06T02:21:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3494562155","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7QY4cu","author":{"login":"ShimamuX"},"authorAssociation":"NONE","body":"<img width=\"1251\" height=\"523\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/09fa3406-af7a-4b0b-8a7f-a149bbb3fecf\" />\n\nThanks for you hard works. \nIt does improved, but didn't fix the accumulate.\n\nHere the video :\nhttps://drive.google.com/file/d/1D1opvGIulupS-6D3Ct8J1E7YbNIkY0xE/view?usp=sharing\n\nNote :\nthe soundflow error has nothing to do with RVC, I just forgot to complete the nodes\n\n<img width=\"463\" height=\"263\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/38574756-773e-4f1d-b627-91d4b7a42ddc\" />","createdAt":"2025-11-06T09:40:00Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3496183598","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7QknGj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Fix Deployed ‚úÖ \n\n**Version 4.14.13** - VRAM accumulation improvements deployed\n\n### Two-Part Solution\n\n#### Part 1 (v4.14.12): Pitch Extractor Cleanup\n- Clear RMVPE and FCPE pitch extraction models after each conversion\n- Prevents intermediate tensors from accumulating in VRAM during conversion\n\n#### Part 2 (v4.14.13): Model Switching Management\n- Track last registered RVC and Hubert model paths\n- Only unload old models when switching to a different model (different path)\n- Prevents premature unloading before models are used\n- Fixes dtype mismatch errors that were causing audio quality issues\n\n### What Was Happening\n1. User switches from RVC Model A to Model B\n2. Model B loaded and registered with ComfyUI management\n3. Model A was immediately unloaded but still in use\n4. Model B moved to CPU before inference\n5. Audio on CUDA, model weights on CPU ‚Üí dtype mismatch error\n6. Fallback to original audio (pitch issues)\n7. Old models accumulated in VRAM with each switch\n\n### How It's Fixed Now\n- When loading a new RVC model, the system checks if it's different from the last one\n- Old models only unload if actually switching models (different file path)\n- New models stay on GPU until inference completes\n- No dtype mismatches, stable VRAM usage\n\n### Testing Recommendations\n- Switch between multiple RVC character models repeatedly\n- Check VRAM usage stays stable (no progressive buildup)\n- Verify audio quality is normal\n- Monitor for any audio processing errors\n\nBoth fixes are now deployed in v4.14.13. Please test and report if the issue is resolved!","createdAt":"2025-11-06T20:24:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3499258275","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7QnczJ","author":{"login":"ShimamuX"},"authorAssociation":"NONE","body":"Still accumulated,\n\nBut hey, Good News! I fixed it! Cheers!:\n\nhttps://drive.google.com/file/d/1Uujt5px6OA9U2pVAtAYs5pTWtEGmBvMG/view?usp=sharing\n\nSummary of RVC VRAM accumulation fixes\n1. RVC Engine cleanup (engines/rvc/rvc_engine.py)\n\n- Detaches and moves audio tensors to CPU after conversion\n- Clears CUDA cache after conversion\n- Unloads RVC and Hubert models after conversion via model manager\n\n2. RVC Adapter cleanup (engines/adapters/rvc_adapter.py)\n\n- Detaches and moves audio tensors to CPU\n- Clears CUDA cache after conversion\n- Unloads RVC models via model manager\n- Clears minimal wrapper cache after conversion\n\n3. Minimal RVC Wrapper cleanup (engines/rvc/minimal_reference_wrapper.py)\n\n- Clears pitch extraction models (RMVPE, FCPE, Crepe) after conversion\n- Unloads RVC models from cache after each conversion\n- Deletes model components (net_g, cpt, vc) to free memory\n- Forces CUDA synchronization and cache clearing\n\nChanges:\n\n- Model unloading: RVC models are unloaded after each conversion\n- Component cleanup: model components (net_g, cpt, vc) are deleted\n- Pitch model cleanup: pitch extraction models are cleared\n- Cache clearing: minimal wrapper cache is cleared after conversion\n- CUDA cleanup: multiple passes of cache clearing with synchronization\n\nResult:\n\n- RVC models are unloaded after each conversion\n- Pitch extraction models are cleared\n- VRAM is freed immediately after conversion\n- No accumulation even when switching between different RVC character models\n- Works for all RVC conversion paths (minimal wrapper, engine, adapter)\n- VRAM should now be properly released after each RVC conversion, preventing accumulation even when switching between different RVC character models.\n\nBefore Run :\n\n<img width=\"353\" height=\"257\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/da330ee8-a4d8-4cb7-b60e-e75e97cb596d\" />\n\n1st Run :\n\n<img width=\"348\" height=\"261\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c87f15ae-237c-4a3a-bcc7-9536718bb7a5\" />\n\n2nd Run:\n\n<img width=\"340\" height=\"240\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/392b88dd-fc42-4a2b-a069-690fb8bd4d11\" />\n\nnow we can rest üíØ ","createdAt":"2025-11-07T00:52:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3500002505","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Qn--N","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Great work debugging this VRAM accumulation issue! Your approach was solid in identifying that pitch extraction models were the main culprit and needed cleanup.\n\n## Solution Approach\n\nFor the final implementation, we followed **ComfyUI's architecture philosophy** rather than aggressive unloading:\n\n**What we do:**\n- ‚úÖ Register RVC and Hubert models with ComfyUI's model management system\n- ‚úÖ Clear pitch extraction models after each conversion (RMVPE, FCPE, Crepe) - these are the main accumulators\n- ‚úÖ Keep RVC/Hubert models cached for performance (same model reuses avoid reload overhead)\n- ‚úÖ Let ComfyUI's `free_memory()` intelligently unload models when VRAM is actually needed\n\n**What we don't do:**\n- ‚ùå Unload models on every conversion (defeats caching benefit)\n- ‚ùå Force reload when the same model is used again\n\n## How Unloading Works\n\nWhen ComfyUI detects VRAM pressure, it automatically calls `free_memory()` which:\n1. Unloads models registered in ComfyUI's `current_loaded_models` list\n2. Respects model priority and usage patterns\n3. Only unloads when necessary (smart, not aggressive)\n\n## Manual Cleanup\n\nThe **\"Clear VRAM\"** button in ComfyUI Manager will also:\n- Unload all RVC voice conversion models\n- Unload Hubert feature extraction models  \n- Clear pitch extractors (RMVPE, FCPE, Crepe)\n\n## Testing\n\nIf you still experience VRAM accumulation after this release:\n1. Let us know the VRAM usage pattern you're seeing\n2. We can enable additional monitoring if needed\n3. The approach should match other TTS engines (ChatterBox, F5-TTS, VibeVoice) which use the same pattern\n\nFixed in v4.14.16","createdAt":"2025-11-07T01:57:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3500142477","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Qn_ie","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Just to explain this a little more, you should see VRAM accumulation, it should be normal. But it SHOULD unload when needed. That is the correct behavior. Please test and report back! and thanks again for the dedication in trying to fix it yourself!","createdAt":"2025-11-07T01:58:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3500144798","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7UDN8k","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@ShimamuX can you please test again in your system and check if the current implementation fit your needs? Thanks","createdAt":"2025-11-20T11:55:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/158#issuecomment-3557613348","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJ-Qoug","name":"confirmed","description":"","color":"b60205"}],"number":158,"title":"[RVC] VRAM accumulated after generating.","updatedAt":"2025-11-20T11:55:24Z"},{"comments":[],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":156,"title":"Consider implementing SoulX-Podcast","updatedAt":"2025-10-31T22:32:36Z"},{"comments":[{"id":"IC_kwDOPZi2kc7JKQzu","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"yes it can, you just drop them here \\TTS\\RVC and the index on the index folder. It should show up.\nAs of right now, I have not added the option to add both model+index into a separate folder, but I should. I'll mark this as a future enhancement.","createdAt":"2025-10-07T02:10:20Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/129#issuecomment-3374910702","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":129,"title":"Can <Load RVC Character Model> node  load other .pth models besides Claire,Fuji,etc. Ôºü","updatedAt":"2025-10-07T02:10:36Z"},{"comments":[{"id":"IC_kwDOPZi2kc7HdSs1","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Yes, it takes some time to load at initialization. But in my end, it's normally just a few more seconds... It's not necessary a bug. It checks for a lot of things at initialization. I have thought of ways to optimize it, but I prefer to check things at initialization then to have 100bug reports right now.\nBut how much time are you talking here?","createdAt":"2025-09-29T11:07:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/122#issuecomment-3346344757","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7H4inX","author":{"login":"Elgokoo"},"authorAssociation":"NONE","body":"It takes 7 minutes, while, instant without the plugin? \n\nFYI I have sage attention plugin and nunckaku installed with the https://github.com/Tavris1/ComfyUI-Easy-Install/\n","createdAt":"2025-09-30T19:18:33Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/122#issuecomment-3353487831","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7H6xkP","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"This is not normal or intended. I also have a installation with more than 20 custom nodes including nunchaku and it takes 1 min max. Can you post your full initialization log?","createdAt":"2025-09-30T23:10:26Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/122#issuecomment-3354073359","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Jpvm7","author":{"login":"Elgokoo"},"authorAssociation":"NONE","body":"The CMD isn't helpful , is there a way to have more log because it happened \n\nThis is what I have below :\n\n[START] Security scan\n[DONE] Security scan\n## ComfyUI-Manager: installing dependencies done.\n** ComfyUI startup time: 2025-10-08 22:38:15.788\n** Platform: Windows\n** Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n** Python executable: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\python_embeded\\python.exe\n** ComfyUI Path: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\n** ComfyUI Base Folder Path: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\n** User directory: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\user\n** ComfyUI-Manager config path: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\user\\default\\ComfyUI-Manager\\config.ini\n** Log path: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\user\\comfyui.log\n\nPrestartup times for custom nodes:\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\rgthree-comfy\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\n   5.6 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-manager\n\nCheckpoint files will always be loaded safely.\nTotal VRAM 16311 MB, total RAM 65388 MB\npytorch version: 2.8.0+cu128\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 NVIDIA GeForce RTX 5060 Ti : cudaMallocAsync\nUsing sage attention\nPython version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\nComfyUI version: 0.3.64\nInitializing frontend: Comfy-Org/ComfyUI_frontend@latest, requesting version details from GitHub...\nDownloading frontend(Comfy-Org_ComfyUI_frontend) version(1.29.0) to (D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\web_custom_versions\\Comfy-Org_ComfyUI_frontend\\1.29.0)\n[Prompt Server] web root: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\web_custom_versions\\Comfy-Org_ComfyUI_frontend\\1.29.0\n[Crystools INFO] Crystools version: 1.27.3\n[Crystools INFO] Platform release: 11\n[Crystools INFO] JETSON: Not detected.\n[Crystools INFO] CPU: AMD Ryzen 7 5800H with Radeon Graphics - Arch: AMD64 - OS: Windows 11\n[Crystools INFO] pynvml (NVIDIA) initialized.\n[Crystools INFO] GPU/s:\n[Crystools INFO] 0) NVIDIA GeForce RTX 3070 Laptop GPU\n[Crystools INFO] 1) NVIDIA GeForce RTX 5060 Ti\n[Crystools INFO] NVIDIA Driver: 581.29\n[ComfyUI-Easy-Use] server: v1.3.4 Loaded\n[ComfyUI-Easy-Use] web root: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\\web_version/v2 Loaded\nComfyUI-GGUF: Allowing full torch compile\nComfyUI sampler names loaded successfully: 42 samplers\nFirst few samplers: ['euler', 'euler_cfg_pp', 'euler_ancestral', 'euler_ancestral_cfg_pp', 'heun']\nSAMPLER_NAMES type: <class 'list'>\nComfyUI scheduler names loaded successfully: 9 schedulers\nSchedulers: ['simple', 'sgm_uniform', 'karras', 'exponential', 'ddim_uniform', 'beta', 'normal', 'linear_quadratic', 'kl_optimal']\nAdded path mapping: D:/Automatic1111/models/Lora -> D:/Automatic1111/models/lora\nAdded path mapping: D:/Automatic1111/models/loras -> D:/ComfyUI-Easy-Install/ComfyUI-Easy-Install/ComfyUI/models/loras\nFound LoRA roots:\n - D:/Automatic1111/models/lora\n - D:/ComfyUI-Easy-Install/ComfyUI-Easy-Install/ComfyUI/models/loras\nAdded path mapping: D:/Automatic1111/models/Stable-diffusion -> D:/Automatic1111/models/unet\nFound checkpoint roots:\n - D:/Automatic1111/models/unet\nFound embedding roots:\n - D:/Automatic1111/models/embeddings\nUpdated 'comfyui' library with current folder paths\nDetected async ComfyUI execution, installing async metadata hooks\nMetadata collection hooks installed for runtime values\nComfyUI Metadata Collector initialized\nExample images path:\nAdded static route for locales: /locales -> D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-lora-manager\\locales\nRegistered model type 'lora' with service LoraService and routes LoraRoutes\nRegistered model type 'checkpoint' with service CheckpointService and routes CheckpointRoutes\nRegistered model type 'embedding' with service EmbeddingService and routes EmbeddingRoutes\nRegistered default model types: lora, checkpoint, embedding\nSetting up routes for 3 registered model types\nSuccessfully set up routes for lora\nSuccessfully set up routes for checkpoint\nSuccessfully set up routes for embedding\nLoRA Manager: Set up routes for 3 model types: lora, checkpoint, embedding\n### Loading: ComfyUI-Manager (V3.37)\n[ComfyUI-Manager] network_mode: public\n### ComfyUI Version: v0.3.64-1-g3e0eb8d3 | Released on '2025-10-08'\n[MultiGPU Core Patching] Patching mm.soft_empty_cache for Comprehensive Memory Management (VRAM + CPU + Store Pruning)\n[MultiGPU Core Patching] Patching mm.get_torch_device and mm.text_encoder_device\n[MultiGPU DEBUG] Initial current_device: cuda:0\n[MultiGPU DEBUG] Initial current_text_encoder_device: cuda:0\n[MultiGPU] Initiating custom_node Registration. . .\n-----------------------------------------------\ncustom_node                   Found     Nodes\n-----------------------------------------------\nComfyUI-LTXVideo                  Y         1\nComfyUI-Florence2                 Y         2\nComfyUI_bitsandbytes_NF4          N         0\nx-flux-comfyui                    N         0\nComfyUI-MMAudio                   N         0\nComfyUI-GGUF                      Y        18\nPuLID_ComfyUI                     N         0\nComfyUI-HunyuanVideoWrapper       N         0\nComfyUI-WanVideoWrapper           Y         8\n-----------------------------------------------\n[MultiGPU] Registration complete. Final mappings: DeviceSelectorMultiGPU, HunyuanVideoEmbeddingsAdapter, CheckpointLoaderAdvancedMultiGPU, CheckpointLoaderAdvancedDisTorch2MultiGPU, UNetLoaderLP, UNETLoaderMultiGPU, VAELoaderMultiGPU, CLIPLoaderMultiGPU, DualCLIPLoaderMultiGPU, TripleCLIPLoaderMultiGPU, QuadrupleCLIPLoaderMultiGPU, CLIPVisionLoaderMultiGPU, CheckpointLoaderSimpleMultiGPU, ControlNetLoaderMultiGPU, DiffusersLoaderMultiGPU, DiffControlNetLoaderMultiGPU, UNETLoaderDisTorch2MultiGPU, VAELoaderDisTorch2MultiGPU, CLIPLoaderDisTorch2MultiGPU, DualCLIPLoaderDisTorch2MultiGPU, TripleCLIPLoaderDisTorch2MultiGPU, QuadrupleCLIPLoaderDisTorch2MultiGPU, CLIPVisionLoaderDisTorch2MultiGPU, CheckpointLoaderSimpleDisTorch2MultiGPU, ControlNetLoaderDisTorch2MultiGPU, DiffusersLoaderDisTorch2MultiGPU, DiffControlNetLoaderDisTorch2MultiGPU, LTXVLoaderMultiGPU, Florence2ModelLoaderMultiGPU, DownloadAndLoadFlorence2ModelMultiGPU, UnetLoaderGGUFDisTorchMultiGPU, UnetLoaderGGUFAdvancedDisTorchMultiGPU, CLIPLoaderGGUFDisTorchMultiGPU, DualCLIPLoaderGGUFDisTorchMultiGPU, TripleCLIPLoaderGGUFDisTorchMultiGPU, QuadrupleCLIPLoaderGGUFDisTorchMultiGPU, UnetLoaderGGUFDisTorch2MultiGPU, UnetLoaderGGUFAdvancedDisTorch2MultiGPU, CLIPLoaderGGUFDisTorch2MultiGPU, DualCLIPLoaderGGUFDisTorch2MultiGPU, TripleCLIPLoaderGGUFDisTorch2MultiGPU, QuadrupleCLIPLoaderGGUFDisTorch2MultiGPU, UnetLoaderGGUFMultiGPU, UnetLoaderGGUFAdvancedMultiGPU, CLIPLoaderGGUFMultiGPU, DualCLIPLoaderGGUFMultiGPU, TripleCLIPLoaderGGUFMultiGPU, QuadrupleCLIPLoaderGGUFMultiGPU, WanVideoModelLoaderMultiGPU, WanVideoModelLoaderMultiGPU_2, WanVideoVAELoaderMultiGPU, LoadWanVideoT5TextEncoderMultiGPU, LoadWanVideoClipTextEncoderMultiGPU, WanVideoTextEncodeMultiGPU, WanVideoBlockSwapMultiGPU, WanVideoSamplerMultiGPU\n======================================== ComfyUI-nunchaku Initialization ========================================\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\nNunchaku version: 1.0.0\nComfyUI-nunchaku version: 1.0.1\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\nD:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\python_embeded\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n'nunchaku_versions.json' not found. Node will start in minimal mode.\n=================================================================================================================\n\n[ReActor] - STATUS - Running v0.6.2-a4 in ComfyUI\nTorch version: 2.8.0+cu128\n\n__     ______   ____                      ____              ____ _      _\n\\ \\   / /  _ \\ / ___| __ _ _ __ ___   ___|  _ \\  _____   __/ ___(_)_ __| |\n \\ \\ / /| |_) | |  _ / _` | '_ ` _ \\ / _ \\ | | |/ _ \\ \\ / / |  _| | '__| |\n  \\ V / |  _ <| |_| | (_| | | | | | |  __/ |_| |  __/\\ V /| |_| | | |  | |\n   \\_/  |_| \\_\\\\____|\\__,_|_| |_| |_|\\___|____/ \\___| \\_/  \\____|_|_|  |_|\n\n             üéÆ VRGameDevGirl custom nodes loaded successfully! üéûÔ∏è\n\n------------------------------------------\nComfyroll Studio v1.76 :  175 Nodes Loaded\n------------------------------------------\n** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n------------------------------------------\n[D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux] | INFO -> Using ckpts path: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux\\ckpts\n[D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux] | INFO -> Using symlinks: False\n[D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\nDWPose: Onnxruntime with acceleration providers detected\n\nInitializing ControlAltAI Nodes\nUsing sage attention\n(RES4LYF) Init\n(RES4LYF) Importing beta samplers.\n(RES4LYF) Importing legacy samplers.\n\n[rgthree-comfy] Loaded 48 extraordinary nodes. üéâ\n\n[save_image_extended] AVIF is supported! Woohoo!\n[save_image_extended] JXL is not supported. To add it: pip install jxlpy\n[save_image_extended]                       You will need a valid MSVC env to build the wheel\n[save_image_extended] version: 2.64\nüîß TTS Audio Suite: Python 3.12 - numba JIT enabled\n‚ÑπÔ∏è Critical package versions: NumPy 2.2.6, Librosa 0.11.0, Numba 0.62.1, PyTorch 2.8.0+cu128, TorchAudio 2.8.0+cu128, Transformers 4.57.0, Accelerate 1.10.1, SoundFile 0.13.1\n‚úÖ FFmpeg available - optimal audio processing enabled\n‚úÖ ChatterboxTTS loaded from bundled package\n‚úÖ ChatterboxVC loaded from bundled package\nJAX version 0.7.2 available.\nFETCH ComfyRegistry Data: 5/99\n‚úÖ F5-TTS loaded from system package\nAPEX FusedRMSNorm not available, using native implementation\nSageAttention: Using SM120+ (Blackwell) with Ada kernel - pv_accum_dtype='fp32+fp32'.\nüé≠ Character voices: Found 26 characters, 10 aliases\n======================================================================\nüöÄ TTS Audio Suite v4.11.0\nUniversal multi-engine TTS extension for ComfyUI\n‚úì Using ComfyUI ChatterBox models\nLoading faiss with AVX2 support.\nSuccessfully loaded faiss with AVX2 support.\n‚úÖ TTS Audio Suite v4.11.0 loaded with 25 nodes:\n   ‚Ä¢ ‚öôÔ∏è ChatterBox Official 23-Lang Engine\n   ‚Ä¢ ‚öôÔ∏è ChatterBox TTS Engine\n   ‚Ä¢ ‚öôÔ∏è F5 TTS Engine\n   ‚Ä¢ ‚öôÔ∏è Higgs Audio 2 Engine\n   ‚Ä¢ ‚öôÔ∏è IndexTTS-2 Engine\n   ‚Ä¢ ‚öôÔ∏è RVC Engine\n   ‚Ä¢ ‚öôÔ∏è VibeVoice Engine\n   ‚Ä¢ üåà IndexTTS-2 Emotion Vectors\n   ‚Ä¢ üåà IndexTTS-2 Text Emotion\n   ‚Ä¢ üåä Audio Wave Analyzer\n   ‚Ä¢ üéôÔ∏è Voice Capture\n   ‚Ä¢ üé§ TTS Text\n   ‚Ä¢ üé≠ Character Voices\n   ‚Ä¢ üé≠ Load RVC Character Model\n   ‚Ä¢ üëÑ F5-TTS Speech Editor\n   ‚Ä¢ üìù Phoneme Text Normalizer\n   ‚Ä¢ üì∫ TTS SRT\n   ‚Ä¢ üîÑ Voice Changer\n   ‚Ä¢ üîß Audio Analyzer Options\n   ‚Ä¢ üîß F5-TTS Edit Options\n   ‚Ä¢ üîß RVC Pitch Extraction Options\n   ‚Ä¢ üîß Viseme Mouth Shape Options\n   ‚Ä¢ üó£Ô∏è Silent Speech Analyzer\n   ‚Ä¢ ü§ê Noise or Vocal Removal\n   ‚Ä¢ ü•™ Merge Audio\n======================================================================\n[VibeVoice] SageAttention available for acceleration\n[VibeVoice] Using embedded VibeVoice (MIT licensed)\n[VibeVoice] VibeVoice nodes registered successfully\nWAS Node Suite: OpenCV Python FFMPEG support is enabled\nWAS Node Suite Warning: `ffmpeg_bin_path` is not set in `D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\was-node-suite-comfyui\\was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\nFETCH ComfyRegistry Data: 10/99\nWAS Node Suite: Finished. Loaded 220 nodes successfully.\n\n        \"Art is not what you see, but what you make others see.\" - Edgar Degas\n\n\nImport times for custom nodes:\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\websocket_image_save.py\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUi-Scale-Image-to-Total-Pixels-Advanced\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\canvas_tab\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_AdvancedRefluxControl\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\Comfyui-QwenEditUtils\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-seamless-tiling\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-omnigen\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\wlsh_nodes\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\janus-pro\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-inpaint-cropandstitch\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-ksampler-tester-loop\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-TiledDiffusion\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-GGUF\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-WanAnimatePreprocess\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-TranscriptionTools\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\teacache\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_essentials\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\save-image-extended-comfyui\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-various\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Florence2\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_ultimatesdupscale\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-custom-scripts\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\controlaltai-nodes\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-segment-anything-2\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-kjnodes\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-vrgamedevgirl\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\VibeVoice-ComfyUI\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-LTXVideo\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Searge_LLM\n   0.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\rgthree-comfy\n   0.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Comfyroll_CustomNodes\n   0.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_controlnet_aux\n   0.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-multigpu\n   0.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-ToSVG\n   0.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI_Sonic\n   0.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-WanVideoWrapper\n   0.2 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\kaytool\n   0.2 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui_layerstyle\n   0.2 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-reactor\n   0.2 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-logicutils\n   0.3 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-videohelpersuite\n   0.4 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-lora-manager\n   0.4 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-kokoro\n   0.5 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-advancedliveportrait\n   0.6 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\RES4LYF\n   0.6 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Crystools\n   0.8 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-itools\n   0.9 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-ollama\n   0.9 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-manager\n   1.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-nunchaku\n   2.0 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\was-node-suite-comfyui\n   2.9 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\comfyui-inspyrenet-rembg\n   4.1 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\tts_audio_suite\n   8.9 seconds: D:\\ComfyUI-Easy-Install\\ComfyUI-Easy-Install\\ComfyUI\\custom_nodes\\ComfyUI-Easy-Use\n\nContext impl SQLiteImpl.\nWill assume non-transactional DDL.\nNo target revision found.\nStarting server\n\nTo see the GUI go to: http://127.0.0.1:8188\nRecipe cache initialized in 0.18 seconds. Found 0 recipes\nLora cache hydrated from persisted snapshot with 446 models\nCheckpoint cache hydrated from persisted snapshot with 56 models\nEmbedding cache hydrated from persisted snapshot with 20 models\nFETCH ComfyRegistry Data: 15/99\nFETCH ComfyRegistry Data: 20/99\nFETCH ComfyRegistry Data: 25/99\nFETCH ComfyRegistry Data: 30/99\nFETCH ComfyRegistry Data: 35/99\nFETCH ComfyRegistry Data: 40/99\nFETCH ComfyRegistry Data: 45/99\nFETCH ComfyRegistry Data: 50/99\nFETCH ComfyRegistry Data: 55/99\nFETCH ComfyRegistry Data: 60/99\nFETCH ComfyRegistry Data: 65/99\nFETCH ComfyRegistry Data: 70/99\nFETCH ComfyRegistry Data: 75/99\nFETCH ComfyRegistry Data: 80/99\nFETCH ComfyRegistry Data: 85/99\nFETCH ComfyRegistry Data: 90/99\nFETCH ComfyRegistry Data: 95/99\nFETCH ComfyRegistry Data [DONE]\n[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\nFETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n[ComfyUI-Manager] All startup tasks have been completed.\n[VibeVoice] Found 1 VibeVoice model(s) available\n[VibeVoice] No LoRA adapters found in ComfyUI/models/vibevoice/loras","createdAt":"2025-10-08T20:42:26Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/122#issuecomment-3383163323","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7NAm-v","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"These are not from my node:\n```\n[VibeVoice] SageAttention available for acceleration\n[VibeVoice] Using embedded VibeVoice (MIT licensed)\n[VibeVoice] VibeVoice nodes registered successfully\n```\n\nI recommend to uninstall other VibeVoice nodes because they might conflict, the same way with any other TTS node with the same models. Some of them might install a dependency that will conflict with our pack.\n\nThe best solution here is to simply have a dedicated portable ComfyuI just for our TTS Audio Suite. I know this is not the solution most people want to hear, but it's probably the easier one. I have many nodes installed and my initialization does take like 2-3 min but no t 7min. And the time is not even just from my custom_node, any install with many custom nodes will add to initialization.\n\nOur Suite makes many checks on initialization, check for dependencies, check for voice character files etc. I think I could improve this by doing SOME of these in a more \"lazy\" way, but I don't have time for this now and I don't consider this high priority.","createdAt":"2025-10-23T22:28:19Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/122#issuecomment-3439488943","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7NErEF","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi! We just released v4.11.19 with startup performance improvements.\n\n**Changes Made:**\n- Optimized all 7 TTS engine nodes to use file-reading-only model discovery instead of importing heavy modules during initialization\n- Moved dependency checking to a non-blocking background thread\n- Added persistent caching for voice character discovery\n\n**Please test v4.11.19 and let us know if the startup time improves for you.**\n\nIf you're still experiencing slowness, could you share:\n1. How long does ComfyUI take to load now?\n2. Does the UI appear faster than before?\n3. Are all model dropdowns still working correctly in the engine nodes?\n\nThis will help us understand if there are other bottlenecks we need to address.","createdAt":"2025-10-24T02:36:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/122#issuecomment-3440554245","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJLIUqA","name":"fixed?","description":"","color":"fbca04"}],"number":122,"title":"[Bug] Everytime I install this plugin, Comfyui Takes ages to load, but when I remove it","updatedAt":"2025-10-25T13:32:25Z"},{"comments":[{"id":"IC_kwDOPZi2kc7GAz__","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"thanks for bringing attention to this. When I get the time I'll look into it. But I can't make a promise this will happen soon.","createdAt":"2025-09-23T01:57:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/109#issuecomment-3322101759","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJLHtrw","name":"check-later","description":"","color":"006b75"}],"number":109,"title":"Vibevoice realtime support  with exllamav3 ?","updatedAt":"2025-09-23T01:57:41Z"},{"comments":[{"id":"IC_kwDOPZi2kc7FIqJm","author":{"login":"patientx"},"authorAssociation":"NONE","body":"here is a test with the same prompt , I tried voxcpm with another node too\n\nother node packs : \n--------------------\nindextts2      :: 30s\nvibevoice 1.5b :: 80s\nvibevoice 7b   :: 251s\nvoxcpm 10 step :: 90s\n\ntts-audio-suite :\n-----------------\nvibevoice 1.5b :: 83s\nvibevoice 7b   :: 229s\nchatterbox     :: 19s\nf5-tts         :: 20s\nhiggs-audio    :: 240s\nindextts2        :: 56s (yes it is somehow slower here)\n\nmy point is , it is a middle tier model at most. At the moment, chatterbox and f5-tts are the fastest, indextts2 best if you need \"emotions\" and it can copy emotions very well from another audio source etc. Yes, voxcpm works but not that great.","createdAt":"2025-09-18T13:12:09Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/99#issuecomment-3307381350","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7FLfUU","author":{"login":"shivdbz2010"},"authorAssociation":"NONE","body":"i came here for same request.","createdAt":"2025-09-18T15:26:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/99#issuecomment-3308123412","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":99,"title":"Any plans to support VoxCPM","updatedAt":"2025-09-18T15:26:47Z"},{"comments":[{"id":"IC_kwDOPZi2kc7E_KYF","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'll look into it. But besides the \"lightweight and efficiency\", do you think this brings anything new to the table?","createdAt":"2025-09-17T23:58:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/87#issuecomment-3304891909","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Fqt3J","author":{"login":"phazei"},"authorAssociation":"NONE","body":"It sounds really good, and vibevoice is SLOW, like so incredibly slow on my 3090, like 10x realtime.  When most other voice generators are closer to 0.5x realtime.","createdAt":"2025-09-21T22:35:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/87#issuecomment-3316309449","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":87,"title":"Any plans for byteDance MegaTTS 3 support?","updatedAt":"2025-09-21T22:35:54Z"},{"comments":[{"id":"IC_kwDOPZi2kc7D1iws","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"This could be a nice addition. Highlighting word by word would need to be an approximation calculated by the time tough since no TTS engine provides word by word time control.","createdAt":"2025-09-12T14:49:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"ROCKET","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/73#issuecomment-3285593132","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7D3Xsr","author":{"login":"StellarBeing25"},"authorAssociation":"NONE","body":"@diodiogod, Would this feature also enable video output with generated audio, as requested in [issue #71 ](https://github.com/diodiogod/TTS-Audio-Suite/issues/71)?","createdAt":"2025-09-12T16:55:35Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/73#issuecomment-3286072107","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7NA1Zj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod), Would this feature also enable video output with generated audio, as requested in [issue #71 ](https://github.com/diodiogod/TTS-Audio-Suite/issues/71)?\n\nWell in this case If I would to add such a node, then yes it would. Because this is a new functionality (subtitle overlay) and this is a new feature, and would cover you combine audio+video component need as well. I wish I had the time to make this, but it's a nice idea. I'll keep it in my list.","createdAt":"2025-10-23T22:41:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/73#issuecomment-3439548003","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJLHnXQ","name":"low-priority","description":"","color":"f9d0c4"},{"id":"LA_kwDOPZi2kc8AAAACJLHtrw","name":"check-later","description":"","color":"006b75"}],"number":73,"title":"[request] subtitle overlay","updatedAt":"2025-10-23T22:41:57Z"},{"comments":[{"id":"IC_kwDOPZi2kc7Do9Cw","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'm not averse to add new old engines, but we might not need a new (old) engine for your \"Polish\" language problem, but actually a better phonamization method for f5 and maybe other models like 23-lang Chantterbox. I still need to go back and study this. It relates to #54 #22 #58 ","createdAt":"2025-09-11T19:08:03Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}},{"content":"THUMBS_DOWN","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/72#issuecomment-3282292912","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7DqDeX","author":{"login":"ziom6270"},"authorAssociation":"NONE","body":"I eagerly await corrections and possible additions. Thanks for the info.","createdAt":"2025-09-11T20:46:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/72#issuecomment-3282581399","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7EYCKo","author":{"login":"youforgetsomething"},"authorAssociation":"NONE","body":"> Master, I have a big favor to ask. Please integrate one of these engines: https://github.com/astramind-ai/Auralis\n> \n> https://github.com/coqui-ai/TTS (XTTSv2)\n> \n> I‚Äôve been playing with ComfyUI and various add-ons for a while and came across yours, which lets me generate audio from an SRT file. The only issue is that it doesn‚Äôt work in my language, which is Polish. In Cursor AI I built a program that uses the XTTSv2 engine and also Auralis, but it took me a long time, and even though I get some ‚Äúhallucinations,‚Äù I regenerate those parts and end up with a nice voice-over for video files. But here it‚Äôs all done much better‚Äîmasterfully and modularly‚Äîsomething my little program doesn‚Äôt have.\n> \n> I tested VibeVoice 7B Large, Higgs, and ChatterBox Multilingual, but my language is handled much worse there than in the two engines mentioned above.\n> \n> Please also add a ‚ÄúMulti SRT Batch‚Äù option so I can select a folder with SRT files and create many final files in a single run.\n> \n> BIG THX\n\nXTTS v2 is the best ever for language i want to use , all new models is a fail in this point. i hope some can wrap xtts2 in a working node with new python and new comfy.","createdAt":"2025-09-16T02:36:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/72#issuecomment-3294634664","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7EaMj-","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> XTTS v2 is the best ever for language i want to use , all new models is a fail in this point. i hope some can wrap xtts2 in a working node with new python and new comfy.\n\nDownvoting me is not going to help you to speed up me supporting an old engine. I get nothing from this project... I hope you do understand that...","createdAt":"2025-09-16T04:55:12Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/72#issuecomment-3295201534","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":72,"title":"[request] New (Old) Engines","updatedAt":"2025-09-16T04:55:12Z"},{"comments":[{"id":"IC_kwDOPZi2kc7NAwyV","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hi thanks for the suggestion, but I think this is not needed given the modular nature of ComfyUI. \n\nThe idea of comfyui is to be less centralized and more modular, meaning you should be able to get your video components + audio generated by the SRT node and combine and preview it with a preview node like the one in the videohelper suite. You don't need to save to test the generation. \n\nYou can use my audio merge node for example to merge the audio components,  then feed the videohelper save node (without saving) just to preview it and many more possibilities. \n\nMaking the SRT node accept video would centralize a process that should be separate inside ComfyUI.","createdAt":"2025-10-23T22:37:36Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/71#issuecomment-3439529109","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7NAytq","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"What I do want to make is a \"Delay SRT timings\" node, that would accept text and would automatically add or remove a amount of time to all the subtitles. This of course could be done externally from a porgram like Subtitle Edit. But would be nice to have it inside Comfy.","createdAt":"2025-10-23T22:39:45Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/71#issuecomment-3439537002","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJRCLwg","name":"not-planned","description":"","color":"d93f0b"}],"number":71,"title":"[Request] Video Path Input and Combined Video Output in SRT Node.","updatedAt":"2025-10-23T22:39:45Z"},{"comments":[{"id":"IC_kwDOPZi2kc7CrYO8","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"yes, for some models I could not get all the files. And some readme for those trained files direct us to use the base English version of the missing files. Others don't.\n\nIf you know of a repo with all the correct files for JP please send it here. I'll gladly add them. But this was the JP chatterbox I found on a collection... I don't really know if it is any good since I don't speak it.\n\nYou could try the official model 23-lang Engine. It should support JP as well. And f5 I guess. Again, please tell me how they perform as I don't know this language. Also it might need better phonemization (related to #22 #54 )","createdAt":"2025-09-08T12:49:11Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/58#issuecomment-3266151356","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GHr6Q","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## üéâ **Update Available: v4.10.0 with Universal Text Processing!**\n\nHey @LumusK! I've just released **v4.10.0** with a new **üìù Phoneme Text Normalizer** node that should help with Japanese text processing issues.\n\n### üÜï What's New: Multilingual Text Processing\n\nThe new **üìù Phoneme Text Normalizer** node offers **4 processing methods** that might help with Japanese ChatterBox:\n\n1. **Pass-through**: Original text (no processing)\n2. **Unicode Decomposition**: Converts special characters to base forms\n3. **IPA Phonemization**: Full phonetic conversion \n4. **Character Mapping**: ASCII fallback\n\n### üîß How It Might Help\n\nThe Japanese ChatterBox issue you're experiencing (\"gibberish\" output) could be related to text encoding/processing problems. The new text normalizer might help by:\n\n- **Standardizing text input** before it reaches ChatterBox\n- **Converting characters** to forms that work better with the incomplete Japanese model\n- **Providing fallback options** when the Japanese tokenizer has issues\n\n### üìñ Try It Out\n\n1. **Update to v4.10.0** \n2. **Download example workflow**: [F5 TTS integration + üìù Phoneme Text Normalizer](https://github.com/diodiogod/TTS-Audio-Suite/blob/main/example_workflows/F5%20TTS%20integration%20+%20üìù%20Phoneme%20Text%20Normalizer.json)\n3. **Test with Japanese text** using different processing methods\n4. **Try with ChatterBox Japanese model** and see if any method improves output\n\n### üß™ Please Test & Report\n\nSince you can verify Japanese output quality:\n- **Does any of the 4 processing methods improve the \"gibberish\" issue?**\n- **Do you get better results with normalized text input?**\n- **How does it compare to the original problematic output?**\n\n### ‚ÑπÔ∏è Note About Japanese Model\n\nYou're right that the Japanese ChatterBox model is incomplete (missing files). The new text processing might help work around some of those limitations, but a complete Japanese model would still be ideal if you find one!\n\n**Please test the new text normalizer and let me know if it helps with Japanese! üáØüáµ**","createdAt":"2025-09-23T12:56:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/58#issuecomment-3323903632","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GJpEc","author":{"login":"LumusK"},"authorAssociation":"NONE","body":"I saw a \"‚öôÔ∏è ChatterBox Official 23-Lang Engine\" node has been added. As far as I can tell this works, but I have to put it in romaji (use English characters). Thankfully there is a 1 to 1 official way to do that. It sometimes does weird pronunciation, but it's so random it could be something as simple as the \"narrator\" audio being bad or other TTS shenanigans.\n\nAs for the Phoneme Text Normalizer node, I don't think that supports Japanese as I don't see it on the language list. (I hope I'm using it right, at the time of writing the link to the example workflow is dead.)","createdAt":"2025-09-23T15:04:14Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/58#issuecomment-3324416284","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7GK-fy","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"You're absolutely right! üìù Phoneme Text Normalizer currently **does not support Japanese**.\n\nLooking at our implementation, Japanese is missing from:\n- Language dropdown options\n- Character detection patterns (no hiragana/katakana/kanji detection)\n- IPA phonemization language mapping\n\nThe Phoneme Text Normalizer was initially designed for European languages with special characters (Polish ƒÖ, ƒô, German √§, √∂, French √©, etc.) where Unicode decomposition and IPA phonemization help with TTS pronunciation.\n\n## Current Japanese Support Options:\n\n**‚úÖ Try ChatterBox Official 23-Lang**: This engine natively supports Japanese and might work better for your Japanese text processing needs. It's specifically designed for multilingual content including Japanese.\n\n**üîÑ Future Exploration**: I could explore adding Japanese support to the Phoneme Text Normalizer later, but it would require:\n- Proper Japanese character detection (hiragana, katakana, kanji)\n- Validation that espeak IPA phonemization actually improves Japanese TTS quality\n- Testing by Japanese speakers to ensure it works correctly\n\nFor now, if ChatterBox Official 23-Lang handles Japanese well, that's probably your best option for Japanese TTS!\n\nThanks for pointing out this limitation - it's an important clarification for Japanese users. üáØüáµ","createdAt":"2025-09-23T16:31:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/58#issuecomment-3324766194","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GK-1C","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I also have updated the broken workflow link","createdAt":"2025-09-23T16:32:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/58#issuecomment-3324767554","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GMnes","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Japanese Support - Limited Testing Results\n\nI've done some basic testing (note: I'm not a Japanese speaker, so this is based on limited observation):\n\n### ChatterBox 23-Lang\n- Romaji input like `Konnichiwa sekai` seemed to work reasonably\n- Native script `„Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå` had mixed results\n- **My recommendation**: Try romaji input if you need Japanese TTS\n\n### Higgs Audio 2  \n- Appeared to handle hiragana characters reasonably\n- Kanji characters get treated as Chinese - for example, `‰∏ñÁïå` (sekai) gets pronounced as Chinese \"sh√¨ ji√®\" instead of Japanese pronunciation\n- Model wasn't trained on Japanese (trained on English/Chinese/Korean/German/Spanish)\n\n### F5-JP\n- Had quality issues in my testing\n\n## My Recommendation (with caveats)\n\nBased on my limited testing as a non-Japanese speaker, ChatterBox 23-Lang with romanized input might be your best option. However, I'd strongly recommend testing yourself to see what works for your specific needs.\n\n## Future Japanese Support in Phoneme Text Normalizer\n\nAdding proper Japanese support would require additional dependencies (like kanji-to-hiragana conversion) and complexity. While this is definitely something we could explore in the future, we're currently focusing development efforts on other language improvements. If there's significant demand for Japanese preprocessing, we'd be open to implementing it.\n\nThanks for the feedback - it's helpful to know what users actually need!","createdAt":"2025-09-23T19:00:24Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/58#issuecomment-3325196204","viewerDidAuthor":true}],"labels":[],"number":58,"title":"Japanese Chatterbox returning gibberish.","updatedAt":"2025-09-23T19:00:46Z"},{"comments":[{"id":"IC_kwDOPZi2kc7CinNm","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Thanks, this will be super helpful, I think it relates to #22 ","createdAt":"2025-09-07T15:32:36Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/54#issuecomment-3263853414","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cinp9","author":{"login":"trollver9000"},"authorAssociation":"NONE","body":"It could be, i know polish so i tested it and works fine, i does sound like english czech accent version of polish but its ok, maybe expression and other flags do not work as well with multilanguage model.\n\nOk its a node now  , heres the code\n\n<img width=\"806\" height=\"548\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5c02fff8-14e7-445f-bcd7-6ae806d03ede\" />\n\n\n\n# Mapping of Polish letters to their decomposed forms\nPOLISH_DECOMPOSE_MAP = {\n    \"ƒÖ\": \"a\\u0328\",\n    \"ƒô\": \"e\\u0328\",\n    \"ƒá\": \"c\\u0301\",\n    \"≈Ñ\": \"n\\u0301\",\n    \"≈õ\": \"s\\u0301\",\n    \"≈∫\": \"z\\u0301\",\n    \"≈º\": \"z\\u0307\",\n    \"√≥\": \"o\\u0301\",\n    \"ƒÑ\": \"A\\u0328\",\n    \"ƒò\": \"E\\u0328\",\n    \"ƒÜ\": \"C\\u0301\",\n    \"≈É\": \"N\\u0301\",\n    \"≈ö\": \"S\\u0301\",\n    \"≈π\": \"Z\\u0301\",\n    \"≈ª\": \"Z\\u0307\",\n    \"√ì\": \"O\\u0301\",\n    # ≈Å/≈Ç is intentionally left out as it typically doesn't need decomposition\n}\n\nclass PolishTextDecomposer:\n    \"\"\"\n    A ComfyUI node to decompose Polish characters in a given text.\n    \"\"\"\n    @classmethod\n    def INPUT_TYPES(s):\n        \"\"\"\n        Defines the input types for the node.\n        \"\"\"\n        return {\n            \"required\": {\n                \"text\": (\"STRING\", {\n                    \"multiline\": True,\n                    \"default\": \"Wpisz tutaj polski tekst do dekompozycji.\"\n                }),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    FUNCTION = \"decompose\"\n\n    CATEGORY = \"text\"\n\n    def decompose(self, text):\n        \"\"\"\n        Replaces Polish special characters with their decomposed forms.\n        \"\"\"\n        decomposed_text = \"\".join(POLISH_DECOMPOSE_MAP.get(char, char) for char in text)\n        return (decomposed_text,)\n\n# A dictionary that maps class names to class objects\nNODE_CLASS_MAPPINGS = {\n    \"PolishTextDecomposer\": PolishTextDecomposer\n}\n\n# A dictionary that maps class names to display names\nNODE_DISPLAY_NAME_MAPPINGS = {\n    \"PolishTextDecomposer\": \"Polish Text Decomposer\"\n}","createdAt":"2025-09-07T15:35:50Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/54#issuecomment-3263855229","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7EEotX","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"Could this be applied to F5TTS model?\n\nI tried replicate your node in my workflow, but not sure if I did it right.\n\nThis is content of my file: \n\npolish_decomposer.py\n\n\n```\nPOLISH_DECOMPOSE_MAP = {\n    \"ƒÖ\": \"a\\u0328\",\n    \"ƒô\": \"e\\u0328\",\n    \"ƒá\": \"c\\u0301\",\n    \"≈Ñ\": \"n\\u0301\",\n    \"≈õ\": \"s\\u0301\",\n    \"≈∫\": \"z\\u0301\",\n    \"≈º\": \"z\\u0307\",\n    \"√≥\": \"o\\u0301\",\n    \"ƒÑ\": \"A\\u0328\",\n    \"ƒò\": \"E\\u0328\",\n    \"ƒÜ\": \"C\\u0301\",\n    \"≈É\": \"N\\u0301\",\n    \"≈ö\": \"S\\u0301\",\n    \"≈π\": \"Z\\u0301\",\n    \"≈ª\": \"Z\\u0307\",\n    \"√ì\": \"O\\u0301\",\n}\n\nclass PolishTextDecomposer:\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"text\": (\"STRING\", {\n                    \"multiline\": True,\n                    \"default\": \"Wpisz tutaj polski tekst do dekompozycji.\"\n                }),\n            },\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"decomposed_text\",)\n    FUNCTION = \"decompose\"\n    CATEGORY = \"text\"\n    OUTPUT_NODE = False\n\n    def decompose(self, text):\n        decomposed_text = \"\".join(POLISH_DECOMPOSE_MAP.get(char, char) for char in text)\n        print(f\"Input text: {text}\")\n        print(f\"Decomposed text: {decomposed_text}\")\n        return (decomposed_text,)\n\nNODE_CLASS_MAPPINGS = {\n    \"PolishTextDecomposer\": PolishTextDecomposer\n}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    \"PolishTextDecomposer\": \"Polish Text Decomposer\"\n}\n```\n\nUsing this model: https://huggingface.co/Gregniuki/F5-tts_English_German_Polish/tree/main/Polish2\n\nMy WF:\n\n<img width=\"723\" height=\"561\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6fa61148-8a77-466d-bc97-ddb4237f6ab4\" />\n\n\nThis is log from generation:\n\n<img width=\"1089\" height=\"463\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/646a70f6-2e16-4ed5-b383-d98edc2c2f10\" />\n\n\nDoes this look like node is working right? Because if the node is correct than the issue must be elsewhere. ","createdAt":"2025-09-14T13:31:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/54#issuecomment-3289549655","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7GHq6a","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## üéâ **Update Available: v4.10.0 - Your Polish Decomposition Idea is Now Built-in!**\n\nHey @trollver9000! Great news - I've implemented your Polish decomposition solution and expanded it into a universal **üìù Phoneme Text Normalizer** node in **v4.10.0**!\n\n### üÜï What's New: Universal Text Processing Node\n\nYour Polish decomposition code inspired a comprehensive solution that works for **all languages**:\n\n- **üìù Phoneme Text Normalizer Node** with 4 processing methods\n- **Unicode Decomposition**: Your exact approach (ƒÖ‚ÜíaÃß, ƒô‚Üí»©, ƒá‚Üíƒá, etc.) + support for German, French, Czech, Nordic languages\n- **IPA Phonemization**: Full phonetic conversion for advanced users\n- **Character Mapping**: ASCII fallback (ƒÖ‚Üía, ƒô‚Üíe, etc.)\n- **Auto-Language Detection**: Automatically detects Polish, German, French, etc.\n\n### üîß Your Code is Now Integrated!\n\nThe Unicode Decomposition method uses the same mapping approach you created:\n\n\n### üìñ Try It Out\n\n1. **Update to v4.10.0** \n2. **Download example workflow**: [F5 TTS integration + üìù Phoneme Text Normalizer](https://github.com/diodiogod/TTS-Audio-Suite/blob/main/example_workflows/F5%20TTS%20integration%20+%20üìù%20Phoneme%20Text%20Normalizer.json)\n3. **Use the Unicode Decomposition method** - it's your solution but expanded!\n4. **Compatible with ChatterBox, F5-TTS, and all other engines**\n\n### üß™ Please Test\n\nSince you know Polish and tested the original concept:\n- **Does the Unicode Decomposition method work as well as your standalone version?**\n- **How does it compare to other processing methods?**\n- **Any other languages you'd like me to add support for?**\n\nThanks for the great idea that led to this universal solution! This should help not just Polish users, but everyone dealing with special characters in multilingual TTS. üåç\n\n**Please test the new node and let me know how it works! üáµüá±**","createdAt":"2025-09-23T12:55:28Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/54#issuecomment-3323899546","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GXShD","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"I compared:\n\nChatterBox Polish Phoneme Text Normalizer - The Unicode Decomposition method:\n\n[ChatterBox_Polish normalizer.wav](https://github.com/user-attachments/files/22513301/ChatterBox_Polish.normalizer.wav)\n\nChatterBox Polish Text Decomposer:\n\n[ChatterBox_Polish decomposer.wav](https://github.com/user-attachments/files/22513303/ChatterBox_Polish.decomposer.wav)\n\nF5TTS Greniuki demo:\n\n[Greniuki_polish.wav](https://github.com/user-attachments/files/22513309/Greniuki_polish.wav)\n\nPhonemes in Greniuki sound better here in my opinion.","createdAt":"2025-09-24T11:40:18Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/54#issuecomment-3327993923","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":54,"title":"chatterbox does not decompose polish letters properly, i made python code with gpt to fix this, its for polish language only","updatedAt":"2025-10-01T11:53:52Z"},{"comments":[{"id":"IC_kwDOPZi2kc7CcA7I","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Have you tried not making line breaks? (every line break is treated as a new chunk -- maybe I should revise this for vibevoice later); also try longer phrases. VibeVoice sucks with small segments. _[edit: Sorry, again, this is not what happended in your exemple, as it was using the native multi speaker, and it does not make line breakes]_\n\nAnd also the native multispeaker works better than my own implementation (that breaks characters speech in separate generations), the reason is the same as above, small segments are not done well by this model...  (I should also change this to default to the native multispeaker). Just change the multi-speaker option to native. _[sorry, now I see you already set it to native]_\n\ntry these and tell me if it works better now!","createdAt":"2025-09-06T13:09:04Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262123720","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7CcBZX","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Can you post your console log? also maybe export your workflow and drop it here, so I can try your exact settings.","createdAt":"2025-09-06T13:10:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262125655","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7CcINw","author":{"login":"Magicalore"},"authorAssociation":"NONE","body":"> Can you post your console log? also maybe export your workflow and drop it here, so I can try your exact settings.\n\nSure here's the workflow, I used the same exact one as yours and even left the text by default: https://pastebin.com/sqg7P12T\nAnd here's the log: https://pastebin.com/9PJ4MBq4\n\nThanks for your help!","createdAt":"2025-09-06T13:22:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262153584","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CclsD","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@Magicalore I could not reproduce your error. I've tried your exact workflow, and saw no errors or discrepancies between my log and yours... look at my output, see if it matches yours (you can drag yours to the comment and post as well, if you want.)\n\n[ComfyUI_00029_.mp3](https://github.com/user-attachments/files/22188228/ComfyUI_00029_.mp3)","createdAt":"2025-09-06T14:24:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262274307","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7CcnYM","author":{"login":"Magicalore"},"authorAssociation":"NONE","body":"@diodiogod Here's how mine sounds like with the sound you gave me\n\n[ComfyUI_00014_.mp3](https://github.com/user-attachments/files/22188238/ComfyUI_00014_.mp3)\n\nI have also updated the node to the latest version  4.8.10 as well\nNo idea then why it's working for you and not me","createdAt":"2025-09-06T14:27:53Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262281228","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Cc0yJ","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"@diodiogod \n> [@Magicalore](https://github.com/Magicalore) I could not reproduce your error. I've tried your exact workflow, and saw no errors or discrepancies between my log and yours... look at my output, see if it matches yours (you can drag yours to the comment and post as well, if you want.)\n> \n> [ComfyUI_00029_.mp3](https://github.com/user-attachments/files/22188228/ComfyUI_00029_.mp3)\n\nMe too, i upgraded to 4.8.8, the vibevoice failed, both 1.5B and 7B\nThe follow is the output of 1.5B\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: auto, Steps: 8\n‚ö†Ô∏è TTS Text: No voice reference provided - this may cause issues with some engines\nüé§ Generating Vibevoice for 'narrator' (lang: en)\n‚úÖ VibeVoice base package found: C:\\Users\\yao\\miniconda3\\envs\\comfyenv\\Lib\\site-packages\\vibevoice\\__init__.py\n‚úÖ VibeVoiceForConditionalGenerationInference imported successfully\n‚úÖ VibeVoiceProcessor imported successfully\nüìÅ Using cached VibeVoice model: D:\\HuggingFaceCache\\hub\\models--microsoft--VibeVoice-1.5B\\snapshots\\0220f13e5dc319548654ffac0059bb0f107345eb\nüì• Downloading tokenizer.json from Qwen/Qwen2.5-1.5B...\n‚úÖ Tokenizer downloaded to D:\\HuggingFaceCache\\hub\\models--microsoft--VibeVoice-1.5B\\snapshots\\0220f13e5dc319548654ffac0059bb0f107345eb\nüîÑ Loading VibeVoice model 'vibevoice-1.5B' on cuda...\n   üöÄ Auto-selected SageAttention (GPU-optimized mixed-precision)\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:15<00:00,  5.16s/it]\n   üéØ Applying SageAttention patch to model...\nSuccessfully patched 28 Qwen2Attention layers with SageAttention\n   ‚úÖ SageAttention successfully applied\nNo preprocessor_config.json found at D:\\HuggingFaceCache\\hub\\models--microsoft--VibeVoice-1.5B\\snapshots\\0220f13e5dc319548654ffac0059bb0f107345eb, using defaults\nLoading tokenizer from Qwen/Qwen2.5-1.5B\nThe tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization.\nThe tokenizer class you load from this checkpoint is 'Qwen2Tokenizer'.\nThe class this function is called from is 'VibeVoiceTextTokenizerFast'.\n‚úÖ VibeVoice model 'vibevoice-1.5B' loaded successfully\n   Device: cuda, Attention: sage\n‚úÖ VibeVoice adapter: Model 'vibevoice-1.5B' loaded with enhanced parameters\nüé≠ VibeVoice: Character switching mode - found characters: speaker1, speaker2\nüîÑ VibeVoice: Using main voice fallback for 'speaker1'\nüîÑ VibeVoice: Using main voice fallback for 'speaker2'\nüéôÔ∏è Using VibeVoice native multi-speaker mode for 2 speakers\nüé≠ Native multi-speaker: Processing 2 segments with characters: ['speaker1', 'speaker2']\nüé≠ Available voice_mapping keys: ['speaker1', 'speaker2']\nüé§ Speaker inputs connected: ['Speaker 2']\nüé§ Manual format 'Speaker 1' -> using ‚ùå no narrator, using default\nüé§ Manual format 'Speaker 2' -> using ‚úÖ connected input\nüé≠ NATIVE MULTI-SPEAKER - Complete formatted text for VibeVoice:\n============================================================\nSpeaker 1: On Tuesday, the pigeons held parliament. They debated the ethics of breadcrumbs and the metaphysics of flight.\nSpeaker 2: One particularly philosophical pigeon named Thistle believed gravity was just a suggestion. He once floated for three minutes straight, fueled by sheer conviction and a gust of rebellious wind.\n============================================================\nüé§ Character mapping: {}\nüé§ Using 2 voice samples for generation\nüéµ VibeVoice ENGINE: Loaded audio from C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\voices_examples\\David_Attenborough CC3.wav - shape: (226436,), sr: 22050\nüîÑ VibeVoice: Using 8 diffusion inference steps\n‚úÖ Vibevoice generation complete for 'narrator'\nPrompt executed in 102.01 seconds\n\n\nHere is an output of 7B, i tried several times, all failed\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-7B on auto\n   Mode: Custom Character Switching\n   CFG Scale: 1.3, Sampling: False\n   Attention: auto, Steps: 8\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS engines will fail\nüé§ Generating Vibevoice for 'narrator' (lang: en)\nüîÑ Reusing cached vibevoice engine instance (updated with new generation parameters)\nüé≠ VibeVoice: Character switching mode - found characters: speaker1, speaker2\nüîÑ VibeVoice: Using main voice fallback for 'speaker1'\nüîÑ VibeVoice: Using main voice fallback for 'speaker2'\nüé≠ SINGLE SEGMENT - Formatted text for VibeVoice:\nüìù Speaker 1: On Tuesday, the pigeons held parliament. They debated the ethics of breadcrumbs and the metaphysics of flight.\nüé§ Character: 'speaker1', Voice ref: <class 'dict'> ‚úÖ\nüîÑ VibeVoice: Using 8 diffusion inference steps\nüé≠ SINGLE SEGMENT - Formatted text for VibeVoice:\nüìù Speaker 1: One particularly philosophical pigeon named Thistle believed gravity was just a suggestion. He once floated for three minutes straight, fueled by sheer conviction and a gust of rebellious wind.\nüé§ Character: 'speaker2', Voice ref: <class 'dict'> ‚úÖ\nüîÑ VibeVoice: Using 8 diffusion inference steps\n‚úÖ Vibevoice generation complete for 'narrator'\nPrompt executed in 161.10 seconds\n\n","createdAt":"2025-09-06T14:52:13Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262336137","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Cc4kR","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@windy-bleue did it output nothing or weird sounds like @Magicalore did? \nCan you guys tell me what is your COmfyUI installation (portable or direct venv) and what python are you using? I'll have to make a clean install to test this.","createdAt":"2025-09-06T15:00:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262351633","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cc76k","author":{"login":"Magicalore"},"authorAssociation":"NONE","body":"@diodiogod I actually just did a clean install myself (portable version). Updated comfyui using the update comfyui bat file, installed the tts-audio-suite manually (following the manual install guide) and now I can't even generate an audio, I get \n\nRuntimeError: Generation failed: 'DynamicCache' object has no attribute 'key_cache'\n\nFull error log here: https://pastebin.com/vz1Sp8ZB","createdAt":"2025-09-06T15:05:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262365348","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CdAy1","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> [@windy-bleue](https://github.com/windy-bleue) did it output nothing or weird sounds like [@Magicalore](https://github.com/Magicalore) did? Can you guys tell me what is your COmfyUI installation (portable or direct venv) and what python are you using? I'll have to make a clean install to test this.\n@diodiogod \nThe output is weird noise. And i install comfyui directly in miniconda ,my python is 3.12.11\n","createdAt":"2025-09-06T15:13:25Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262385333","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CdOc4","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Update: VibeVoice Improvements (v4.8.11)\n\nI've integrated improvements from wildminder's VibeVoice implementation, but these probably aren't related to your specific issue.\n\n## For @Magicalore \nSince you're getting the `DynamicCache` error after clean install:\n1. Did you use our `install_script.py` or install manually?\n2. What transformers version got installed? (`pip show transformers`)\n\n## For @windy-bleue\nFor the weird noise issue, we need to dig deeper since our transformers compatibility fix was already in place. Can you try with v4.8.11 and let us know if the issue persists?\n\nThe fact that it works in my environment but not yours suggests an environment/dependency mismatch we haven't identified yet.","createdAt":"2025-09-06T15:39:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262441272","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7CdbRb","author":{"login":"Magicalore"},"authorAssociation":"NONE","body":"@diodiogod @windy-bleue \nok I found the issue, it was indeed a transformers version issue, which sucks because I had to go through a bunch of installs to get it to work on an already existing install which was hell...\nBUT on a new comfyui portable install version, it's fairly simple. A new install has the 3.13.6 python version.\nSo first, update comfyui using the update_comfyui.bat file inside the update folder. Then go inside the python_embeded folder, open a command window in that folder (cmd then press enter in the folder path) then paste these two commands:\n\npython.exe -m pip install --upgrade pip\npython.exe -m pip install \"transformers==4.51.3\" \"accelerate==1.6.0\" \"tokenizers==0.21.2\" --only-binary=:all:\n\nthen once everything is installed using this workflow works\n\n[ComfyUI_00002_.mp3](https://github.com/user-attachments/files/22188938/ComfyUI_00002_.mp3)\n\n@diodiogod not sure how we can make it easier for other people who installs it for the first time but hey, at least there is 1 surefire way to make it work","createdAt":"2025-09-06T16:03:51Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262493787","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Cdges","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod) [@windy-bleue](https://github.com/windy-bleue) ok I found the issue, it was indeed a transformers version issue, which sucks because I had to go through a bunch of installs to get it to work on an already existing install which was hell... BUT on a new comfyui portable install version, it's fairly simple. A new install has the 3.13.6 python version. So first, update comfyui using the update_comfyui.bat file inside the update folder. Then go inside the python_embeded folder, open a command window in that folder (cmd then press enter in the folder path) then paste these two commands:\n> \n> python.exe -m pip install --upgrade pip python.exe -m pip install \"transformers==4.51.3\" \"accelerate==1.6.0\" \"tokenizers==0.21.2\" --only-binary=:all:\n> \n> then once everything is installed using this workflow works\n> \n> [ComfyUI_00002_.mp3](https://github.com/user-attachments/files/22188938/ComfyUI_00002_.mp3)\n> \n> [@diodiogod](https://github.com/diodiogod) not sure how we can make it easier for other people who installs it for the first time but hey, at least there is 1 surefire way to make it work\n\nHey this helps a lot! Our install.py script was made exactly for this type of complex dependencies' installation, it is run by ComfyUI Manager every time a user installs the node or updates it. I can try to integrate your findings it there. i'll ivastigate this later. Thanks.","createdAt":"2025-09-06T16:11:03Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262515116","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cduyu","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> For the weird noise issue, we need to dig deeper since our transformers compatibility fix was already in place. Can you try with v4.8.11 and let us know if the issue persists?\n\n@diodiogod \nI upgrade to 4.8.11, run ‚Äòpython install.py' , 1.5b and 7b  both fail , the output is weird noise.\nPlus, in my installation,  transformers 4.51.3, accelerate 1.8.1  tokenizers 0.21.4 \n\n[ComfyUI_temp_1.5b.wav](https://github.com/user-attachments/files/22189109/ComfyUI_temp_1.5b.wav)\n[ComfyUI_temp_7b_.wav](https://github.com/user-attachments/files/22189108/ComfyUI_temp_7b_.wav)","createdAt":"2025-09-06T16:36:06Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262573742","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CePaz","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## ‚úÖ FIXED in v4.8.14\n\nThis issue has been resolved! The VibeVoice DynamicCache compatibility problem has been fixed with comprehensive patches for transformers 4.56+.\n\n**What was fixed:**\n- Added  and  compatibility properties to DynamicCache\n- Fixed  signature changes in newer transformers\n- Added runtime monkey patching for VibeVoice model compatibility\n\n**How to get the fix:**\n1. Update to TTS-Audio-Suite v4.8.14 (via ComfyUI Manager or git pull)\n2. Restart ComfyUI\n3. VibeVoice should now work with transformers 4.56+ without the cache error\n\nYou can now safely upgrade transformers to the latest version. The fix maintains backward compatibility with older transformers versions as well.\n\n**Testing confirmed:** VibeVoice multi-speaker generation now works properly with newer transformers versions.\n\nPlease test and let me know if you encounter any remaining issues!","createdAt":"2025-09-06T17:29:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3262707379","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cgava","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> ## ‚úÖ FIXED in v4.8.14\n> This issue has been resolved! The VibeVoice DynamicCache compatibility problem has been fixed with comprehensive patches for transformers 4.56+.\n> Please test and let me know if you encounter any remaining issues!\n\n@diodiogod \nYes, it works, i upgrade the tts to 4.8.19, the transformers to 4.56.1 , both 1.5B and 7B work, but the output 1.5B is weird, the txt is:\nSpeaker1: On Tuesday, the pigeons held parliament. They debated the ethics of breadcrumbs and the metaphysics of flight.\nSpeaker2: One particularly philosophical pigeon named Thistle believed gravity was just a suggestion. He once floated for three minutes straight, fueled by sheer conviction and a gust of rebellious wind.\n \n\n[ComfyUI_temp_1.5B_repeat_.wav](https://github.com/user-attachments/files/22192164/ComfyUI_temp_1.5B_repeat_.wav)\n\nI restart the conda and comfyui, run again, \n\n[ComfyUI_temp_1.5B_weird.wav](https://github.com/user-attachments/files/22192237/ComfyUI_temp_1.5B_weird.wav)\n\nPerhaps, i uesd it in a wrong way ,the multi-speaker-mode , the loadaudio , the slot of the speaker_voice i uesd .   Thanks.\n\n<img width=\"1296\" height=\"507\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c378ba59-81cf-4dde-a13e-7bc46bcd93a4\" />\n\n","createdAt":"2025-09-06T23:16:05Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263278042","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CghjR","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"1.5B kind of sucks, but something is off. Some of the david attenborough reference text is leaking to the model text input in your exemples, which should NOT happen, because from what I remembered, VibeVoice does not support reference text (I think, I'll have to check, I know Higg 2 supports it, and f5 NEEDS it).\n\nThis is probably a bug I'll have to look into it. Your workflow looks correct.","createdAt":"2025-09-07T00:19:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263305937","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cg5ko","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@windy-bleue after a second analysis, I see a lot of problems with your workflow. 1st you are using Cutom Character Switching (meaning my implementation of switching characters with tags [Alice] ) but you are trying to set up the native multi-speaker VibeVoice format of \"Speaker\" on your text. This won't work well. Speaker will just be parsed as text.\n\n~~Even if you do set the Native Multi-speaker option. You formatted your text wrong. It's \"Speaker 1:\" Not \"Speaker1:\" This is probably enough to not trigger the correct multi-speaker setting for the engine... I need to imprive this to make user small \"errors\" like that be automatically corrected.~~ Edit: Actually, I'm wrong. My code already handles this. Speaker1 and Speaker 1 both work and triggers the correct multispeaker (if the native option is on)\n\nIn any case, your ouput still suggests a bug on my implementation, because how the David Reference text is getting spoken? This should not happen.\n\nIt would be immensely helpful if you could provide me you exact json (you can simply drag it all in the comment here on github). AND you Emily Blunt wav file, so I can try to reproduce the exact workflow you did.","createdAt":"2025-09-07T02:54:45Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263404328","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cg8Jm","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> [@windy-bleue](https://github.com/windy-bleue) after a second analysis, I see a lot of problems with your workflow. 1st you are using Cutom Character Switching (meaning my implementation of switching characters with tags [Alice] ) but you are trying to set up the native multi-speaker VibeVoice format of \"Speaker\" on your text. This won't work well. Speaker will just be parsed as text.\n> It would be immensely helpful if you could provide me you exact json (you can simply drag it all in the comment here on github). AND you Emily Blunt wav file, so I can try to reproduce the exact workflow you did.\n\n@diodiogod \nThanks, i think the weird thing is what the content that David said comes from? \n[my tts.json](https://github.com/user-attachments/files/22192705/my.tts.json)\n\n[E_B_01.wav](https://github.com/user-attachments/files/22192706/E_B_01.wav)","createdAt":"2025-09-07T03:09:48Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263414886","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Cg-Ee","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> > [@windy-bleue](https://github.com/windy-bleue) after a second analysis, I see a lot of problems with your workflow. 1st you are using Cutom Character Switching (meaning my implementation of switching characters with tags [Alice] ) but you are trying to set up the native multi-speaker VibeVoice format of \"Speaker\" on your text. This won't work well. Speaker will just be parsed as text.\n> > It would be immensely helpful if you could provide me you exact json (you can simply drag it all in the comment here on github). AND you Emily Blunt wav file, so I can try to reproduce the exact workflow you did.\n> \n> [@diodiogod](https://github.com/diodiogod) Thanks, i think the weird thing is what the content that David said comes from? [my tts.json](https://github.com/user-attachments/files/22192705/my.tts.json)\n> \n> [E_B_01.wav](https://github.com/user-attachments/files/22192706/E_B_01.wav)\n\nExactly, the weird phrase inside your audio comes from David reference text (what the original audio says). Thanks for the audio and json. I'll lookt at this as soon as I can.\n\nOn a positive note: I've just pushed VibeVoice and Lang-23 Chatterbox to work with memory management! No more OOMS because you loaded more than one Engine. When switching models they should be clearing out of memory. (or when you click the unload models button)","createdAt":"2025-09-07T03:23:10Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263422750","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cg_PT","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> Exactly, the weird phrase inside your audio comes from David reference text (what the original audio says). Thanks for the audio and json. I'll lookt at this as soon as I can.\n> \n> On a positive note: I've just pushed VibeVoice and Lang-23 Chatterbox to work with memory management! No more OOMS because you loaded more than one Engine. When switching models they should be clearing out of memory. (or when you click the unload models button)\n\n@diodiogod \nI just tried the 4.8.22 with the vibevoice module in \"my_tts\" , both 1.5B and 7B, if i chose \"custom multi speaker\" , then it didn't switch the voice, just the opt_narrator; if i chose the \"Native Multi-speaker\", it's normal.\n","createdAt":"2025-09-07T03:33:06Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263427539","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7ChBXO","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> On a positive note: I've just pushed VibeVoice and Lang-23 Chatterbox to work with memory management! No more OOMS because you loaded more than one Engine. When switching models they should be clearing out of memory. (or when you click the unload models button)\n\n@diodiogod \ni upgrade it to 4.8.23, vibevoice  1.5B, Native multi-speaker , the extra text comes again,7B is normal: \n\n[ComfyUI_temp_jqbef_00002_.wav](https://github.com/user-attachments/files/22192814/ComfyUI_temp_jqbef_00002_.wav)\n\n \n","createdAt":"2025-09-07T03:47:38Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263436238","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CiM1p","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Oh I was finally able to reproduce it! O got the reference audio spoken. Now I'll work on it. Something for sure is wrong.\nEdit: or... now that I'm thinking about it.. could it be that VibeVoice it'self is just using the reference AUDIO not the text. Which could be just a model error (since we do have to give the model the reference AUDIO), might not be my code. Anyway, better check.","createdAt":"2025-09-07T12:36:51Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3263745385","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cj0zB","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> Oh I was finally able to reproduce it! O got the reference audio spoken. Now I'll work on it. Something for sure is wrong. Edit: or... now that I'm thinking about it.. could it be that VibeVoice it'self is just using the reference AUDIO not the text. Which could be just a model error (since we do have to give the model the reference AUDIO), might not be my code. Anyway, better check.\n\n\n@diodiogod I have upgraded the tts to 4.8.25, and  i have run both ‚Äòpip install -r requirements.txt' and 'python install.py', then the vibevoice 1.5B failed:\n\n\ngot prompt\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS engines will fail\nüé§ Generating Vibevoice for 'narrator' (lang: en)\nüîÑ Reusing cached vibevoice engine instance (updated with new generation parameters)\nüé≠ VibeVoice: Character switching mode - found characters: speaker1, speaker 1, speaker 2\nüîÑ VibeVoice: Using main voice fallback for 'speaker1'\nüîÑ VibeVoice: Using main voice fallback for 'speaker 1'\nüîÑ VibeVoice: Using main voice fallback for 'speaker 2'\nüéôÔ∏è Using VibeVoice native multi-speaker mode for 3 speakers\nüé≠ Native multi-speaker: Processing 3 segments with characters: ['speaker 1', 'speaker 2', 'speaker1']\nüé≠ Available voice_mapping keys: ['speaker1', 'speaker 1', 'speaker 2']\nüé§ Speaker inputs connected: ['Speaker 1', 'Speaker 2']\nüé§ Manual format 'Speaker 1' -> using ‚úÖ main narrator (Tony)\nüé§ Manual format 'Speaker 2' -> using ‚úÖ connected input\nüé§ Manual format 'Speaker 1' -> using ‚úÖ main narrator (Tony)\nüé≠ NATIVE MULTI-SPEAKER - Complete formatted text for VibeVoice:\n============================================================\nSpeaker 1: On Tuesday, the pigeons held parliament. They debated the ethics of breadcrumbs and the metaphysics of flight.\nSpeaker 2: One particularly philosophical pigeon named Thistle believed gravity was just a suggestion. He once floated for three minutes straight, fueled by sheer conviction and a gust of rebellious wind.\nSpeaker 1: Here is all.\n============================================================\nüé§ Character mapping: {}\nüé§ Using 2 voice samples for generation\nüéµ VibeVoice ENGINE: Loaded audio from C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\voices_examples\\David_Attenborough CC3.wav - shape: (226436,), sr: 22050\nüîÑ VibeVoice: Using 8 diffusion inference steps\nCompatibility patch fallback triggered: GenerationMixin._prepare_cache_for_generation() takes 6 positional arguments but 7 were given\nCompatibility patch fallback triggered: GenerationMixin._prepare_cache_for_generation() takes 6 positional arguments but 7 were given\nVibeVoice generation failed: 'DynamicCache' object has no attribute 'key_cache'\n‚ùå TTS Text generation failed: Generation failed: 'DynamicCache' object has no attribute 'key_cache'\nTraceback (most recent call last):\n  File \"C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\engines\\vibevoice_engine\\vibevoice_engine.py\", line 668, in generate_speech\n    output = self.model.generate(**inputs, **generation_kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yao\\miniconda3\\envs\\comfyenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yao\\miniconda3\\envs\\comfyenv\\Lib\\site-packages\\vibevoice\\modular\\modeling_vibevoice_inference.py\", line 554, in generate\n    for layer_idx, (k_cache, v_cache) in enumerate(zip(negative_model_kwargs['past_key_values'].key_cache,\n                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'DynamicCache' object has no attribute 'key_cache'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\unified/tts_text_node.py\", line 667, in generate_speech\n    result = engine_instance.generate_tts_audio(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\unified/tts_text_node.py\", line 373, in generate_tts_audio\n    audio_segments = self.processor.process_text(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\vibevoice\\vibevoice_processor.py\", line 106, in process_text\n    return self._process_native_multispeaker(character_segments, voice_mapping, params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\nodes\\vibevoice\\vibevoice_processor.py\", line 197, in _process_native_multispeaker\n    audio = self.adapter._generate_native_multispeaker(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\engines\\adapters\\vibevoice_adapter.py\", line 504, in _generate_native_multispeaker\n    return self.vibevoice_engine.generate_speech(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\yao\\ComfyUI\\custom_nodes\\TTS-Audio-Suite\\engines\\vibevoice_engine\\vibevoice_engine.py\", line 704, in generate_speech\n    raise RuntimeError(f\"Generation failed: {e}\")\nRuntimeError: Generation failed: 'DynamicCache' object has no attribute 'key_cache'\nPrompt executed in 13.75 seconds","createdAt":"2025-09-08T00:04:28Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3264171201","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CrNz9","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Are you guys using the sage attention method? I need to have time to investigate this, but I think when using sage it returns the weird noise.","createdAt":"2025-09-08T12:39:45Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3266108669","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7CsOyN","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> Are you guys using the sage attention method? I need to have time to investigate this, but I think when using sage it returns the weird noise.\nYes, my comfyui starts as  :  python main.py --use-sage-attention.","createdAt":"2025-09-08T13:38:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3266374797","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Dc-0h","author":{"login":"alessandroperilli"},"authorAssociation":"NONE","body":"@diodiogod First of all, thank you for developing this suite and sharing it with the community. It's a fantastic project, and I'm evaluating it for inclusion in the next version of my [Open Creative Studio](https://oc.studio) for ComfyUI.\n\nAfter hours-long testing yesterday, I discovered that Sage Attention significantly impacts the speech generation, even with the 7B model parameters, producing the weird, metallic, echoed noises described by others in this thread. And they usually appear around 1min of generated speech.\n\nManually setting the attention parameters to `sdpa` almost completely fixes the problem (you can still, very occasionally, hear a background sound at the very beginning of the generated speech, or a speech that is not fully normalized in terms of audio levels). \n\nI hope this helps.","createdAt":"2025-09-11T08:26:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":2}},{"content":"HEART","users":{"totalCount":2}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3279154465","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Dgn5G","author":{"login":"Peffat"},"authorAssociation":"NONE","body":"i have the vibevoice working with 7b","createdAt":"2025-09-11T11:34:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3280109126","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7GCu-u","author":{"login":"alenknight"},"authorAssociation":"NONE","body":"I'm also having this issue too.  TTS Index works... Chatterbox works (now ... thanks again for helping me fix).... but vibe voice is producing that weird metallic noise.\nI'm using SageAttention... what's SDPA?  how to enable?  \nit runs, no errors... but just that weird noise.\n\nalso, I ran another custom node for vibevoice .. and that works just fine.  ","createdAt":"2025-09-23T06:30:48Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3322605486","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7GD08b","author":{"login":"alessandroperilli"},"authorAssociation":"NONE","body":"@alenknight SDPA stands for Scaled Dot-Product Attention. It's Python's out-of-the-box attention mode, and the default attention mode for ComfyUI. In other words, just don't load ComfyUI with the `--use-sage-attention` flag.","createdAt":"2025-09-23T08:15:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3322892059","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7GIbdc","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I need to check other implementations for VibeVoice with sage again to see what happened here that Sage is giving this weird sounds on my project. Just didn't get the time for the moment.\n\n@alenknight the SDPA should be an option on the Engine node. But like @alessandroperilli pointed out, if you have --use-sage-attention flag it might override the option.","createdAt":"2025-09-23T13:47:01Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3324098396","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GJccX","author":{"login":"alessandroperilli"},"authorAssociation":"NONE","body":"@diodiogod I tried other VibeVoice implementations and yours is, by far, the best. For some reason, the others generate speech that is way too fast or flat in emotion. Whatever you pick from them, I hope it won't compromise the quality we have today.","createdAt":"2025-09-23T14:50:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3324364567","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7GK8H4","author":{"login":"alenknight"},"authorAssociation":"NONE","body":"working!  yeah if I select SDPA manually in the 'attention mode' that works.  thanks!","createdAt":"2025-09-23T16:29:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3324756472","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HB_Fn","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I have remade the sage attn based on Enemyx-net implementation. This should now be fixed. \n@alessandroperilli can you check if the quality in your perception stays the same?\n\n@alenknight @windy-bleue @Magicalore can you guys test sage attention now? It's working on my end.\n\nThere are still some minor bugs I need to check (it hits cache after changing attn modes and it should not, it should regenerate)\nAnd also the Speaker4 behavior is completely erratic... this could be my implementation bug or the model simply can't handle 4 speakers... IDK, needs more investigation. But 3 speakers work great here.","createdAt":"2025-09-26T15:29:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3339186535","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7HDVSg","author":{"login":"alessandroperilli"},"authorAssociation":"NONE","body":"@diodiogod No more metallic sounds with Sage Attention (at least not with the CFG value I use). \nIt's good, but it's not as good as with SDPA. The latter makes the voice more expressive and the pauses more natural. It's a subtle difference, but it's there.\n\nThe quality with SDPA has remained untouched. Thank you!","createdAt":"2025-09-26T16:36:36Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HOORAY","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3339539616","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HE9PZ","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod) No more metallic sounds with Sage Attention (at least not with the CFG value I use). It's good, but it's not as good as with SDPA. The latter makes the voice more expressive and the pauses more natural. It's a subtle difference, but it's there.\n> \n> The quality with SDPA has remained untouched. Thank you!\n\nGood to know! I don't see any relevant increase in speed either for Sage, so better stick with SDPA.\n\nAnd about the 4 speaker \"bug\" was actually my inference fault. I used 2 character, (ex: narrator and Cowboy - same audio) for 2 different speakers. This makes the model confused. When using 4 complete different audios, it works as intended.\nChanging att mode will now invalidate cache (as it should).\n\nI'm closing this for now, if anyone has a problem let me know.","createdAt":"2025-09-26T18:32:10Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3339965401","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7HFbhh","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> I have remade the sage attn based on Enemyx-net implementation. This should now be fixed. [@alessandroperilli](https://github.com/alessandroperilli) can you check if the quality in your perception stays the same?\n\n@diodiogod \nThanks for your work, the model 1.5B works normal in both sage and sdpa.\n\nBut i have two problems: \n1. the model list , there are some extra names.\n2. After i switched the model and attention_mode several times, the inference time becomes too long, about 320s. It should be about 110s.\n<img width=\"809\" height=\"398\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/324336ac-b46f-4e67-97de-851afccfe5a3\" />\n\n<img width=\"679\" height=\"99\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/804264be-6cbb-4bbc-a738-f8d2d38669b1\" />\n\n\n1\ngot prompt\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: auto, Steps: 16\n   üöÄ Auto-selected SageAttention (GPU-optimized mixed-precision)\nüîß VibeVoice: Using device_map: cuda\nPrompt executed in 114.89 seconds\n\n2\ngot prompt\nüêõ VibeVoice ENGINE: Cache params - character='multi_speaker', cfg_scale=1.3, use_sampling=False, multi_speaker_mode='Native Multi-Speaker', attention=sage, steps=16, quant=False\nüîÑ VibeVoice: Using 16 diffusion inference steps\n‚úÖ Vibevoice generation complete. Default narrator: Sophie_Anderson CC3\nPrompt executed in 111.80 seconds\n\n3\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sdpa, Steps: 16\nPrompt executed in 109.37 seconds\n\n4\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sage, Steps: 16\nPrompt executed in 113.95 seconds\n\n5\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-7B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sage, Steps: 16\nPrompt executed in 148.96 seconds\n\n6\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-7B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sdpa, Steps: 16\nPrompt executed in 125.31 seconds\n\n7\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sdpa, Steps: 16\nPrompt executed in 321.24 seconds\n\n8\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sage, Steps: 16\nPrompt executed in 320.95 seconds\n\n","createdAt":"2025-09-26T19:03:23Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3340089441","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HGggW","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@windy-bleue it is probably reading from a legacy path in your models on the same folder. IS VibeVoice stored where in your models? I need to filter it out, probably. \n\nAbout the slowdown it's probably because it filled your system RAM and is now using your HDD files system... After each att change it loads the model again on your RAM. This accumulation is a \"bug\" I tried fixing, but I gave up. Normally you won't reload the model all that much, (change att or quant option), and you can reboot to clear the VRAM an RAM memory. I need to try to fix this again, but I'll leave it for later.","createdAt":"2025-09-26T20:17:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3340371990","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7HI1Ym","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> [@windy-bleue](https://github.com/windy-bleue) it is probably reading from a legacy path in your models on the same folder. IS VibeVoice stored where in your models? I need to filter it out, probably. \n@diodiogod \nAbout the extra names, they come from a directory, comfyui/models/checkpoints , the i make two tests:\n1.  put a file in this directory\n\n<img width=\"277\" height=\"328\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3b144d8d-3e5a-484f-b9d2-2c37e08b1c3f\" />\n\nthen refresh,  it appears in the model list:\n\n<img width=\"251\" height=\"301\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7066eb75-e481-4254-a4cd-3b3e82e0798b\" />\n \n2.  change the directory name 'checkpoints' to something else, then here is un error message, cann't find the file: \\\\ComfyUI\\\\models\\\\checkpoints , does this directory in any cached list?\n \n3. Look the picture, did you ever change the model directory, and i have tow copies of 7B model?  Or you added the huggingfacecache into your model search list ? The f5-tts engine has the same problem. O the same as chatterbox tts engine. \n \n<img width=\"227\" height=\"117\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3d98a67e-f7ca-4d78-b5ad-9530afd6449f\" />\n\n<img width=\"224\" height=\"320\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c5ed8e3c-409f-40e9-82e5-c070845d0181\" />\n\n<img width=\"254\" height=\"307\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8421a2a5-5ab5-4b6c-b5d1-16ee0c92e7c6\" />\n\nI am sorry to bother you, thanks for your works.","createdAt":"2025-09-27T01:43:40Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3340981798","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HJVA3","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> About the slowdown it's probably because it filled your system RAM and is now using your HDD files system... After each att change it loads the model again on your RAM. This accumulation is a \"bug\" I tried fixing, but I gave up. Normally you won't reload the model all that much, (change att or quant option), and you can reboot to clear the VRAM an RAM memory. I need to try to fix this again, but I'll leave it for later.\n@diodiogod \n\nAbout this problem, i may guess something.\nIn my reply above, I ran the TTS in the sequence 1.5B, 7B, 1.5B, then the second 1.5B ran slowly.\nNow i run the  TTS in the sequence 7B, 1.5B, 7B, 1.5B , then the second 7B runs  slowly, 15m30s, the second 1.5B runs normally, and i paste some debug messages below. \n\nSo i think, the second 7B runs in ram, and the cpu does the inference work: \n1  when i first run this tts with the model 7B, it runs normally;\n2  i run 7B again, the speed is normal, but i don't understand why here has a model moving operation,i just change the att; \n3 then i switch to 1.5B , here has another model moving operation, and the speed is normal;\n4 i run 1.5B again, the speed is normal, but i don't understand why here has a model moving operation,i just change the att;\n5 then i switch back to 7B, here hasn't a model moving operation, the speed is very slow, i think the 7B is in ram.\n6 then i switch back to 1.5B, the speed is normal,   here hasn't a model moving operation. \n\nSo, i guess, when i want to run the same model that the tts has moved to ram and offload to cpu , the tts does not move it back to vram. This model runs in ram and the cpu does the inference work.\nIf you don't expect users use the model that you have just moved to ram again , i think you should unload it directly rather than move it to ram. Otherwise, what the meaning of this moving operation.\n\nAfter i finished 6 tests, the ram usage is about 64GB,  the vram usage is about 7GB , it's weired,  the size of 7B  is about 17GB , the size of 1.5B is about 5GB,  there may have 2 copies of 7B model and 1 copy of 1.5B in the ram.\n\nSpeaker 1: Driving across South Dakota, I brought along two trusted aids: a GPS to help me navigate and an audio version of the Bible to keep me calm.  Both did their jobs well, even though every once in a while the GPS interrupted the GoodpBook's narration.\nSpeaker 2: During one account of God leading the Israelites through the wilderness, this is what I heard: ‚ÄúAnd the Lord said to Moses‚Ä¶ in 2 miles, take Exit 110.‚Äù\nSpeaker 3: Clearly, my 11-year-old son has been hanging around his teenage sisters too much. One recent morning he announced, ‚ÄúI can't go to school today.‚Äù\nSpeaker 1: ‚ÄúWhy not?‚Äù I asked.\nSpeaker 2: ‚ÄúI've got cramps.‚Äù\nSpeaker 3: I love you all.\n\n1\ngot prompt\n   Model: vibevoice-7B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sage, Steps: 16\n   üß† Using sage attention\nüîß VibeVoice: Using device_map: cuda\nPrompt executed in 118.55 seconds\n\n2\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-7B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sdpa, Steps: 16\nüîÑ VibeVoice: Moving existing model to CPU instead of clearing (allows reuse)\nüîÑ VibeVoice: Smart CPU migration with RAM cleanup to prevent accumulation\nüîç No old VibeVoice models found in RAM\nüì• Moving VibeVoice to CPU (RAM cleanup completed)\nüîÑ Moved tts model components (vibevoice) to CPU, freed 17821MB\nüîß Unified Interface: accelerate 1.8.1 available for VibeVoice\nüìÅ Using local VibeVoice model: C:\\Users\\yao\\ComfyUI\\models\\TTS\\vibevoice\\vibevoice-7B\nüîÑ Loading VibeVoice model 'vibevoice-7B' on cuda...\n   üß† Using sdpa attention\nüîß VibeVoice: Using device_map: cuda\nPrompt executed in 116.90 seconds\n\n3\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sdpa, Steps: 16\nüîÑ VibeVoice: Moving existing model to CPU instead of clearing (allows reuse)\nüîÑ VibeVoice: Moving existing model to CPU instead of clearing (allows reuse)\nüîÑ VibeVoice: Smart CPU migration with RAM cleanup to prevent accumulation\nüóëÔ∏è Attempting to unload vibevoice model (stateless wrapper enabled)\nüîÑ TTS Model unload requested: vibevoice tts\nüîç VibeVoice deletion: Model currently on cuda\nüóëÔ∏è Cleared VibeVoice class-level cache\n‚ö†Ô∏è NUCLEAR: Forcing CUDA device reset to clear stubborn VibeVoice memory\nüßπ ComfyUI freed memory\nüßπ NUCLEAR CUDA cleanup completed\nüóëÔ∏è VibeVoice: Model deleted completely from cuda\n‚úÖ VibeVoice full deletion: freed 17821MB from cuda\nüóëÔ∏è Removed VibeVoice model from RAM: vibevoice_tts_vi...\nüßπ RAM cleanup: removed 1 old VibeVoice models from system memory\nüì• Moving VibeVoice to CPU (RAM cleanup completed)\nüîÑ Moved tts model components (vibevoice) to CPU, freed 17821MB\nüîß Unified Interface: accelerate 1.8.1 available for VibeVoice\nüìÅ Using cached VibeVoice model: D:\\HuggingFaceCache\\hub\\models--microsoft--VibeVoice-1.5B\\snapshots\\1904eae38036e9c780d28e27990c27748984eafe\nüîÑ Loading VibeVoice model 'vibevoice-1.5B' on cuda...\n   üß† Using sdpa attention\nüîß VibeVoice: Using device_map: cuda\nPrompt executed in 94.55 seconds\n\n4\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sage, Steps: 16\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS engines will fail\nüé§ Generating Vibevoice for 'narrator' (lang: en)\nüîÑ VibeVoice: Moving existing model to CPU instead of clearing (allows reuse)\nüîÑ VibeVoice: Moving existing model to CPU instead of clearing (allows reuse)\nüîÑ VibeVoice: Smart CPU migration with RAM cleanup to prevent accumulation\nüóëÔ∏è Attempting to unload vibevoice model (stateless wrapper enabled)\nüîÑ TTS Model unload requested: vibevoice tts\nüîç VibeVoice deletion: Model currently on cuda\nüóëÔ∏è Cleared VibeVoice class-level cache\n‚ö†Ô∏è NUCLEAR: Forcing CUDA device reset to clear stubborn VibeVoice memory\nüßπ ComfyUI freed memory\nüßπ NUCLEAR CUDA cleanup completed\nüóëÔ∏è VibeVoice: Model deleted completely from cuda\n‚úÖ VibeVoice full deletion: freed 17821MB from cuda\nüóëÔ∏è Removed VibeVoice model from RAM: vibevoice_tts_vi...\nüßπ RAM cleanup: removed 1 old VibeVoice models from system memory\nüì• Moving VibeVoice to CPU (RAM cleanup completed)\nüîÑ Moved tts model components (vibevoice) to CPU, freed 5157MB\nüîß Unified Interface: accelerate 1.8.1 available for VibeVoice\nüìÅ Using cached VibeVoice model: D:\\HuggingFaceCache\\hub\\models--microsoft--VibeVoice-1.5B\\snapshots\\1904eae38036e9c780d28e27990c27748984eafe\nüîÑ Loading VibeVoice model 'vibevoice-1.5B' on cuda...\n   üß† Using sage attention\nüîß VibeVoice: Using device_map: cuda\nPrompt executed in 118.10 seconds\n\n5\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-7B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sage, Steps: 16\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS engines will fail\nüé§ Generating Vibevoice for 'narrator' (lang: en)\nüîÑ Reusing cached vibevoice engine instance (updated with new generation parameters)\nüé≠ VibeVoice: Character switching mode - found characters: speaker 1, speaker 2, speaker 3\nPrompt executed in 00:15:30\n\n6\ngot prompt\nüéôÔ∏è VibeVoice Engine configured:\n   Model: vibevoice-1.5B on auto\n   Mode: Native Multi-Speaker\n   CFG Scale: 1.3, Sampling: False\n   Attention: sage, Steps: 16\nüé§ TTS Text: Using direct audio input (narrator)\n‚ö†Ô∏è TTS Text: Direct audio input has no reference text - F5-TTS engines will fail\nüé§ Generating Vibevoice for 'narrator' (lang: en)\nüîÑ Reusing cached vibevoice engine instance (updated with new generation parameters)\nPrompt executed in 98.40 seconds","createdAt":"2025-09-27T03:32:35Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3341111351","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HJboi","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> > [@windy-bleue]\n> \n>     1. put a file in this directory\n> \n\nIn what directory? The recent version searches for safetensors but it should not search for any safetensors like it is now. This is a minor bug. I asked about the directory because the default directory is `ComfyUI\\models\\TTS\\vibevoice` but I normally make it search for legacy paths like checkpoints, .cache, and so on.\n\nShowing two of the same model, one 7b one 1.5b and local:7b and local:1.5b is normal an intended behavior. Not a problem. F5 and all others works like this. It's to show the user they already have the model \"locally\" and don't need to download it again. But it's the same thing. Choosing 7b or local:7b in the end will load the same local model in this case.\n\n\"just changing\" the attn mode is not like \"just changing a parameter\" like CFG. Changing the att basically means you have to load the model again (at least that is how I manage to make it work). That is why the model re-loads or get sent to RAM. You are correct though, if I can't make the model go back to VRAM again (and I think I can't, I've tried and it get's corrupted or something), I need to not move it to RAM in the first place, just unload it completely. I've tried... but... anyway.\n\nThe model should not be running on CPU. I need to review the whole unloading again in the future. I gave up because it was getting too complex, but i'll try again.","createdAt":"2025-09-27T04:09:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3341138466","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7HJhN9","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> > 1. put a file in this directory\n\n> In what directory? The recent version searches for safetensors but it should not search for any safetensors like it is now. \n@diodiogod \n\nThe directory: comfyui/models/checkpoints . These extra names are the  models name in this directory.\n\nAbout the multipile  copies of the same model , the viebvoice, chatterbox, f5-tts, beacuse i already have  these models in HuggingFaceCache directory,  and i do have some of these models in the  ComfyUI\\models\\TTS . I think i can delete these models from ComfyUI\\models\\TTS, right? \n\n\n\n\n","createdAt":"2025-09-27T04:31:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3341161341","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HKcnI","author":{"login":"alessandroperilli"},"authorAssociation":"NONE","body":"I think this Issue is expanding a lot in terms of scope compared to its title, and it will be challenging to find this information later on for other people. \nI opened #119. It might be a more suitable home for some of these questions.\n\n@windy-bleue Did you try to press this button when the inference time becomes too long? What happens?\n\n<img width=\"283\" height=\"113\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/47c902b5-2828-4010-955c-bb69ff1f66b8\" />\n\n","createdAt":"2025-09-27T08:36:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3341404616","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HLmxT","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I agree with @alessandroperilli. The sage attn is now working and we should close this topic for this to be more manageable for me.\n\nThe unload button should work. Sometimes you have to press it multiple times, but it should work for VRAM (but for RAM accumulation, which VibeVoice tends to do when you switch attn and models a lot, I think you might need to reboot)\n\n@windy-bleue so yes, the VibeVoice code is using comfyui/models/checkpoints as a fallback path, which in your case contains other safetensors beyond the VibeVoice model. That is why you see other models on the selections. Try putting vibevoice in the correct TTS/vibevoice/ path to see if it will stop showing the other models of checkpoints.","createdAt":"2025-09-27T13:24:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3341708371","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7HL7IJ","author":{"login":"windy-bleue"},"authorAssociation":"NONE","body":"> [@windy-bleue](https://github.com/windy-bleue) so yes, the VibeVoice code is using comfyui/models/checkpoints as a fallback path, which in your case contains other safetensors beyond the VibeVoice model. That is why you see other models on the selections. Try putting vibevoice in the correct TTS/vibevoice/ path to see if it will stop showing the other models of checkpoints.\n\n@diodiogod \nYes, i agree with you. This topic should be closed. I just pose my question, how you manager the development is entirely up to you, thanks for your work.\nMy tts models are stored in the comfyui/models/tts/ and huggingfacecache/, it's not a problem, i can handle it , i think i should just keep one copy of the models, in comfyui/models/tts or in HuggingFaceCache .\n \n@alessandroperilli  The button isn't the matter, the matter is the software design.  If a model which has been moved to RAM  can't be moved back to VRAM when it's required for use again , i think it should be unloaded  rather than be moved to RAM. The simpler, the better.  This is just my opinion.\n","createdAt":"2025-09-27T14:13:30Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3341791753","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HMMRm","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> > [@windy-bleue](https://github.com/windy-bleue) so yes, the VibeVoice code is using comfyui/models/checkpoints as a fallback path, which in your case contains other safetensors beyond the VibeVoice model. That is why you see other models on the selections. Try putting vibevoice in the correct TTS/vibevoice/ path to see if it will stop showing the other models of checkpoints.\n> \n> [@diodiogod](https://github.com/diodiogod) Yes, i agree with you. This topic should be closed. I just pose my question, how you manager the development is entirely up to you, thanks for your work. My tts models are stored in the comfyui/tts/ and huggingfacecache/, it isn't a problem, i can handle it , i think i should just keep one copy of the models, in comfyui/models/tts or in HuggingFaceCache .\n> \n> [@alessandroperilli](https://github.com/alessandroperilli) The button isn't the matter, the matter is the software design. If a model which have been moved to RAM can't be moved back to VRAM when it's required for use again , i think it should be unloaded rather than be moved to RAM. The simpler, the better. This is just my opinion.\n\nI agree, I need to do some more work on it whenever I get the time","createdAt":"2025-09-27T15:32:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/44#issuecomment-3341861990","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":44,"title":"Vibevoice not working [check Sage attn implementation]>[check ram accumation]","updatedAt":"2025-12-06T03:23:54Z"},{"comments":[{"id":"IC_kwDOPZi2kc7Ul1oy","author":{"login":"CyberSys"},"authorAssociation":"NONE","body":"+1","createdAt":"2025-11-22T12:55:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/28#issuecomment-3566688818","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Umipa","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Please vote on the discord channel for the next Engine! I'm having a poll there","createdAt":"2025-11-22T16:43:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/28#issuecomment-3566873178","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7UptxQ","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"Where is the link to discord?","createdAt":"2025-11-23T09:39:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/28#issuecomment-3567705168","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7Up6S7","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"First badge on the readme","createdAt":"2025-11-23T10:07:54Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"LAUGH","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/28#issuecomment-3567756475","viewerDidAuthor":true}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLHnXQ","name":"low-priority","description":"","color":"f9d0c4"},{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":28,"title":"Would it be possible to use XTTS-v2 model?","updatedAt":"2025-12-06T03:25:51Z"},{"comments":[{"id":"IC_kwDOPZi2kc7BJdPj","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"It looks correct! But if it doesn't sound like Polish, it might be something wrong. Could you link me the model, so I can try it? (even though I don't speak Polish, but just to do some testing)","createdAt":"2025-08-31T23:14:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3240481763","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7BLBZ7","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"Sure. This is model I used:\n\nhttps://huggingface.co/Gregniuki/F5-tts_English_German_Polish/tree/main/Polish2\n\n","createdAt":"2025-09-01T05:21:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3240892027","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7BP-Ul","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Hey! I found the likely cause of the quality issue with your Polish model.\n\nThe \"lang: lo\" display was just a cosmetic bug (fixed in v4.6.22), but the real quality problem is probably the **vocab.txt file**.\n\nF5-TTS models need a vocabulary file that defines their phoneme set. When you put a local model in the folder without its own vocab.txt, the system falls back to using the default English vocabulary. This causes quality issues because:\n- Polish has different phonemes than English  \n- The model expects Polish phonemes but gets English ones\n\n**Solution:**\nMake sure your Polish model folder includes the correct vocab.txt file from wherever you downloaded the model. The folder structure should be:\n```\nComfyUI/models/TTS/F5-TTS/F5-Polish/\n‚îú‚îÄ‚îÄ model_1200000.safetensors (or .pt)\n‚îî‚îÄ‚îÄ vocab.txt  <-- This is critical for Polish!\n```\n\nIf the original source didn't provide a vocab.txt, try checking if they have a vocab_updated.txt or similar file - just rename it to vocab.txt.\n\nThe model IS loading correctly (you can see it works on the second run with cache), but without the right vocabulary file, the phoneme conversion won't match what the model was trained on.","createdAt":"2025-09-01T12:33:08Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3242190117","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7BQBix","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"Since I have zero knowledge of the language, I cannot assess the quality. Does this sound correct? [The reference voice used was English, so this could also be a problem, maybe a ref in Polish could help]\nInput:\n‚ÄûNie zawsze to, co wydaje siƒô pora≈ºkƒÖ, jest ko≈Ñcem drogi. Czasem to tylko zakrƒôt prowadzƒÖcy do czego≈õ lepszego.‚Äù\n\nAudio:\n[ComfyUI_00020_.mp3](https://github.com/user-attachments/files/22078206/ComfyUI_00020_.mp3)","createdAt":"2025-09-01T12:37:36Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3242203313","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7BRFdz","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"Looks like it is struggling with phoneme: ƒÖ, ƒô.\n\nI tried with polish reference voice and it same issue.\n\nI did use vocab.txt provided with the model, so I don't think this is the source of problem\n\n<img width=\"1056\" height=\"468\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9c203976-7164-4cc6-b29e-be3d68eba75f\" />\n\nAs well when I use WebUI based on this model there is no issue with phonemes.\n\nhttps://huggingface.co/spaces/Gregniuki/f5-tts_Polish_English_German\n\nSeems like the vocab file has correct phonemes as well.\n\n<img width=\"362\" height=\"279\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3e846fc6-e65c-48a4-976d-d41195e37e42\" />\n","createdAt":"2025-09-01T13:57:15Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3242481523","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CVEo-","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I'm working on this, apparently, there is much more I can do to make non-english and non-chinese models work better;","createdAt":"2025-09-06T03:31:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3260303934","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7Cb0eb","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## Tentative Fix Implemented (v4.8.8)\n\nBased on the working Polish F5-TTS implementation you linked, I've implemented a **tentative fix** that adds phonemization support similar to what was working in that reference implementation.\n\n### What I Found\nThe reference implementation you shared was using **phonemization** (text ‚Üí IPA phonemes) for better multilingual support. Our F5-TTS was missing this crucial step, which explains why Polish \"sucks\" compared to implementations that work well.\n\n### What Changed\n- **New phonemization system** that converts non-English text to IPA phonemes (like the working implementation)\n- **User control toggle** (ü¶ú auto_phonemization) in the F5-TTS Engine node \n- **Smart detection** for Polish and other non-English models/text\n- **Portuguese F5-PT-BR protection** (phonemization disabled - was making quality worse)\n\n### How It Works\nFollowing the working implementation pattern:\n1. Detects non-English models (like F5-Polish) \n2. Detects special characters in text (ƒÖ, ƒá, ƒô, ≈Ç, ≈Ñ, √≥, ≈õ, ≈∫, ≈º, etc.)\n3. Converts text to universal phonetic alphabet (IPA) that works with English vocab\n\n### Need Your Help\n\n**@healthyfat** and **anyone who speaks Polish, German, French, Italian, or other languages**:\n\nPlease test this with your F5-TTS models and report back:\n- **Better quality** - phonemization helped (like the reference implementation)\n- **Worse quality** - should be disabled like Portuguese  \n- **No difference** - unclear if it helps\n\nYou'll see debug messages like:\n\n\n### How to Test\n1. Update to v4.8.8\n2. Use F5-TTS Engine node with Polish/other language models\n3. **If quality is poor**: Disable the ü¶ú auto_phonemization toggle\n4. Report back here with results\n\nThis is based on the working implementation you shared, but I need real user feedback to confirm it works across different models!","createdAt":"2025-09-06T12:38:01Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3262072731","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7ChmBO","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"How to update to v4.8.8?\n\nComfyUI is showing only 4.8.23.\n\nGithub shows [v4.8.6](https://github.com/diodiogod/TTS-Audio-Suite/tree/v4.8.6)\n\nhttps://github.com/diodiogod/TTS-Audio-Suite/releases \n\nI manually installed v4.8.6, but the F5 Engine node is not updated. It shows updated node when installed through ComfyUi, but this is 4.8.23 version.","createdAt":"2025-09-07T08:27:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3263586382","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CiEFq","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"You need to change the main option on the manager, channel to current and another oprion to latest, or something. Then restart and wait for it to fetch the registry... I think that works. Or you can do the manual pull and install, but that involves ativating venv or using the bundled python, which most people don't know hoe to do it.\nIt's normal for the manager to lag behind.","createdAt":"2025-09-07T11:32:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3263709546","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7CiFub","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"There is no current channel. Maybe default? \n\n<img width=\"320\" height=\"211\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0ff12dfc-cbbe-4d65-8d90-d4599a471d55\" />\n\nI think for latest you want to choose nightly.\n\n<img width=\"323\" height=\"92\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/aa840746-66bc-4410-9aa1-26b95ce741d4\" />\n\nStill Comfy doesn't see latest update no matter what settings I try.\n\nHow to do manual pull? \n\ngit clone https://github.com/diodiogod/TTS-Audio-Suite.git\n\nWhen I git clone it pulls old version TTS Audio Suite v4.8.23.","createdAt":"2025-09-07T11:46:36Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3263716251","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CiGpR","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"try this \n\n<img width=\"709\" height=\"147\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b3ec632c-e095-4654-871f-5f3920ade44a\" />\n\nSee if it shows the current version for you\n\nand v4.8.23 is the current versionüòÖ 23 is bigger than 8","createdAt":"2025-09-07T11:53:16Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3263720017","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7CiLiU","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"I had no clue this is how it works with numbering versions. Was convince the higher the newer o0 Well in that case I had most current version v4.8.23 from the start and wasted some time trying to install older version XD Oh well, I learn some in the process so maybe not wasted :) \n\nAnyways back to the issue: \n\nUnfortunately phonemization system make it worse. It doesn't sound like Polish language.\n\nDisabling phonemization make it sound like Polish, but special characters are wrong.","createdAt":"2025-09-07T12:27:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3263740052","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CiMrD","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> I had no clue this is how it works with numbering versions. Was convince the higher the newer o0 Well in that case I had most current version v4.8.23 from the start and wasted some time trying to install older version XD Oh well, I learn some in the process so maybe not wasted :)\n> \n> Anyways back to the issue:\n> \n> Unfortunately phonemization system make it worse. It doesn't sound like Polish language.\n> \n> Disabling phonemization make it sound like Polish, but special characters are wrong.\n\noh well! Thanks for testing this... I'll need to keep working on it. I'll try to base again on your reference project that you said sounds good. But I'll have to work on this later. But I won't forget!","createdAt":"2025-09-07T12:35:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3263744707","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GHqOn","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"## üéâ **Update Available: v4.10.0 with New Multilingual Text Processing!**\n\nHey @healthyfat! I've just released **v4.10.0** with a completely new approach to fixing Polish F5-TTS pronunciation issues based on the working reference implementation you shared.\n\n### üÜï What's New: üìù Phoneme Text Normalizer Node\n\nInstead of automatic phonemization (which you said made it worse), I've created a dedicated **üìù Phoneme Text Normalizer** node that gives you full control over text preprocessing with **4 different methods**:\n\n1. **Pass-through**: Original text (no processing)\n2. **Unicode Decomposition**: Converts ƒÖ‚ÜíaÃß, ƒô‚ÜíeÃß, ƒá‚Üíƒá, etc. (similar to @trollver9000's solution in #54)\n3. **IPA Phonemization**: Full phonetic conversion using the exact same method as your working reference\n4. **Character Mapping**: ASCII fallback (ƒÖ‚Üía, ƒô‚Üíe, etc.)\n\n### üîß How It Works\n\nI analyzed the working Polish F5-TTS you linked and implemented the **exact same phonemization pipeline**:\n- Uses  with  backend\n- Same parameters: , \n- Same cleanup regex patterns\n- Works on Windows (uses )\n\n### üìñ Try It Out\n\n1. **Update to v4.10.0** (should be available via ComfyUI Manager soon)\n2. **Download the example workflow**: [F5 TTS integration + üìù Phoneme Text Normalizer](https://github.com/diodiogod/TTS-Audio-Suite/blob/main/example_workflows/F5%20TTS%20integration%20+%20üìù%20Phoneme%20Text%20Normalizer.json)\n3. **Test with your Polish model** using different processing methods\n4. **Let me know which method works best!**\n\n### üß™ Please Test & Report\n\nSince this is experimental and I don't speak Polish, I really need your feedback on:\n- **Which processing method gives the best pronunciation?**\n- **Does IPA Phonemization now work properly?** (should match the reference implementation)\n- **How does Unicode Decomposition compare to the old system?**\n\nThis addresses the exact issues you reported with ƒÖ, ƒô and other special characters. The new system is based on your working reference, so it should finally solve the Polish pronunciation problems!\n\n**Please test and let me know how it works! üáµüá±**","createdAt":"2025-09-23T12:54:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3323896743","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7GUfqX","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"Thanks. I appreciate your effort. Unfortunately it generates gibberish. Some words sound close to polish and some are even close to correct. Overall it seems like phonemeisation makes it worse.\n\nIt seems like model demo might be using espeak and it looks like you implemented some espeak functionality here as well. Maybe it is still some espeak phonemeisation issue.\n\nGeneration log:\n\ngot prompt\nüé§ TTS Text: Using voice reference from folder (polish)\nüé§ Generating F5Tts for 'polish' (lang: local)\nüîÑ Reusing cached f5tts engine instance (updated with new generation parameters)\n‚úÖ F5-TTS: Using reference file 'polish.wav' with auto-detected text\nüîÑ Loading F5-TTS model 'local:F5-Polish' for single character generation\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.31s/it]\n‚úÖ F5Tts generation complete. Default narrator: polish\nPrompt executed in 8.43 seconds\n\nMy workflow:\n\n<img width=\"1581\" height=\"714\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bd2ad120-66e9-49d6-9f05-ff3ef639ca91\" />\n\n","createdAt":"2025-09-24T08:47:04Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3327261335","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7GU1qa","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"I noticed that you used different model: multi3/model_900000.pt, but there is exclusive Polish2/model_1200000.pt which doesn't include tokenizer and vocab looks different. Could this be somehow connected to the issue?","createdAt":"2025-09-24T09:11:19Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3327351450","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7HCMcy","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"At least for now I'm glad that the üìù Phoneme Text Normalizer makes my language (pt-br) on 23-lang chatterbox better than raw text when using Unicode Decomposition mode. Maybe it helps other languages as well.\n\nBut I'll keep investigating the F5 Polish language. Hopefully we eventually can make Polish f5 work as the reference project. I'll check this ASAP.","createdAt":"2025-09-26T15:39:31Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3339241266","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7HCQxL","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@healthyfat do you have a Polish character for using as narrator (audio+text ref) you can send me for my testings? I can't really assess the pronunciation, but it might help in my testings","createdAt":"2025-09-26T15:41:33Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3339258955","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7HKBt2","author":{"login":"healthyfat"},"authorAssociation":"NONE","body":"Sure. Here is the speaker voice I use:\n\n[polish.wav](https://github.com/user-attachments/files/22571291/polish.wav)\n[polish.reference.txt](https://github.com/user-attachments/files/22571292/polish.reference.txt)","createdAt":"2025-09-27T06:11:53Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/22#issuecomment-3341294454","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWvQ","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACHIPW3g","name":"question","description":"Further information is requested","color":"d876e3"},{"id":"LA_kwDOPZi2kc8AAAACJLHtrw","name":"check-later","description":"","color":"006b75"}],"number":22,"title":"Is it possible to choose language for F5-TTS Model? [better phonemization!]","updatedAt":"2025-09-27T06:11:53Z"},{"comments":[],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLHtrw","name":"check-later","description":"","color":"006b75"},{"id":"LA_kwDOPZi2kc8AAAACJLJIww","name":"New-Engines","description":"","color":"5319e7"}],"number":17,"title":"support vevo, xtts2, stylestts2?","updatedAt":"2025-09-01T11:43:43Z"},{"comments":[{"id":"IC_kwDOPZi2kc6_7e17","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"I have not tested this one, IDK what model he is using for the transcription. But the best free transcription model I know and have used is Whisper. It can output an SRT. I might integrate it in my nodes in the future, but I pretty sure you can find a custom node with whisper already if you search for it.","createdAt":"2025-08-25T12:17:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/8#issuecomment-3220041083","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7ADqFu","author":{"login":"BenDes21"},"authorAssociation":"NONE","body":"Thanks a lot!","createdAt":"2025-08-26T00:51:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/8#issuecomment-3222184302","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7CjLd1","author":{"login":"trollver9000"},"authorAssociation":"NONE","body":"Please do integrate whisper to srt ! This would save lot of time going between nodes and workflows from other devs.","createdAt":"2025-09-07T19:50:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/8#issuecomment-3264001909","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7DIeJQ","author":{"login":"gmorain"},"authorAssociation":"NONE","body":"Have you tested [Parakeet v3](https://parakeettdt.com) from NVidia? This model is waaaay faster than Whisper for the languages it supports (multiple European languages), and quality is impressive! Model is on HF, I have not yet looked for a ComfyUI node (used it from the shell and native apps supporting it already)","createdAt":"2025-09-10T07:57:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/8#issuecomment-3273777744","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOPZi2kc8AAAACJLHtrw","name":"check-later","description":"","color":"006b75"}],"number":8,"title":"Best way to generate accurate voice transcription for voice cloning [Add whisper request]","updatedAt":"2025-09-10T07:57:08Z"},{"comments":[{"id":"IC_kwDOPZi2kc6-qsL5","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"The vllm is in my plans. I drafted it already. I'm just not sure I'll manage, but I'll try. \nI first tried the batch (actually parallelization) from https://github.com/petermg/Chatterbox-TTS-Extended, and as you can test it for yourself (with the streamed option)... it does not bring any speed increase unfortunately.","createdAt":"2025-08-19T01:04:52Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/6#issuecomment-3198862073","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc6_qeI1","author":{"login":"jaimitoes"},"authorAssociation":"NONE","body":"@diodiogod The new nodes are amazing! Thanks for all your work. I'm not sure how your nodes handle memory, but I'd settle for the ability to offload after a generation. It would be great if this is not too dificult to do. Again awesome job! ","createdAt":"2025-08-22T20:41:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/6#issuecomment-3215581749","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7AEQAc","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@jaimitoes Great news! I've just implemented ComfyUI memory management integration in v4.5.11.\n\n**You can now manually unload TTS models** using either:\n\n1. **ComfyUI Manager's 'Unload Models' button** - This will unload ChatterBox and F5-TTS models to free up VRAM\n2. **'Clean VRAM Used' node from [Easy Use](https://github.com/yolain/ComfyUI-Easy-Use)** - You can connect this between your TTS output and preview/save audio nodes for automatic memory cleanup\n\n**Example workflow setup:**\n\n<img width=\"1818\" height=\"432\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/633e4dcb-560b-44bb-a07c-5815b6ec6f1b\" />\n\n**Important notes:**\n- ChatterBox and F5-TTS models: ‚úÖ Full unloading support\n- Higgs Audio models: ‚ùå Cannot be unloaded due to CUDA graph limitations (they lock GPU memory)\n\nThe implementation includes device consistency fixes and reduced warning spam. Models will properly unload and free VRAM when requested through ComfyUI's memory management system.\n\nThis addresses the memory management part of your request! As for ChatterBox optimizations (vLLM integration), that's still planned for future development as mentioned earlier.","createdAt":"2025-08-26T02:22:31Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/6#issuecomment-3222339612","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7AQY5j","author":{"login":"jaimitoes"},"authorAssociation":"NONE","body":"@diodiogod You are amazing! Thank you very much! This give us the ability to create combined video and audio Workflows. Again, Thank you very much for your Job!","createdAt":"2025-08-26T19:47:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/6#issuecomment-3225521763","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7ARD-7","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> [@diodiogod](https://github.com/diodiogod) You are amazing! Thank you very much! This give us the ability to create combined video and audio Workflows. Again, Thank you very much for your Job!\n\nIt's unfortunate that Higgs 2 didn't work, since it's the biggest of them all (11GB). I tried my best, I've tried many approaches, but it might require a real dev to look into it. It always gives cuda graph errors when unloading or reloading it back.","createdAt":"2025-08-26T20:53:38Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/6#issuecomment-3225698235","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7A1Wvz","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"@jaimitoes Update on the Higgs Audio memory management:\n\nI spent way too much time trying to fix the CUDA graph crashes, but it's a fundamental incompatibility issue. \n\nAs a workaround, I added a toggle in v4.5.27 that lets you choose between performance vs memory management:\n- High performance mode: 55+ tok/s but can't unload (same as before)\n- Memory safe mode: ~12 tok/s (about 70% slower) but you can unload properly\n\nSo technically it works now, but the performance hit is pretty brutal. Better than nothing for workflows that need the memory management I guess.","createdAt":"2025-08-28T23:13:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/6#issuecomment-3235212275","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7BJBQE","author":{"login":"jaimitoes"},"authorAssociation":"NONE","body":"@diodiogod Very thanks for the update! Audio generation is just called one time in my case in a workflow, so this slowdown to save more memory really deserve it when the big part computing is from the video side. Again, thank you very much! It is very apreciated!","createdAt":"2025-08-31T19:41:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/6#issuecomment-3240367108","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACHIPWyQ","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":6,"title":"Optimized Chatterbox?","updatedAt":"2025-09-01T11:39:41Z"},{"comments":[{"id":"IC_kwDOPZi2kc6-eF55","author":{"login":"JaneDoe84"},"authorAssociation":"NONE","body":"if the discord user only want to use it on sillytavern, he can just create a \"api\" workflow in comfyui.\nas sillytavern support this kind of \"api\" workflow.\n\nhere is an example for \"image generation\", can be used as refference how comfyui api -> sillytavern works:\nhttps://docs.sillytavern.app/extensions/stable-diffusion/#comfyui-configuration","createdAt":"2025-08-18T08:00:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/1#issuecomment-3195559545","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc6-hF4v","author":{"login":"diodiogod"},"authorAssociation":"OWNER","body":"> if the discord user only want to use it on sillytavern, he can just create a \"api\" workflow in comfyui. as sillytavern support this kind of \"api\" workflow.\n> \n> here is an example for \"image generation\", can be used as refference how comfyui api -> sillytavern works: https://docs.sillytavern.app/extensions/stable-diffusion/#comfyui-configuration\n\nThis would be incredibly helpful, since I don't want to make an native API inside my node suite for \n1- I don't use it, and it would be a lot of research for me \n2- IDK but communicating through an API within a custom_node might signal security issues that some people might not be willing to take \n3- I feel like it falls a little out of the scope of this project\n\nThanks for bringing this up, I'll redirect to that user!","createdAt":"2025-08-18T11:56:42Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/1#issuecomment-3196345903","viewerDidAuthor":true},{"id":"IC_kwDOPZi2kc7BF0Wj","author":{"login":"shivdbz2010"},"authorAssociation":"NONE","body":"can you make it openai api compatible? sillytavern support that too.","createdAt":"2025-08-30T20:33:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_DOWN","users":{"totalCount":1}}],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/1#issuecomment-3239527843","viewerDidAuthor":false},{"id":"IC_kwDOPZi2kc7BGojk","author":{"login":"JaneDoe84"},"authorAssociation":"NONE","body":"> can you make it openai api compatible? sillytavern support that too.\n\n@shivshankar11 \ni try to explain simple:\nwhy should the dev work on his OWN api, wen comfyui allready has a API you can use with other apps like sillytavern ?\ndid you read my answer above and clicked the link to sillytavern wiki how to use comfyui workflows inside ?\n\nplease let the dev work on his app, were he did a very great job for all of us :-)","createdAt":"2025-08-31T04:11:31Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/diodiogod/TTS-Audio-Suite/issues/1#issuecomment-3239741668","viewerDidAuthor":false}],"labels":[{"id":"LA_kwDOPZi2kc8AAAACJLHnXQ","name":"low-priority","description":"","color":"f9d0c4"},{"id":"LA_kwDOPZi2kc8AAAACJLHtrw","name":"check-later","description":"","color":"006b75"}],"number":1,"title":"Feature Request: API Integration for SillyTavern and External Applications","updatedAt":"2025-09-01T11:38:49Z"}]
